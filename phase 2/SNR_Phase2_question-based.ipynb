{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfVq3nqAhea"
      },
      "source": [
        "### 0. Loading data\n",
        "#### We've attached the raw data. To use this, load the data by `pandas.read_excel()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "HzM3OkRHAu7U",
        "outputId": "2bc2e3c1-3ef4-40f0-e570-b119fdaa18f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab8337fe-b528-47f6-a20b-eca21bd51c60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab8337fe-b528-47f6-a20b-eca21bd51c60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab8337fe-b528-47f6-a20b-eca21bd51c60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab8337fe-b528-47f6-a20b-eca21bd51c60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "root_dir = os.getcwd() + '/data/'\n",
        "questions_dir = 'Question.xlsx'\n",
        "train_dir = 'tot_train.xlsx'\n",
        "train2_dir = 'p2_train.xlsx'\n",
        "test_dir = 'p2_test.xlsx'\n",
        "\n",
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F6VEWREu_V62"
      },
      "source": [
        "### 1. Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QiYKNlnu3qIn"
      },
      "source": [
        "#### 1-1. Encoding MBTI Labels\n",
        "Since the lable is given as String type (e.g. ISTP), we have to convert it to vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB41Fus33pof"
      },
      "outputs": [],
      "source": [
        "def MBTI_to_vec(mbti):\n",
        "  if len(mbti) != 4:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[0] == 'I':\n",
        "    fst = [1, 0]\n",
        "  elif mbti[0] == 'E':\n",
        "    fst = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[1] == 'S':\n",
        "    snd = [1, 0]\n",
        "  elif mbti[1] == 'N':\n",
        "    snd = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[2] == 'T':\n",
        "    trd = [1, 0]\n",
        "  elif mbti[2] == 'F':\n",
        "    trd = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "  \n",
        "  if mbti[3] == 'J':\n",
        "    fth = [1, 0]\n",
        "  elif mbti[3] == 'P':\n",
        "    fth = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "  \n",
        "  return [fst, snd, trd, fth]\n",
        "\n",
        "# Unit Test\n",
        "assert(MBTI_to_vec(\"ISTJ\") == [[1, 0], [1, 0], [1, 0], [1, 0]])\n",
        "assert(MBTI_to_vec(\"ENFP\") == [[0, 1], [0, 1], [0, 1], [0, 1]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "amXEp8Fm6MAY"
      },
      "source": [
        "#### 1-2. Encoding Short Answers\n",
        "Since the short answer is given as String type (e.g. 그렇다), we have to convert it to vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvYyVH9U6MAZ"
      },
      "outputs": [],
      "source": [
        "def short_answer_to_vec(short_answer):\n",
        "  if short_answer == '그렇다':\n",
        "    return [[0, 0]]\n",
        "  \n",
        "  elif short_answer == '중립/모르겠다':\n",
        "    return [[0, 1]]\n",
        "  \n",
        "  elif short_answer == '아니다':\n",
        "    return [[1, 0]]\n",
        "  \n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {short_answer}\")\n",
        "\n",
        "# Unit Test\n",
        "assert(short_answer_to_vec(\"그렇다\") == [[0, 0]])\n",
        "assert(short_answer_to_vec(\"중립/모르겠다\") == [[0, 1]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6bWrEpfD-syd"
      },
      "source": [
        "#### 1-3. Types(Intention) of Questions\n",
        "We found that each question is specially designed for each sort of personalities. Therefore, make a list of questions for each sort of personalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ6xF1Az-sye"
      },
      "outputs": [],
      "source": [
        "IE_list = [1, 6, 11, 15, 16, 21, 26, 31, 36, 41, 43, 51, 53]\n",
        "SN_list = [2, 12, 17, 19, 22, 28, 30, 32, 35, 37, 40, 45, 46, 50, 52, 55]\n",
        "TF_list = [3, 5, 8, 10, 13, 18, 23, 25, 27, 33, 38, 42, 47, 48, 54, 57, 58]\n",
        "JP_list = [4, 7, 9, 14, 20, 24, 29, 34, 39, 44, 49, 56, 59, 60]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4nPMPB_oNa"
      },
      "source": [
        "### 2. Model Proposal\n",
        "#### 질문별 모델: 질문 별로 모델을 만든 후 60개의 확률 도출 => 질문의 의도에 따라 MBTI 도출"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhmqy-tM25V9"
      },
      "source": [
        "### 3. Implementation of the Question-based Approach\n",
        "We decide to use pre-trained BERT model as the base model, so let's implement it!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V80QZhIB6bQA"
      },
      "source": [
        "#### 3-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1QeW-w4U7FaE",
        "outputId": "cd9f1fc3-fc8d-4426-abde-6f25fe4cea95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6aa6bc1d-3afa-46b1-90f3-a473483c63a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa6bc1d-3afa-46b1-90f3-a473483c63a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aa6bc1d-3afa-46b1-90f3-a473483c63a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aa6bc1d-3afa-46b1-90f3-a473483c63a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions_raw = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions = questions_raw.drop(['index', 'index.1'], axis='columns')\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Uj0IDoIeBqc5",
        "outputId": "b083bf8e-bf1e-49dc-e02d-e122ef61eca6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-348f3bf3-397f-490c-b5a9-80256fe42c16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Q_number</th>\n",
              "      <th>Short_Answer</th>\n",
              "      <th>Long_Answer</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의 친구와만...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>저는 일부러 만들려고 노력하지는 않아요. 생활하면서 자연스럽게 만들어지는 건 좋아해요.</td>\n",
              "      <td>ESTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>꼭 필요한 상황이 아니면 먼저 친해지려 하지 않는다. 친구를 만드는 일도 신경을 ...</td>\n",
              "      <td>ISTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>저는 새로운 친구보다 오랜 친구를 선호합니다. 나의 가장 친한 친구는 5살 때 유...</td>\n",
              "      <td>INFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>저는 주기적으로 새로운 친구를 만들지 않습니다. 이유는 나이가 들수록 새로운 사람...</td>\n",
              "      <td>ISTJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-348f3bf3-397f-490c-b5a9-80256fe42c16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-348f3bf3-397f-490c-b5a9-80256fe42c16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-348f3bf3-397f-490c-b5a9-80256fe42c16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  Q_number Short_Answer  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1          아니다   \n",
              "1  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1      중립/모르겠다   \n",
              "2  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1          아니다   \n",
              "3  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1          아니다   \n",
              "4  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1          아니다   \n",
              "\n",
              "                                         Long_Answer  MBTI  \n",
              "0   어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의 친구와만...  INFP  \n",
              "1   저는 일부러 만들려고 노력하지는 않아요. 생활하면서 자연스럽게 만들어지는 건 좋아해요.  ESTJ  \n",
              "2   꼭 필요한 상황이 아니면 먼저 친해지려 하지 않는다. 친구를 만드는 일도 신경을 ...  ISTP  \n",
              "3   저는 새로운 친구보다 오랜 친구를 선호합니다. 나의 가장 친한 친구는 5살 때 유...  INFJ  \n",
              "4   저는 주기적으로 새로운 친구를 만들지 않습니다. 이유는 나이가 들수록 새로운 사람...  ISTJ  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "training = pd.read_excel(os.path.join(root_dir, train_dir))\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "# training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Q_number', 'Short_Answer', 'Long_Answer', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "u5J9Zg-VKKmM",
        "outputId": "2c272241-6c12-439f-cb82-178a842d752a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e8f0a2f-2d8b-4ce4-b2c6-760b8df4a4f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Q_number</th>\n",
              "      <th>Short_Answer</th>\n",
              "      <th>Long_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>친구를 만들 상황에 새로운 친구를 만듭니다. 의도적으로나 꼭 주기적으로 새로운 친구...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>주기적으로 새로운 친구를 만들지는 않습니다. 자연스러운 만남을 추구하는 스타일로 업...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>새로운 친구를 만들기 위해 주기적으로 노력을 하진 않지만 같은 사람들과의 만남이 무...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>주기적으로는 아니나 새로운 친구를 만들고, 만나는 것엔 부담이 없다. 아이가 있어 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>저는 기존 친구들과 만나기도 바쁘고 하지만 친구가 새로운 친구 소개해 주면 반갑게 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e8f0a2f-2d8b-4ce4-b2c6-760b8df4a4f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e8f0a2f-2d8b-4ce4-b2c6-760b8df4a4f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e8f0a2f-2d8b-4ce4-b2c6-760b8df4a4f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   User_ID                                           Question  Q_number  \\\n",
              "0        1  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "1        2  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "2        3  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "3        4  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "4        5  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "\n",
              "  Short_Answer                                        Long_Answer  \n",
              "0          아니다  친구를 만들 상황에 새로운 친구를 만듭니다. 의도적으로나 꼭 주기적으로 새로운 친구...  \n",
              "1          아니다  주기적으로 새로운 친구를 만들지는 않습니다. 자연스러운 만남을 추구하는 스타일로 업...  \n",
              "2      중립/모르겠다  새로운 친구를 만들기 위해 주기적으로 노력을 하진 않지만 같은 사람들과의 만남이 무...  \n",
              "3          아니다  주기적으로는 아니나 새로운 친구를 만들고, 만나는 것엔 부담이 없다. 아이가 있어 ...  \n",
              "4      중립/모르겠다  저는 기존 친구들과 만나기도 바쁘고 하지만 친구가 새로운 친구 소개해 주면 반갑게 ...  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_excel(os.path.join(root_dir, test_dir))\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Data_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "# testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['User_ID', 'Question', 'Q_number', 'Short_Answer', 'Long_Answer']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VUjMGHr950gO"
      },
      "source": [
        "#### 3-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXzVx931Cz1n",
        "outputId": "1dde715a-d885-4646-f7f4-0e54b8190336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Long_Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 203 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "short_answers = []\n",
        "labels = []\n",
        "q_nums = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  # question = training['Question'][idx]\n",
        "  short_answer = training['Short_Answer'][idx]\n",
        "  long_answer = training['Long_Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "  q_num = training['Q_number'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      # question,\n",
        "      long_answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  short_answers.append(torch.tensor(short_answer_to_vec(short_answer)))\n",
        "  labels.append(torch.tensor([mbti]))\n",
        "  q_nums.append(torch.tensor([[q_num]]))\n",
        "  \n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "short_answers = torch.cat(short_answers, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "q_nums = torch.cat(q_nums, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYX7jj944Nl",
        "outputId": "e52daed7-b685-4915-fb12-d22601e76945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2, 18430,  3463,  5724,  8423, 26850, 20699, 14204, 15916, 17729,\n",
            "        25878, 18895, 14045, 27024,  8107, 28669,  8120,  6266, 24832,  2016,\n",
            "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 0])\n",
            "tensor([[1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1]])\n",
            "tensor([1])\n",
            "18720 18720 18720 18720 18720\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(short_answers[0])\n",
        "print(labels[0])\n",
        "print(q_nums[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(short_answers), len(labels), len(q_nums))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1tvttyE7u-u"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YfufvCqV8hAk"
      },
      "source": [
        "#### 3-2. Dataset & Dataloader Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fpBRC3bE81Yt",
        "outputId": "7b4c4ee9-6d79-4bd4-ee39-1d0fa86ee3a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n###\\ntrain_dataloader = DataLoader(\\n    train_dataset,\\n    sampler = RandomSampler(train_dataset),\\n    batch_size = batch_size\\n)\\n\\nval_dataloader = DataLoader(\\n    val_dataset,\\n    sampler = RandomSampler(val_dataset),\\n    batch_size = batch_size\\n)\\n###\\n'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset = TensorDataset(input_ids, att_masks, short_answers, labels, q_nums)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "'''\n",
        "###\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "print(f\"lengths are {train_size}:{val_size}\")\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "###\n",
        "'''\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    sampler = RandomSampler(dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "'''\n",
        "###\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler = RandomSampler(val_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "###\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MiFi795-0LRR"
      },
      "source": [
        "#### 3-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bXQ6VK10S-2",
        "outputId": "6f403001-fcfc-4ce9-9234-cd3b689605c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 1 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 2 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 3 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 4 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 5 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 6 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 7 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 8 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 9 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 10 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 11 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 12 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 13 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 14 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 15 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 16 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 17 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 18 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 19 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 20 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 21 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 22 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 23 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 24 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 25 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 26 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 27 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 28 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 29 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 30 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 31 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 32 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 33 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 34 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 35 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 36 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 37 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 38 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 39 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 40 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 41 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 42 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 43 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 44 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 45 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 46 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 47 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 48 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 49 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 50 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 51 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 52 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 53 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 54 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 55 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 56 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 57 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 58 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 59 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: 60 / 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.lin = nn.Linear(hidden_size, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "    '''\n",
        "    self.linstr = nn.Linear(hidden_size, (int)(hidden_size * (127 / 128)))\n",
        "    self.linsrt = nn.Linear(2, hidden_size - (int)(hidden_size * (127 / 128)))\n",
        "    self.lin = nn.Linear(hidden_size, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(128, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "    '''\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks, short_answers):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "\n",
        "    lin_output = self.lin(dr_output)\n",
        "    \n",
        "    return self.classifier(lin_output)\n",
        "    '''\n",
        "    linstr_output = self.linstr(dr_output)\n",
        "    linsrt_output = self.linsrt(short_answers)\n",
        "\n",
        "    srt_added = torch.cat((linstr_output, linsrt_output), dim=1)\n",
        "\n",
        "    lin_output = self.lin(srt_added)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "\n",
        "    return self.classifier(lin2_output)\n",
        "    '''\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "learning_rate = 2e-5\n",
        "epochs = (15, 1)\n",
        "\n",
        "cnt = 1\n",
        "for (idx_list, sort) in zip([IE_list, SN_list, TF_list, JP_list], ['IE', 'SN', 'TF', 'JP']):\n",
        "  for i in idx_list:\n",
        "    # if i != 49:\n",
        "    #   cnt += 1\n",
        "    #   continue\n",
        "    \n",
        "    if i > 48:\n",
        "      iepochs = epochs[1]\n",
        "    else:\n",
        "      iepochs = epochs[0]\n",
        "    \n",
        "    total_steps = len(dataloader) * iepochs\n",
        "    warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "    print(f\"model: {cnt} / 60\")\n",
        "    model_bert = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "    model = MBTIClassifier(model_bert, dr_rate = 0.3)\n",
        "\n",
        "    optimizer_grouped_parameters = [\n",
        "      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "        \n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "\n",
        "    torch.save({\n",
        "            'model': model,\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler\n",
        "            }, f\"model_{i}.pt\")\n",
        "\n",
        "    del(model, optimizer, scheduler)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cnt += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o4aI0xph5XZY"
      },
      "source": [
        "#### 3-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96CmUo_RMZ5I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpoE7t9f3yKz",
        "outputId": "f498145b-fa68-4734-8fdd-d7e2d5c566d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= model JP_57 =======\n",
            "\n",
            "======= 1 / 1 =======\n",
            "epoch 1 batch id 15066 loss 0.6246479153633118 train acc 0.5\n",
            "epoch 1 batch id 15134 loss 0.6105066537857056 train acc 0.5051546391752577\n",
            "epoch 1 batch id 15427 loss 0.6723166108131409 train acc 0.5102040816326531\n",
            "epoch 1 batch id 15447 loss 0.7272826433181763 train acc 0.5050505050505051\n",
            "epoch 1 batch id 15463 loss 0.7480919361114502 train acc 0.5\n",
            "epoch 1 batch id 15501 loss 0.6603890657424927 train acc 0.504950495049505\n",
            "epoch 1 batch id 15531 loss 0.9035084247589111 train acc 0.5\n",
            "epoch 1 batch id 15647 loss 0.7314177751541138 train acc 0.49514563106796117\n",
            "epoch 1 batch id 16038 loss 0.6845346689224243 train acc 0.5\n",
            "epoch 1 batch id 16059 loss 0.6100777387619019 train acc 0.5047619047619047\n",
            "epoch 1 batch id 16169 loss 0.8777186870574951 train acc 0.5\n",
            "epoch 1 batch id 16745 loss 0.7407786250114441 train acc 0.4953271028037383\n",
            "epoch 1 size 13 validation acc 0.5384615384615384\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "###\n",
        "cnt = 1\n",
        "\n",
        "for (idx_list, sort) in zip([IE_list, SN_list, TF_list, JP_list], ['IE', 'SN', 'TF', 'JP']):\n",
        "  for i in idx_list:\n",
        "    # if i != 49:\n",
        "    #   cnt += 1\n",
        "    #   continue\n",
        "    \n",
        "    if i > 48:\n",
        "      iepochs = epochs[1]\n",
        "    else:\n",
        "      iepochs = epochs[0]\n",
        "\n",
        "    print(f\"\\n======= model {sort}_{cnt} =======\")\n",
        "\n",
        "    loading = torch.load(f\"model_{i}.pt\")\n",
        "    model = loading['model']\n",
        "    optimizer = loading['optimizer']\n",
        "    scheduler = loading['scheduler']\n",
        "    \n",
        "    model.train()\n",
        "    model.cuda()\n",
        "  \n",
        "    for epoch in range(iepochs):\n",
        "      print(f\"\\n======= {epoch + 1} / {iepochs} =======\")\n",
        "      train_acc = 0.0\n",
        "      train_step = 0\n",
        "      val_acc = 0.0\n",
        "      val_step = 0\n",
        "\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "        b_input_id = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_short = batch[2].float().to(device)\n",
        "        \n",
        "        if sort == 'IE':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[0] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'SN':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[1] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'TF':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[2] , batch[3].tolist()))).float().to(device)\n",
        "        else:\n",
        "          b_label = torch.tensor(list(map(lambda x: x[3] , batch[3].tolist()))).float().to(device)\n",
        "        \n",
        "        b_q_num = int(batch[4][0])\n",
        "\n",
        "        if b_q_num != i:\n",
        "          continue\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        b_out = model(b_input_id, b_input_mask, b_short)\n",
        "        loss = loss_fn(b_out, b_label)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_acc += calc_accuracy(b_out, b_label)\n",
        "        train_step += 1\n",
        "\n",
        "        if step > 15000:\n",
        "          print(f\"epoch {epoch + 1} batch id {step} loss {loss.data.cpu().numpy()} train acc {train_acc / train_step}\")\n",
        "      \n",
        "      model.eval()\n",
        "      for step, batch in enumerate(val_dataloader):\n",
        "        b_input_id = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_short = batch[2].float().to(device)\n",
        "\n",
        "        if sort == 'IE':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[0] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'SN':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[1] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'TF':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[2] , batch[3].tolist()))).float().to(device)\n",
        "        else:\n",
        "          b_label = torch.tensor(list(map(lambda x: x[3] , batch[3].tolist()))).float().to(device)\n",
        "        \n",
        "        b_q_num = int(batch[4][0])\n",
        "\n",
        "        if b_q_num != i:\n",
        "          continue\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          b_out = model(b_input_id, b_input_mask, b_short)\n",
        "        \n",
        "        val_acc += calc_accuracy(b_out, b_label)\n",
        "        val_step += 1\n",
        "\n",
        "      print(f\"epoch {epoch + 1} size {val_step} validation acc {val_acc / val_step}\")\n",
        "    \n",
        "    torch.save({\n",
        "            'model': model,\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler\n",
        "            }, f\"model_{i}.pt\")\n",
        "\n",
        "    del(model, optimizer, scheduler)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cnt += 1\n",
        "\n",
        "###\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PoqmoaRECiF"
      },
      "outputs": [],
      "source": [
        "cnt = 1\n",
        "\n",
        "for (idx_list, sort) in zip([IE_list, SN_list, TF_list, JP_list], ['IE', 'SN', 'TF', 'JP']):\n",
        "  for i in idx_list:\n",
        "    if i > 48:\n",
        "      iepochs = epochs[1]\n",
        "    else:\n",
        "      iepochs = epochs[0]\n",
        "    \n",
        "    print(f\"\\n======= model {sort}_{cnt} =======\")\n",
        "\n",
        "    loading = torch.load(f\"model_{i}.pt\")\n",
        "    model = loading['model']\n",
        "    optimizer = loading['optimizer']\n",
        "    scheduler = loading['scheduler']\n",
        "    \n",
        "    model.train()\n",
        "    model.cuda()\n",
        "  \n",
        "    for epoch in range(iepochs):\n",
        "      print(f\"\\n======= {epoch + 1} / {iepochs} =======\")\n",
        "      train_acc = 0.0\n",
        "      train_step = 0\n",
        "\n",
        "      for step, batch in enumerate(dataloader):\n",
        "        b_input_id = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_short = batch[2].float().to(device)\n",
        "        \n",
        "        if sort == 'IE':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[0] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'SN':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[1] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'TF':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[2] , batch[3].tolist()))).float().to(device)\n",
        "        else:\n",
        "          b_label = torch.tensor(list(map(lambda x: x[3] , batch[3].tolist()))).float().to(device)\n",
        "        \n",
        "        b_q_num = int(batch[4][0])\n",
        "\n",
        "        if b_q_num != i:\n",
        "          continue\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        b_out = model(b_input_id, b_input_mask, b_short)\n",
        "        loss = loss_fn(b_out, b_label)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_acc += calc_accuracy(b_out, b_label)\n",
        "        train_step += 1\n",
        "\n",
        "        if step > 15000:\n",
        "          print(f\"epoch {epoch + 1} batch id {step} loss {loss.data.cpu().numpy()} train acc {train_acc / train_step}\")\n",
        "    \n",
        "    torch.save({\n",
        "            'model': model,\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler\n",
        "            }, f\"model_{i}.pt\")\n",
        "\n",
        "    del(model, optimizer, scheduler)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cnt += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r6aUUqFB4QcB"
      },
      "source": [
        "#### 3-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mly0ZcZJ69TI",
        "outputId": "cae7a338-26dd-48c0-ee9a-283782577ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Long_Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "short_answers = []\n",
        "q_nums = []\n",
        "user_ids = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  short_answer = testing['Short_Answer'][idx]\n",
        "  long_answer = testing['Long_Answer'][idx]\n",
        "  q_num = testing['Q_number'][idx]\n",
        "  user_id = testing['User_ID'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      long_answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  short_answers.append(torch.tensor(short_answer_to_vec(short_answer)))\n",
        "  q_nums.append(torch.tensor([[q_num]]))\n",
        "  user_ids.append(torch.tensor([[user_id]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "short_answers = torch.cat(short_answers, dim=0)\n",
        "q_nums = torch.cat(q_nums, dim=0)\n",
        "user_ids = torch.cat(user_ids, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoLpownw4P9S"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset = TensorDataset(input_ids, att_masks, short_answers, q_nums, user_ids)\n",
        "\n",
        "batch_size = 1 # each person, each question\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    sampler = SequentialSampler(dataset),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM2eHuMr9T7E"
      },
      "outputs": [],
      "source": [
        "probs = []\n",
        "preds = []\n",
        "users = []\n",
        "\n",
        "users_IE = dict()\n",
        "users_SN = dict()\n",
        "users_TF = dict()\n",
        "users_JP = dict()\n",
        "\n",
        "cur_q = 0\n",
        "\n",
        "for step, batch in enumerate(dataloader):\n",
        "  print(f\"-------------- {step} / {len(dataloader)} --------------\")\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_short = batch[2].float().to(device)\n",
        "  b_q_num = int(batch[3][0])\n",
        "  b_user_id = int(batch[4][0])\n",
        "\n",
        "  if not b_user_id in users:\n",
        "    users.append(b_user_id)\n",
        "  \n",
        "  if cur_q != b_q_num:\n",
        "    cur_q = b_q_num\n",
        "\n",
        "    model = torch.load(f\"model_{b_q_num}.pt\")['model']\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    b_out = model(b_input_id, b_input_mask, b_short)\n",
        "  \n",
        "  b_out_np = b_out.detach().cpu().numpy().tolist()[0]\n",
        "\n",
        "  if b_q_num in IE_list:\n",
        "    if b_user_id in users_IE.keys():\n",
        "      users_IE[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_IE[b_user_id] = [b_out_np[1]]\n",
        "    \n",
        "  elif b_q_num in SN_list:\n",
        "    if b_user_id in users_SN.keys():\n",
        "      users_SN[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_SN[b_user_id] = [b_out_np[1]]\n",
        "  \n",
        "  elif b_q_num in TF_list:\n",
        "    if b_user_id in users_TF.keys():\n",
        "      users_TF[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_TF[b_user_id] = [b_out_np[1]]\n",
        "  \n",
        "  else:\n",
        "    if b_user_id in users_JP.keys():\n",
        "      users_JP[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_JP[b_user_id] = [b_out_np[1]]\n",
        "\n",
        "for prob_IE, prob_SN, prob_TF, prob_JP in zip(users_IE.values(), users_SN.values(), users_TF.values(), users_JP.values()):\n",
        "  avg_prob_IE = float (sum(prob_IE) / len(prob_IE))\n",
        "  avg_prob_SN = float (sum(prob_SN) / len(prob_SN))\n",
        "  avg_prob_TF = float (sum(prob_TF) / len(prob_TF))\n",
        "  avg_prob_JP = float (sum(prob_JP) / len(prob_JP))\n",
        "\n",
        "  probs.append([avg_prob_IE, avg_prob_SN, avg_prob_TF, avg_prob_JP])\n",
        "  preds.append(list(map(lambda x: 1 if x > 0.5 else 0, [avg_prob_IE, avg_prob_SN, avg_prob_TF, avg_prob_JP])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGdVXi7R-o50",
        "outputId": "238656c3-511d-4693-d84d-b9045600c8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120 120 120 120\n"
          ]
        }
      ],
      "source": [
        "print(len(users), len(users_IE.values()), len(probs), len(preds))\n",
        "\n",
        "preds_df = {'User_ID': users, 'I/E': list(map(lambda x:x[0], preds)), 'S/N': list(map(lambda x:x[1], preds)), 'T/F': list(map(lambda x:x[2], preds)), 'J/P': list(map(lambda x:x[3], preds))}\n",
        "preds_df = pd.DataFrame(data=preds_df)\n",
        "preds_df = preds_df.set_index('User_ID')\n",
        "preds_df.to_csv('result.csv')\n",
        "\n",
        "probs_df = {'User_ID': users, 'I/E': list(map(lambda x:x[0], probs)), 'S/N': list(map(lambda x:x[1], probs)), 'T/F': list(map(lambda x:x[2], probs)), 'J/P': list(map(lambda x:x[3], probs))}\n",
        "probs_df = pd.DataFrame(data=probs_df)\n",
        "probs_df = probs_df.set_index('User_ID')\n",
        "probs_df.to_csv('result_prob.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aldjke5v-I4w"
      },
      "source": [
        "### 4. Expansion of the Question-based Approach\n",
        "Now, aggregate results using a deep learning model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yKoLgHZM-I4y"
      },
      "source": [
        "#### 4-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2z2-xwrg-I4z",
        "outputId": "d1f0bc4f-8f31-49f1-e208-94d4cfba39c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-20efacd1-18f0-4009-8d63-6d07504abbe1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20efacd1-18f0-4009-8d63-6d07504abbe1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20efacd1-18f0-4009-8d63-6d07504abbe1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20efacd1-18f0-4009-8d63-6d07504abbe1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions_raw = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions = questions_raw.drop(['index', 'index.1'], axis='columns')\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "N9qSiv9b-I40",
        "outputId": "e33462ef-251f-4262-abc2-46cfff0b9e48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-effd8953-a560-449f-b0cf-a8afb9ebcfd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Q_number</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Short_Answer</th>\n",
              "      <th>Long_Answer</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>아니다</td>\n",
              "      <td>새로운 사람을 만나서 이야기를 나누고 마음이 통하는 친구가 되기까지의 과정은 많은 ...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>저는 주기적으로는 새로운 친구들을 만들지 않습니다. 이유는 새로운 친구들을 사기기 ...</td>\n",
              "      <td>ENTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>아니다</td>\n",
              "      <td>저는 굳이 새로운 친구들을 만들려고 하지 않아요. 원래 친하던 친구들과 만나는 게 ...</td>\n",
              "      <td>ESFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>아니다</td>\n",
              "      <td>저는 주기적으로 새로운 친구를 잘 만드는 편은 아닙니다. 최근에 재택근무를 하면서 ...</td>\n",
              "      <td>ENFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>그렇다</td>\n",
              "      <td>새로운 친구를 만들면서 그들의 일상을 듣고 나누는 것이 재미있습니다. 새로운 사람을...</td>\n",
              "      <td>ESFJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-effd8953-a560-449f-b0cf-a8afb9ebcfd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-effd8953-a560-449f-b0cf-a8afb9ebcfd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-effd8953-a560-449f-b0cf-a8afb9ebcfd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  Q_number  User_ID  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1        9   \n",
              "1  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1       18   \n",
              "2  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1       48   \n",
              "3  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1       54   \n",
              "4  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1       61   \n",
              "\n",
              "  Short_Answer                                        Long_Answer  MBTI  \n",
              "0          아니다  새로운 사람을 만나서 이야기를 나누고 마음이 통하는 친구가 되기까지의 과정은 많은 ...  INTJ  \n",
              "1      중립/모르겠다  저는 주기적으로는 새로운 친구들을 만들지 않습니다. 이유는 새로운 친구들을 사기기 ...  ENTJ  \n",
              "2          아니다  저는 굳이 새로운 친구들을 만들려고 하지 않아요. 원래 친하던 친구들과 만나는 게 ...  ESFJ  \n",
              "3          아니다  저는 주기적으로 새로운 친구를 잘 만드는 편은 아닙니다. 최근에 재택근무를 하면서 ...  ENFJ  \n",
              "4          그렇다  새로운 친구를 만들면서 그들의 일상을 듣고 나누는 것이 재미있습니다. 새로운 사람을...  ESFJ  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "training = pd.read_excel(os.path.join(root_dir, train2_dir))\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "# training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Q_number', 'User_ID', 'Short_Answer', 'Long_Answer', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_aEeyvrr-I41",
        "outputId": "04a7003f-d8b6-4857-90f0-2cde65c11fc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-289b1ece-4bb5-4cf3-abf6-8e066885c231\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Q_number</th>\n",
              "      <th>Short_Answer</th>\n",
              "      <th>Long_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>친구를 만들 상황에 새로운 친구를 만듭니다. 의도적으로나 꼭 주기적으로 새로운 친구...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>주기적으로 새로운 친구를 만들지는 않습니다. 자연스러운 만남을 추구하는 스타일로 업...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>새로운 친구를 만들기 위해 주기적으로 노력을 하진 않지만 같은 사람들과의 만남이 무...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>아니다</td>\n",
              "      <td>주기적으로는 아니나 새로운 친구를 만들고, 만나는 것엔 부담이 없다. 아이가 있어 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>1</td>\n",
              "      <td>중립/모르겠다</td>\n",
              "      <td>저는 기존 친구들과 만나기도 바쁘고 하지만 친구가 새로운 친구 소개해 주면 반갑게 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-289b1ece-4bb5-4cf3-abf6-8e066885c231')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-289b1ece-4bb5-4cf3-abf6-8e066885c231 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-289b1ece-4bb5-4cf3-abf6-8e066885c231');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   User_ID                                           Question  Q_number  \\\n",
              "0        1  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "1        2  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "2        3  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "3        4  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "4        5  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...         1   \n",
              "\n",
              "  Short_Answer                                        Long_Answer  \n",
              "0          아니다  친구를 만들 상황에 새로운 친구를 만듭니다. 의도적으로나 꼭 주기적으로 새로운 친구...  \n",
              "1          아니다  주기적으로 새로운 친구를 만들지는 않습니다. 자연스러운 만남을 추구하는 스타일로 업...  \n",
              "2      중립/모르겠다  새로운 친구를 만들기 위해 주기적으로 노력을 하진 않지만 같은 사람들과의 만남이 무...  \n",
              "3          아니다  주기적으로는 아니나 새로운 친구를 만들고, 만나는 것엔 부담이 없다. 아이가 있어 ...  \n",
              "4      중립/모르겠다  저는 기존 친구들과 만나기도 바쁘고 하지만 친구가 새로운 친구 소개해 주면 반갑게 ...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_excel(os.path.join(root_dir, test_dir))\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Data_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "# testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['User_ID', 'Question', 'Q_number', 'Short_Answer', 'Long_Answer']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8XkroC-I43"
      },
      "source": [
        "#### 4-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4ZwKwz4-I44"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Long_Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 203 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "probabilities = dict()\n",
        "labels = []\n",
        "user_ids = []\n",
        "\n",
        "cur_q_num = 1\n",
        "model = torch.load(f\"model_1.pt\")['model']\n",
        "model.eval()\n",
        "model.cuda()\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  short_answer = training['Short_Answer'][idx]\n",
        "  long_answer = training['Long_Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "  user_id = training['User_ID'][idx]\n",
        "  q_num = training['Q_number']\n",
        "\n",
        "  if cur_q_num != q_num:\n",
        "    cur_q_num = q_num\n",
        "    del model\n",
        "    model = torch.load(f\"model_{q_num}.pt\")['model']\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      long_answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  prob = model(encodings['input_ids'], encodings['attention_mask'], short_answer)\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "  \n",
        "  if user_id in probabilities.keys():\n",
        "    probabilities[user_id].append(prob)\n",
        "  else:\n",
        "    probabilities[user_id] = [prob]\n",
        "  \n",
        "  labels.append(torch.tensor([mbti]))\n",
        "  user_ids.append(torch.tensor([[user_id]]))\n",
        "\n",
        "del model\n",
        "\n",
        "prob_list = []\n",
        "for user in user_ids:\n",
        "  user = int(user[0][0])\n",
        "  for prob_in in probabilitixes[user]:\n",
        "    prob_list.append(torch.from_numpy(prob_in))\n",
        "\n",
        "# Convert to tensors.\n",
        "probabilities = torch.cat(prob_list, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "user_ids = torch.cat(user_ids, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFMaf0nN-I44"
      },
      "outputs": [],
      "source": [
        "print(probabilities[0])\n",
        "print(type(probabilities[0]))\n",
        "print(labels[0])\n",
        "print(user_ids[0])\n",
        "\n",
        "print(len(probabilities), len(labels), len(q_nums), len(user_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaP8Iw37-I47"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s4kp3Z3I-I47"
      },
      "source": [
        "#### 4-2. Dataset & Dataloader Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "jbFY57GC-I48",
        "outputId": "7b4c4ee9-6d79-4bd4-ee39-1d0fa86ee3a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n###\\ntrain_dataloader = DataLoader(\\n    train_dataset,\\n    sampler = RandomSampler(train_dataset),\\n    batch_size = batch_size\\n)\\n\\nval_dataloader = DataLoader(\\n    val_dataset,\\n    sampler = RandomSampler(val_dataset),\\n    batch_size = batch_size\\n)\\n###\\n'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset = TensorDataset(probabilities, labels, user_ids)\n",
        "\n",
        "batch_size = 60\n",
        "\n",
        "'''\n",
        "###\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "print(f\"lengths are {train_size}:{val_size}\")\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "###\n",
        "'''\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    sampler = SequentialSampler(dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "'''\n",
        "###\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler = RandomSampler(val_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "###\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YXGkEtuP-I49"
      },
      "source": [
        "#### 4-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqdgqItA-I49"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIAggregator(nn.Module): # 모델마다 사이즈 달라질 수도 있음\n",
        "  def __init__ (self,\n",
        "                hidden_size=1, # ?\n",
        "                num_classes=2):\n",
        "    super(MBTIAggregator, self).__init__()\n",
        "\n",
        "    self.lin = nn.Linear(hidden_size, 8)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(8, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "    '''\n",
        "    self.linstr = nn.Linear(hidden_size, (int)(hidden_size * (127 / 128)))\n",
        "    self.linsrt = nn.Linear(2, hidden_size - (int)(hidden_size * (127 / 128)))\n",
        "    self.lin = nn.Linear(hidden_size, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(128, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "    '''\n",
        "    \n",
        "  def forward(self, probabilities):\n",
        "\n",
        "    lin_output = self.lin(probabilities)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "    \n",
        "    return self.classifier(lin2_output)\n",
        "    '''\n",
        "    linstr_output = self.linstr(dr_output)\n",
        "    linsrt_output = self.linsrt(short_answers)\n",
        "\n",
        "    srt_added = torch.cat((linstr_output, linsrt_output), dim=1)\n",
        "\n",
        "    lin_output = self.lin(srt_added)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "\n",
        "    return self.classifier(lin2_output)\n",
        "    '''\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "learning_rate = 2e-5\n",
        "epochs = 10\n",
        "\n",
        "for (sort_list, sort) in zip([IE_list, SN_list, TF_list, JP_list], ['IE', 'SN', 'TF', 'JP']):\n",
        "  total_steps = len(dataloader) * epcohs\n",
        "  warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "  print(f\"model_{sort}\")\n",
        "  model = MBTIAggregator(hidden_size=len(sort_list))\n",
        "\n",
        "  optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                lr = learning_rate,\n",
        "                eps = 1e-8\n",
        "              )\n",
        "        \n",
        "  scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "\n",
        "  torch.save({\n",
        "          'model': model,\n",
        "          'optimizer': optimizer,\n",
        "          'scheduler': scheduler\n",
        "          }, f\"model_{sort}.pt\")\n",
        "\n",
        "  del(model, optimizer, scheduler)\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bilNJDBI-I4-"
      },
      "source": [
        "#### 4-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbKe1rwV-I4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqCt5JPY-I4_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "###\n",
        "cnt = 1\n",
        "\n",
        "for (idx_list, sort) in zip([IE_list, SN_list, TF_list, JP_list], ['IE', 'SN', 'TF', 'JP']):\n",
        "  for i in idx_list:\n",
        "    # if i != 49:\n",
        "    #   cnt += 1\n",
        "    #   continue\n",
        "    \n",
        "    if i > 48:\n",
        "      iepochs = epochs[1]\n",
        "    else:\n",
        "      iepochs = epochs[0]\n",
        "\n",
        "    print(f\"\\n======= model {sort}_{cnt} =======\")\n",
        "\n",
        "    loading = torch.load(f\"model_{i}.pt\")\n",
        "    model = loading['model']\n",
        "    optimizer = loading['optimizer']\n",
        "    scheduler = loading['scheduler']\n",
        "    \n",
        "    model.train()\n",
        "    model.cuda()\n",
        "  \n",
        "    for epoch in range(iepochs):\n",
        "      print(f\"\\n======= {epoch + 1} / {iepochs} =======\")\n",
        "      train_acc = 0.0\n",
        "      train_step = 0\n",
        "      val_acc = 0.0\n",
        "      val_step = 0\n",
        "\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "        b_input_id = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_short = batch[2].float().to(device)\n",
        "        \n",
        "        if sort == 'IE':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[0] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'SN':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[1] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'TF':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[2] , batch[3].tolist()))).float().to(device)\n",
        "        else:\n",
        "          b_label = torch.tensor(list(map(lambda x: x[3] , batch[3].tolist()))).float().to(device)\n",
        "        \n",
        "        b_q_num = int(batch[4][0])\n",
        "\n",
        "        if b_q_num != i:\n",
        "          continue\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        b_out = model(b_input_id, b_input_mask, b_short)\n",
        "        loss = loss_fn(b_out, b_label)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_acc += calc_accuracy(b_out, b_label)\n",
        "        train_step += 1\n",
        "\n",
        "        if step > 15000:\n",
        "          print(f\"epoch {epoch + 1} batch id {step} loss {loss.data.cpu().numpy()} train acc {train_acc / train_step}\")\n",
        "      \n",
        "      model.eval()\n",
        "      for step, batch in enumerate(val_dataloader):\n",
        "        b_input_id = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_short = batch[2].float().to(device)\n",
        "\n",
        "        if sort == 'IE':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[0] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'SN':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[1] , batch[3].tolist()))).float().to(device)\n",
        "        elif sort == 'TF':\n",
        "          b_label = torch.tensor(list(map(lambda x: x[2] , batch[3].tolist()))).float().to(device)\n",
        "        else:\n",
        "          b_label = torch.tensor(list(map(lambda x: x[3] , batch[3].tolist()))).float().to(device)\n",
        "        \n",
        "        b_q_num = int(batch[4][0])\n",
        "\n",
        "        if b_q_num != i:\n",
        "          continue\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          b_out = model(b_input_id, b_input_mask, b_short)\n",
        "        \n",
        "        val_acc += calc_accuracy(b_out, b_label)\n",
        "        val_step += 1\n",
        "\n",
        "      print(f\"epoch {epoch + 1} size {val_step} validation acc {val_acc / val_step}\")\n",
        "    \n",
        "    torch.save({\n",
        "            'model': model,\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler\n",
        "            }, f\"model_{i}.pt\")\n",
        "\n",
        "    del(model, optimizer, scheduler)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cnt += 1\n",
        "\n",
        "###\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4o2YltM-I5A"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= {epoch + 1} / {epcohs} =======\")\n",
        "  train_acc = 0.0\n",
        "  train_step = 0\n",
        "\n",
        "  for step, batch in enumerate(dataloader):\n",
        "    b_probabilities = batch[0]\n",
        "    b_label = batch[1][0]\n",
        "    b_user_id = int(batch[2][0])\n",
        "\n",
        "    for sort in ['IE', 'SN', 'TF', 'JP']:\n",
        "      print(f\"======= model_{sort} =======\")\n",
        "\n",
        "      loading = torch.load(f\"model_{sort}.pt\")\n",
        "\n",
        "      model = loading['model']\n",
        "      optimizer = loading['optimizer']\n",
        "      scheduler = loading['scheduler']\n",
        "\n",
        "      model.train()\n",
        "      model.cuda()\n",
        "\n",
        "      if sort == 'IE':\n",
        "        in_label = b_label[0]\n",
        "        for q in IE_list:\n",
        "          in_probabilities[]\n",
        "      \n",
        "      elif sort == 'SN':\n",
        "        in_label = b_label[1]\n",
        "\n",
        "      elif sort == 'TF':\n",
        "        in_label = b_label[2]\n",
        "      \n",
        "      else:\n",
        "        in_label = b_label[3]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for sort in ['IE', 'SN', 'TF', 'JP']:\n",
        "  print(f\"======= model_{sort} =======\")\n",
        "\n",
        "  loading = torch.load(f\"model_{sort}.pt\")\n",
        "  \n",
        "  model = loading['model']\n",
        "  optimizer = loading['optimizer']\n",
        "  scheduler = loading['scheduler']\n",
        "\n",
        "  model.train()\n",
        "  model.cuda()\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    print(f\"\\n======= {epoch + 1} / {epcohs} =======\")\n",
        "    train_acc = 0.0\n",
        "    train_step = 0\n",
        "\n",
        "    for step, batch in enumerate(dataloader):\n",
        "      b_probabilities = batch[0]\n",
        "      b_probabilities = torch.cat(b_probabilities, dim=0).to(device)\n",
        "      \n",
        "      if sort == 'IE':\n",
        "        b_label = batch[1][0][0]\n",
        "      elif sort == 'SN':\n",
        "        b_label = batch[1][0][1]\n",
        "      elif sort == 'TF':\n",
        "        b_label = batch[1][0][2]\n",
        "      else:\n",
        "        b_label = batch[1][0][3]\n",
        "      \n",
        "      b_user_id = int(batch[2][0])\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      b_out = model(b_probabilities) # 크기 확인 필요\n",
        "      loss = loss_fn(b_out, b_label)\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      train_acc += calc_accurach(b_out, b_label)\n",
        "      train_step += 1\n",
        "    \n",
        "      torch.save({\n",
        "              'model': model,\n",
        "              'optimizer': optimizer,\n",
        "              'scheduler': scheduler\n",
        "              }, f\"model_{sort}.pt\")\n",
        "\n",
        "    del(model, optimizer, scheduler)\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H7oC3cUP-I5B"
      },
      "source": [
        "#### 4-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noc_09oq-I5B",
        "outputId": "cae7a338-26dd-48c0-ee9a-283782577ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Long_Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "short_answers = []\n",
        "q_nums = []\n",
        "user_ids = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  short_answer = testing['Short_Answer'][idx]\n",
        "  long_answer = testing['Long_Answer'][idx]\n",
        "  q_num = testing['Q_number'][idx]\n",
        "  user_id = testing['User_ID'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      long_answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  short_answers.append(torch.tensor(short_answer_to_vec(short_answer)))\n",
        "  q_nums.append(torch.tensor([[q_num]]))\n",
        "  user_ids.append(torch.tensor([[user_id]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "short_answers = torch.cat(short_answers, dim=0)\n",
        "q_nums = torch.cat(q_nums, dim=0)\n",
        "user_ids = torch.cat(user_ids, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZlCfYvV-I5B"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset = TensorDataset(input_ids, att_masks, short_answers, q_nums, user_ids)\n",
        "\n",
        "batch_size = 1 # each person, each question\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    sampler = SequentialSampler(dataset),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ut4N4Ta-I5D"
      },
      "outputs": [],
      "source": [
        "probs = dict()\n",
        "preds = dict()\n",
        "users = []\n",
        "\n",
        "users_IE = dict()\n",
        "users_SN = dict()\n",
        "users_TF = dict()\n",
        "users_JP = dict()\n",
        "\n",
        "cur_q = 0\n",
        "\n",
        "for step, batch in enumerate(dataloader):\n",
        "  if step % 60 == 0:\n",
        "    print(f\"-------------- {(step)/60 + 1} / {len(dataloader)/60} --------------\")\n",
        "  \n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_short = batch[2].float().to(device)\n",
        "  b_q_num = int(batch[3][0])\n",
        "  b_user_id = int(batch[4][0])\n",
        "\n",
        "  if not b_user_id in users:\n",
        "    users.append(b_user_id)\n",
        "  \n",
        "  if cur_q != b_q_num:\n",
        "    cur_q = b_q_num\n",
        "\n",
        "    model = torch.load(f\"model_{b_q_num}.pt\")['model']\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    b_out = model(b_input_id, b_input_mask, b_short)\n",
        "  \n",
        "  b_out_np = b_out.detach().cpu().numpy().tolist()[0]\n",
        "\n",
        "  if b_q_num in IE_list:\n",
        "    if b_user_id in users_IE.keys():\n",
        "      users_IE[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_IE[b_user_id] = [b_out_np[1]]\n",
        "    \n",
        "  elif b_q_num in SN_list:\n",
        "    if b_user_id in users_SN.keys():\n",
        "      users_SN[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_SN[b_user_id] = [b_out_np[1]]\n",
        "  \n",
        "  elif b_q_num in TF_list:\n",
        "    if b_user_id in users_TF.keys():\n",
        "      users_TF[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_TF[b_user_id] = [b_out_np[1]]\n",
        "  \n",
        "  else:\n",
        "    if b_user_id in users_JP.keys():\n",
        "      users_JP[b_user_id].append(b_out_np[1])\n",
        "    else:\n",
        "      users_JP[b_user_id] = [b_out_np[1]]\n",
        "\n",
        "for user in users:  \n",
        "  prob_IE, prob_SN, prob_TF, prob_JP = users_IE[user], users_SN[user], users_TF[user], users_JP[user]\n",
        "\n",
        "  model_IE = torch.load(f\"model_IE.pt\")['model']\n",
        "  model_IE.eval()\n",
        "  model_IE.cuda()\n",
        "  \n",
        "  prob_IE = model_IE(torch.cat(prob_IE, dim=0))\n",
        "  prob_IE = prob_IE.detach().cpu().numpy().float()\n",
        "\n",
        "  del model_IE\n",
        "\n",
        "  model_SN = torch.load(\"model_SN.pt\")['model']\n",
        "  model_SN.eval()\n",
        "  model_SN.cuda()\n",
        "\n",
        "  prob_SN = model_SN(torch.cat(prob_SN, dim=0))\n",
        "  prob_SN = prob_SN.detach().cpu().numpy().float()\n",
        "  \n",
        "  del model_SN\n",
        "\n",
        "  model_TF = torch.load(\"model_TF.pt\")['model']\n",
        "  model_TF.eval()\n",
        "  model_TF.cuda()\n",
        "\n",
        "  prob_TF = model_TF(torch.cat(prob_TF, dim=0))\n",
        "  prob_TF = prob_TF.detach().cpu().numpy().float()\n",
        "\n",
        "  del model_TF\n",
        "\n",
        "  model_JP = torch.load(\"model_JP.pt\")['model']\n",
        "  model_JP.eval()\n",
        "  model_JP.cuda()\n",
        "\n",
        "  prob_JP = model_JP(torch.cat(prob_JP, dim=0))\n",
        "  prob_JP = prob_JP.detach().cpu().numpy().float()\n",
        "\n",
        "  del model_JP\n",
        "\n",
        "  probs[user] = [prob_IE, prob_SN, prob_TF, prob_JP]\n",
        "  preds[user] = list(map(lambda x: 1 if x > 0.5 else 0, [prob_IE, prob_SN, prob_TF, prob_JP]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be1_MkBr-I5E",
        "outputId": "238656c3-511d-4693-d84d-b9045600c8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120 120 120 120\n"
          ]
        }
      ],
      "source": [
        "preds_ls = []\n",
        "probs_ls = []\n",
        "\n",
        "for user in users:\n",
        "    preds_ls.append(preds[user])\n",
        "    probs_ls.append(probs[user])\n",
        "\n",
        "preds_df = {'User_ID': users, 'I/E': list(map(lambda x:x[0], preds_ls)), 'S/N': list(map(lambda x:x[1], preds_ls)), 'T/F': list(map(lambda x:x[2], preds_ls)), 'J/P': list(map(lambda x:x[3], preds_ls))}\n",
        "preds_df = pd.DataFrame(data=preds_df)\n",
        "preds_df = preds_df.set_index('User_ID')\n",
        "preds_df.to_csv('result.csv')\n",
        "\n",
        "probs_df = {'User_ID': users, 'I/E': list(map(lambda x:x[0], probs_ls)), 'S/N': list(map(lambda x:x[1], probs_ls)), 'T/F': list(map(lambda x:x[2], probs_ls)), 'J/P': list(map(lambda x:x[3], probs_ls))}\n",
        "probs_df = pd.DataFrame(data=probs_df)\n",
        "probs_df = probs_df.set_index('User_ID')\n",
        "probs_df.to_csv('result_prob.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
