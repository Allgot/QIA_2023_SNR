{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfVq3nqAhea"
      },
      "source": [
        "### 0. Loading data\n",
        "#### We've attached the raw data. To use this, load the data by `pandas.read_excel()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "HzM3OkRHAu7U",
        "outputId": "9f28b671-568f-4b1b-817e-aae42c8d2dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-373c2134-636b-45cc-b17b-b111fb9dcde7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-373c2134-636b-45cc-b17b-b111fb9dcde7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-373c2134-636b-45cc-b17b-b111fb9dcde7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-373c2134-636b-45cc-b17b-b111fb9dcde7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# root_dir = '/content/drive/My Drive/QIA2023'\n",
        "root_dir = os.getcwd() + '/data/'\n",
        "questions_dir = 'Question.xlsx'\n",
        "train_dir = 'p1_train.csv'\n",
        "test_dir = 'p1_test.csv'\n",
        "\n",
        "model_IE_dir = 'model_IE.pt'\n",
        "model_SN_dir = 'model_SN.pt'\n",
        "model_TF_dir = 'model_TF.pt'\n",
        "model_JP_dir = 'model_JP.pt'\n",
        "\n",
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F6VEWREu_V62"
      },
      "source": [
        "### 1. Preprocessing\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QiYKNlnu3qIn"
      },
      "source": [
        "#### 1-1. Encoding MBTI Labels\n",
        "Since the lable is given as String type (e.g. ISTP), we have to convert it to vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB41Fus33pof"
      },
      "outputs": [],
      "source": [
        "def MBTI_to_vec(mbti):\n",
        "  if len(mbti) != 4:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[0] == 'I':\n",
        "    fst = [1, 0]\n",
        "  elif mbti[0] == 'E':\n",
        "    fst = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[1] == 'S':\n",
        "    snd = [1, 0]\n",
        "  elif mbti[1] == 'N':\n",
        "    snd = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "\n",
        "  if mbti[2] == 'T':\n",
        "    trd = [1, 0]\n",
        "  elif mbti[2] == 'F':\n",
        "    trd = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "  \n",
        "  if mbti[3] == 'J':\n",
        "    fth = [1, 0]\n",
        "  elif mbti[3] == 'P':\n",
        "    fth = [0, 1]\n",
        "  else:\n",
        "    raise Exception(f\"Not valid: {mbti}\")\n",
        "  \n",
        "  return [fst, snd, trd, fth]\n",
        "\n",
        "# Unit Test\n",
        "assert(MBTI_to_vec(\"ISTJ\") == [[1, 0], [1, 0], [1, 0], [1, 0]])\n",
        "assert(MBTI_to_vec(\"ENFP\") == [[0, 1], [0, 1], [0, 1], [0, 1]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4nPMPB_oNa"
      },
      "source": [
        "### 2. Model Proposal\n",
        "#### BERT-based model\n",
        "Please refer to the report!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhmqy-tM25V9"
      },
      "source": [
        "### 3. Implementation of the BERT-based Model\n",
        "We decide to use pre-trained BERT model as the base model, so let's implement it!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V80QZhIB6bQA"
      },
      "source": [
        "#### 3-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1QeW-w4U7FaE",
        "outputId": "0064d25c-f1b5-4d3f-92d8-d3b810d25532"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-86928478-695b-4819-904c-21ca4009d2eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86928478-695b-4819-904c-21ca4009d2eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86928478-695b-4819-904c-21ca4009d2eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86928478-695b-4819-904c-21ca4009d2eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Uj0IDoIeBqc5",
        "outputId": "ec83fc87-5503-4caa-fd26-9034f0dde8a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1c8464b-d352-4987-8285-8ca169af058e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c8464b-d352-4987-8285-8ca169af058e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1c8464b-d352-4987-8285-8ca169af058e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1c8464b-d352-4987-8285-8ca169af058e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...   \n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...   \n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...   \n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.   \n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.   \n",
              "\n",
              "                                              Answer  MBTI  \n",
              "0  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...  INFP  \n",
              "1  <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...  INFP  \n",
              "2  <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...  INFP  \n",
              "3  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...  INFP  \n",
              "4  <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...  INFP  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "\n",
        "training = pd.read_csv(os.path.join(root_dir, train_dir), encoding=\"CP949\")\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Answer', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u5J9Zg-VKKmM",
        "outputId": "a316f7ff-441a-440e-af74-bc52a354b2b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ee5f87ec-d575-48e1-8eb0-ec83c5f07140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.</td>\n",
              "      <td>&lt;아니다&gt; 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...</td>\n",
              "      <td>&lt;중립&gt; 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...</td>\n",
              "      <td>&lt;그렇다&gt; 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.</td>\n",
              "      <td>&lt;그렇다&gt; 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.</td>\n",
              "      <td>&lt;중립&gt; 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee5f87ec-d575-48e1-8eb0-ec83c5f07140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee5f87ec-d575-48e1-8eb0-ec83c5f07140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee5f87ec-d575-48e1-8eb0-ec83c5f07140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0                     마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.   \n",
              "1  조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...   \n",
              "2  단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...   \n",
              "3    일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.   \n",
              "4         대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.   \n",
              "\n",
              "                                              Answer  \n",
              "0  <아니다> 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...  \n",
              "1  <중립> 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...  \n",
              "2  <그렇다> 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...  \n",
              "3  <그렇다> 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...  \n",
              "4  <중립> 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_csv(os.path.join(root_dir, test_dir), encoding=\"CP949\")\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['Question', 'Answer']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VUjMGHr950gO"
      },
      "source": [
        "#### 3-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "61c019a689574884bc05001cb9c1ccaf",
            "afcdfdd961154c438e311bf21ca9251b",
            "c62cdcd8b89c4c29852c83bd7ed5039b",
            "bee618c6b25f427cb89ecf50f2014f0a",
            "e8d840714f184b91914d7a4eb7cc83cf",
            "cc3e3d4162884d24bdcffc90dd0ec342",
            "e3b1f39d3ef946a584e20ef866dad68f",
            "b62be928a72444e0a62a710b97c0a448",
            "a561895a74604d7b9b2dc1e2fc8977bc",
            "f2e73d5ee4a544fdbe5a19a91e1a6e66",
            "d7d70836251a4cd3a00d8e204e3b5845",
            "e08ea6bf1f7840d893d56b87f90c493d",
            "038fafb3656f40e990fa6ed1b50c769e",
            "e7fafc08f0a44ba0b0c8787be0d8a994",
            "9b9782e16c6c4c90b2f0b6ec74d173f8",
            "787972945ca240dba19400497f40f8da",
            "78826cc2909d4e3784970a2a33cd4da8",
            "8e552f369d8143838c5cd2b3a2d1ade7",
            "ea72dac4e45d4a11922a021623a9f61c",
            "794b7f421a294afd9292ac5753d691af",
            "366c8c5afc3d44f3967179dd05d7ba22",
            "a11eb887e8da44a9a90c3b5bd29313f7",
            "7b883e028819448b9f4c86ea4c4da45b",
            "a9ef141849ca4015990d1d882679cf2d",
            "e1915d29a39647598ef924d91a192c07",
            "ed7435492f634be4b94e571d86abcc25",
            "2c2a87b00f56464d8a525ef85730811f",
            "ed22766ce8aa478689d14e2669ea8f4a",
            "3d19659167fc40518e98c3cdde65384a",
            "566d868ceab14a21abbabdf7408c1161",
            "9cb932d402504b5989e57d78fa1b3140",
            "82b81824fce74e7cbfff7fe71662e5dd",
            "383a387effcb4435a67f2b1659685879"
          ]
        },
        "id": "NXzVx931Cz1n",
        "outputId": "c8986184-d101-4d9c-b5ec-a2c4a64474ac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61c019a689574884bc05001cb9c1ccaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e08ea6bf1f7840d893d56b87f90c493d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b883e028819448b9f4c86ea4c4da45b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 206 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  question = training['Question'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYX7jj944Nl",
        "outputId": "bbf5bfe0-7440-467b-e853-ecd71284d271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2, 25753, 14567, 28897, 18069, 14526,  2033, 19742, 22742,  8082,\n",
            "        31724,  3463, 32771,  8061, 19773, 16941, 24296,  8055,  2016,     3,\n",
            "         2030, 15345,  2032, 18430,  3463,  5724,  8423, 26850, 20699, 14204,\n",
            "        15916, 17729, 25878, 18895, 14045, 27024,  8107, 28669,  8120,  6266,\n",
            "        24832,  2016,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 0])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "11520 11520 11520\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1tvttyE7u-u"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YfufvCqV8hAk"
      },
      "source": [
        "#### 3-2. Data Split\n",
        "Currently, we do not have the answers for testing dataset, so we must split the training data to evaluate our model. (8:1:1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpBRC3bE81Yt",
        "outputId": "5b385f16-3780-418e-85f8-7f1552c52c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lengths are 10368:576:576\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, labels_JP)\n",
        "\n",
        "train_size = int(0.9 * len(dataset_IE))\n",
        "val_size = int(0.05 * len(dataset_IE))\n",
        "test_size = len(dataset_IE) - train_size - val_size\n",
        "\n",
        "print(f\"lengths are {train_size}:{val_size}:{test_size}\")\n",
        "\n",
        "# Split into train dataset, validation dataset and test dataset.\n",
        "train_dataset_IE, val_dataset_IE, test_dataset_IE = random_split(dataset_IE, [train_size, val_size, test_size])\n",
        "train_dataset_SN, val_dataset_SN, test_dataset_SN = random_split(dataset_SN, [train_size, val_size, test_size])\n",
        "train_dataset_TF, val_dataset_TF, test_dataset_TF = random_split(dataset_TF, [train_size, val_size, test_size])\n",
        "train_dataset_JP, val_dataset_JP, test_dataset_JP = random_split(dataset_JP, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataloader_IE = DataLoader(\n",
        "    train_dataset_IE,\n",
        "    sampler = RandomSampler(train_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_IE = DataLoader (\n",
        "    val_dataset_IE,\n",
        "    sampler = SequentialSampler(val_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_IE = DataLoader (\n",
        "    test_dataset_IE,\n",
        "    sampler = SequentialSampler(test_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_SN = DataLoader(\n",
        "    train_dataset_SN,\n",
        "    sampler = RandomSampler(train_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_SN = DataLoader (\n",
        "    val_dataset_SN,\n",
        "    sampler = SequentialSampler(val_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_SN = DataLoader (\n",
        "    test_dataset_SN,\n",
        "    sampler = SequentialSampler(test_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_TF = DataLoader(\n",
        "    train_dataset_TF,\n",
        "    sampler = RandomSampler(train_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_TF = DataLoader (\n",
        "    val_dataset_TF,\n",
        "    sampler = SequentialSampler(val_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_TF = DataLoader (\n",
        "    test_dataset_TF,\n",
        "    sampler = SequentialSampler(test_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_JP = DataLoader(\n",
        "    train_dataset_JP,\n",
        "    sampler = RandomSampler(train_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_JP = DataLoader (\n",
        "    val_dataset_JP,\n",
        "    sampler = SequentialSampler(val_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_JP = DataLoader (\n",
        "    test_dataset_JP,\n",
        "    sampler = SequentialSampler(test_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MiFi795-0LRR"
      },
      "source": [
        "#### 3-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bXQ6VK10S-2",
        "outputId": "d351ae58-428b-4c22-81b4-25ac38c1141e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.lin = nn.Linear(hidden_size, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "\n",
        "    # Model 0.\n",
        "    # self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    # Model 1.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.lin2 = nn.Linear(256, 128)\n",
        "    # self.lin3 = nn.Linear(128, 64)\n",
        "    # self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    # Model 2.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.lin2 = nn.Linear(256, 128)\n",
        "    # self.lin3 = nn.Linear(128, 64)\n",
        "    # self.lin4 = nn.Linear(64, num_classes)\n",
        "    # self.classifier = nn.Softmax(dim=0)\n",
        "\n",
        "    # Model 3.\n",
        "    # self.lin = nn.Linear(hidden_size, 512)\n",
        "    # self.lin2 = nn.Linear(512, 256)\n",
        "    # self.lin3 = nn.Linear(256, 64)\n",
        "    # self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    # Model 4.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.sig = nn.Sigmoid()\n",
        "    # self.lin2 = nn.Linear(256, 64)\n",
        "    # self.sig2 = nn.Sigmoid()\n",
        "    # self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    # Model 5.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.relu = nn.ReLU()\n",
        "    # self.lin2 = nn.Linear(256, 64)\n",
        "    # self.relu2 = nn.ReLU()\n",
        "    # self.lin3 = nn.Linear(64, num_classes)\n",
        "    # self.classifier = nn.Sigmoid()\n",
        "\n",
        "    # Model 6.\n",
        "    # self.lin = nn.Linear(hidden_size, 128)\n",
        "    # self.relu = nn.ReLU()\n",
        "    # self.lin2 = nn.Linear(128, num_classes)\n",
        "    # self.classifier = nn.Sigmoid()\n",
        "\n",
        "    # Model 7.\n",
        "    # self.lin = nn.Linear(hidden_size, num_classes)\n",
        "    # self.classifier = nn.Sigmoid()\n",
        "\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "\n",
        "    lin_output = self.lin(dr_output)\n",
        "    return self.classifier(lin_output)\n",
        "\n",
        "    # Model 0.\n",
        "    # return self.classifier(dr_output)\n",
        "\n",
        "    # Model 1.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # lin2_output = self.lin2(lin_output)\n",
        "    # lin3_output = self.lin3(lin2_output)\n",
        "    # return self.classifier(lin3_output)\n",
        "\n",
        "    # Model 2.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # lin2_output = self.lin2(lin_output)\n",
        "    # lin3_output = self.lin3(lin2_output)\n",
        "    # lin4_output = self.lin4(lin3_output)\n",
        "    # return self.classifier(lin4_output)\n",
        "\n",
        "    # Model 3.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # lin2_output = self.lin2(lin_output)\n",
        "    # lin3_output = self.lin3(lin2_output)\n",
        "    # return self.classifier(lin3_output)\n",
        "\n",
        "    # Model 4.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # sig_output = self.sig(lin_output)\n",
        "    # lin2_output = self.lin2(sig_output)\n",
        "    # sig2_output = self.sig2(lin2_output)\n",
        "    # return self.classifier(lin2_output)\n",
        "\n",
        "    # Model 5.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # relu_output = self.relu(lin_output)\n",
        "    # lin2_output = self.lin2(relu_output)\n",
        "    # relu2_output = self.relu2(lin2_output)\n",
        "    # lin3_output = self.lin3(relu2_output)\n",
        "    # return self.classifier(lin3_output)\n",
        "\n",
        "    # Model 6.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # relu_output = self.relu(lin_output)\n",
        "    # lin2_output = self.lin2(relu_output)\n",
        "    # return self.classifier(lin2_output)\n",
        "\n",
        "    # Model 7.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # return self.classifier(lin_output)\n",
        "\n",
        "model_bert_IE = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert_IE, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert_SN, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert_TF, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert_JP, dr_rate = 0.3)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters_IE = [\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_SN = [\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_TF = [\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_JP = [\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "learning_rate = 2e-5\n",
        "\n",
        "optimizer_IE = AdamW(optimizer_grouped_parameters_IE,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = AdamW(optimizer_grouped_parameters_SN,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = AdamW(optimizer_grouped_parameters_TF,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = AdamW(optimizer_grouped_parameters_JP,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4 # 2 or 4\n",
        "\n",
        "total_steps = len(train_dataloader_IE) * epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "scheduler_IE = get_cosine_schedule_with_warmup(optimizer_IE, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_SN = get_cosine_schedule_with_warmup(optimizer_SN, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_TF = get_cosine_schedule_with_warmup(optimizer_TF, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_JP = get_cosine_schedule_with_warmup(optimizer_JP, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o4aI0xph5XZY"
      },
      "source": [
        "#### 3-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96CmUo_RMZ5I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N7-Z2Fw6MTHx"
      },
      "source": [
        "##### 3-4-1. I vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge0ob0hQ6iI6",
        "outputId": "a71803ec-be63-416e-e190-794e45955e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : 1 / 4 =======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-53-e920b4d27860>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.classifier(lin_output)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.6359407901763916 train acc 0.75\n",
            "epoch 1 batch id 129 loss 0.6607937812805176 train acc 0.49660852713178294\n",
            "epoch 1 batch id 257 loss 0.6595480442047119 train acc 0.498784046692607\n",
            "epoch 1 batch id 385 loss 0.713675856590271 train acc 0.5128246753246753\n",
            "epoch 1 batch id 513 loss 0.6880520582199097 train acc 0.5237573099415205\n",
            "epoch 1 batch id 641 loss 0.64157634973526 train acc 0.5350039001560063\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 1 train acc 0.5347222222222222\n",
            "epoch 1 validation acc 0.6197916666666666\n",
            "\n",
            "======= I/E : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7934859991073608 train acc 0.4375\n",
            "epoch 2 batch id 129 loss 0.6510183811187744 train acc 0.6017441860465116\n",
            "epoch 2 batch id 257 loss 0.6619061231613159 train acc 0.6116245136186771\n",
            "epoch 2 batch id 385 loss 0.4731528162956238 train acc 0.6233766233766234\n",
            "epoch 2 batch id 513 loss 0.6018325090408325 train acc 0.6270711500974658\n",
            "epoch 2 batch id 641 loss 0.6540859341621399 train acc 0.6312402496099844\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 2 train acc 0.6318479938271605\n",
            "epoch 2 validation acc 0.6284722222222222\n",
            "\n",
            "======= I/E : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6631679534912109 train acc 0.5625\n",
            "epoch 3 batch id 129 loss 0.5746456384658813 train acc 0.7437015503875969\n",
            "epoch 3 batch id 257 loss 0.60837322473526 train acc 0.7354085603112841\n",
            "epoch 3 batch id 385 loss 0.734930694103241 train acc 0.7362012987012987\n",
            "epoch 3 batch id 513 loss 0.6430940628051758 train acc 0.7428118908382066\n",
            "epoch 3 batch id 641 loss 0.7609715461730957 train acc 0.7443447737909517\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 3 train acc 0.7446952160493827\n",
            "epoch 3 validation acc 0.640625\n",
            "\n",
            "======= I/E : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.4498610198497772 train acc 0.875\n",
            "epoch 4 batch id 129 loss 0.5514728426933289 train acc 0.8187984496124031\n",
            "epoch 4 batch id 257 loss 0.5931614637374878 train acc 0.8139591439688716\n",
            "epoch 4 batch id 385 loss 0.5420881509780884 train acc 0.8196428571428571\n",
            "epoch 4 batch id 513 loss 0.5887580513954163 train acc 0.8222465886939572\n",
            "epoch 4 batch id 641 loss 0.6251927018165588 train acc 0.8186427457098284\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 4 train acc 0.8180941358024691\n",
            "epoch 4 validation acc 0.6354166666666666\n",
            "\n",
            "======= I/E : Test =======\n",
            "Test Accuracy: 0.6267361111111112\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= I/E : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_IE.eval()\n",
        "  for step, batch in enumerate(val_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask)\n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_IE.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= I/E : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W1-saVsLleot"
      },
      "source": [
        "모델0: pooler_output -> Linear  \n",
        ": epochs = 4, Test Accuracy: 0.6154513888888888\n",
        "\n",
        "모델1: pooler_output -> Linear(256) -> Linear(128) -> Linear(64) -> Linear  \n",
        ": epochs = 4, Test Accuracy: 0.6362847222222222\n",
        "\n",
        "모델2: pooler_output -> Linear(256) -> Linear(128) -> Linear(64) -> Linear(2) -> Softmax  \n",
        ": epochs = 4, Test Accuracy: 0.6085069444444444\n",
        "\n",
        "모델3: pooler_output -> Linear(512) -> Linear(256) -> Linear(64) -> Linear  \n",
        ": epochs = 4, Test Accuracy: 0.6345486111111112  \n",
        "\n",
        "모델4: pooler_output -> Linear(256) -> Sigmoid -> Linear(64) -> Sigmoid -> Linear  \n",
        ": epochs = 4, Test Accuracy: 0.625\n",
        "\n",
        "모델5: pooler_output -> Linear(256) -> ReLU -> Linear(64) -> ReLU -> Linear(2) -> Sigmoid  \n",
        ": epochs = 4, Test Accuracy: 0.6145833333333334\n",
        "\n",
        "모델6: pooler_output -> Linear(128) -> ReLU -> Linear(2) -> Sigmoid  \n",
        ": epochs = 4, Test Accuracy: 0.4869791666666667\n",
        "\n",
        "모델7: pooler_output -> Linear(2) -> Sigmoid  \n",
        ": epochs = 4, Test Accuracy: 0.6137152777777778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bZNUr5wx8sP"
      },
      "outputs": [],
      "source": [
        "torch.save(model_IE, model_IE_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N-UvZfxF1FUv"
      },
      "source": [
        "##### 3-4-2. S vs. N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "lVHcA2R6Bj5v",
        "outputId": "f4071742-1dc8-4d4b-e309-e1d460b1e869"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-d716bda5a0af>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_IE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_IE' is not defined"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "del model_IE\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRQcTBAZ1Ez3",
        "outputId": "73705868-3ef4-43d3-c6c9-358d704e4d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= S/N : 1 / 4 =======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-53-e920b4d27860>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.classifier(lin_output)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.6561090350151062 train acc 0.5625\n",
            "epoch 1 batch id 129 loss 0.7160962820053101 train acc 0.5116279069767442\n",
            "epoch 1 batch id 257 loss 0.6556985378265381 train acc 0.5235894941634242\n",
            "epoch 1 batch id 385 loss 0.6088603734970093 train acc 0.5314935064935065\n",
            "epoch 1 batch id 513 loss 0.6628450155258179 train acc 0.5389863547758285\n",
            "epoch 1 batch id 641 loss 0.6282668113708496 train acc 0.5482644305772231\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 1 train acc 0.5482253086419753\n",
            "epoch 1 validation acc 0.5902777777777778\n",
            "\n",
            "======= S/N : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7458827495574951 train acc 0.5625\n",
            "epoch 2 batch id 129 loss 0.7295388579368591 train acc 0.6201550387596899\n",
            "epoch 2 batch id 257 loss 0.6125571727752686 train acc 0.6288910505836576\n",
            "epoch 2 batch id 385 loss 0.6020779609680176 train acc 0.6293831168831169\n",
            "epoch 2 batch id 513 loss 0.5244085192680359 train acc 0.628167641325536\n",
            "epoch 2 batch id 641 loss 0.6077920198440552 train acc 0.6310452418096724\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 2 train acc 0.6299189814814815\n",
            "epoch 2 validation acc 0.6197916666666666\n",
            "\n",
            "======= S/N : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5157619714736938 train acc 0.8125\n",
            "epoch 3 batch id 129 loss 0.5737255811691284 train acc 0.7349806201550387\n",
            "epoch 3 batch id 257 loss 0.6541610956192017 train acc 0.72568093385214\n",
            "epoch 3 batch id 385 loss 0.5550487637519836 train acc 0.7314935064935065\n",
            "epoch 3 batch id 513 loss 0.4659457504749298 train acc 0.7323343079922028\n",
            "epoch 3 batch id 641 loss 0.5220942497253418 train acc 0.7310842433697348\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 3 train acc 0.7321566358024691\n",
            "epoch 3 validation acc 0.6267361111111112\n",
            "\n",
            "======= S/N : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.5920111536979675 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.4128974378108978 train acc 0.7863372093023255\n",
            "epoch 4 batch id 257 loss 0.5330355763435364 train acc 0.7884241245136187\n",
            "epoch 4 batch id 385 loss 0.4213704764842987 train acc 0.7894480519480519\n",
            "epoch 4 batch id 513 loss 0.5042537450790405 train acc 0.7921539961013645\n",
            "epoch 4 batch id 641 loss 0.5658494234085083 train acc 0.7975819032761311\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 4 train acc 0.7985146604938271\n",
            "epoch 4 validation acc 0.625\n",
            "\n",
            "======= S/N : Test =======\n",
            "Test Accuracy: 0.6215277777777778\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= S/N : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_SN.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].float().to(device)\n",
        "\n",
        "    optimizer_SN.zero_grad()\n",
        "\n",
        "    b_out = model_SN(b_input_id, b_input_mask)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_SN.parameters(), 1.0)\n",
        "\n",
        "    optimizer_SN.step()\n",
        "    scheduler_SN.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= S/N : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_SN.eval()\n",
        "  for step, batch in enumerate(val_dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    b_out = model_SN(b_input_id, b_input_mask)\n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_SN.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= S/N : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctW-6Gb-yEZ5"
      },
      "outputs": [],
      "source": [
        "torch.save(model_SN, model_SN_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QM48-g2O2HDW"
      },
      "source": [
        "##### 3-4-3. T vs. F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyZtXrgLB7w1"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_SN\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leh7_j3l2HDY",
        "outputId": "026fc715-d692-4586-c0bc-7acd4b06c065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= T/F : 1 / 4 =======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-53-e920b4d27860>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.classifier(lin_output)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.7232190370559692 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.7479486465454102 train acc 0.499515503875969\n",
            "epoch 1 batch id 257 loss 0.6741865277290344 train acc 0.5133754863813229\n",
            "epoch 1 batch id 385 loss 0.8030481934547424 train acc 0.5194805194805194\n",
            "epoch 1 batch id 513 loss 0.6884487867355347 train acc 0.5281432748538012\n",
            "epoch 1 batch id 641 loss 0.7721391320228577 train acc 0.5357839313572543\n",
            "\n",
            "======= T/F : Validation =======\n",
            "epoch 1 train acc 0.5372299382716049\n",
            "epoch 1 validation acc 0.5954861111111112\n",
            "\n",
            "======= T/F : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6030490398406982 train acc 0.6875\n",
            "epoch 2 batch id 129 loss 0.5946832895278931 train acc 0.6172480620155039\n",
            "epoch 2 batch id 257 loss 0.6368663907051086 train acc 0.604328793774319\n",
            "epoch 2 batch id 385 loss 0.5814990997314453 train acc 0.610551948051948\n",
            "epoch 2 batch id 513 loss 0.5211884379386902 train acc 0.6193957115009746\n",
            "epoch 2 batch id 641 loss 0.750889778137207 train acc 0.6216848673946958\n",
            "\n",
            "======= T/F : Validation =======\n",
            "epoch 2 train acc 0.6206597222222222\n",
            "epoch 2 validation acc 0.5954861111111112\n",
            "\n",
            "======= T/F : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.657733142375946 train acc 0.5625\n",
            "epoch 3 batch id 129 loss 0.4277121126651764 train acc 0.7378875968992248\n",
            "epoch 3 batch id 257 loss 0.5065150856971741 train acc 0.7373540856031129\n",
            "epoch 3 batch id 385 loss 0.5196105241775513 train acc 0.7381493506493506\n",
            "epoch 3 batch id 513 loss 0.713841438293457 train acc 0.7395224171539961\n",
            "epoch 3 batch id 641 loss 0.4091625213623047 train acc 0.7412246489859594\n",
            "\n",
            "======= T/F : Validation =======\n",
            "epoch 3 train acc 0.7420910493827161\n",
            "epoch 3 validation acc 0.6284722222222222\n",
            "\n",
            "======= T/F : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.4734434485435486 train acc 0.875\n",
            "epoch 4 batch id 129 loss 0.4979211091995239 train acc 0.815406976744186\n",
            "epoch 4 batch id 257 loss 0.5218783617019653 train acc 0.8125\n",
            "epoch 4 batch id 385 loss 0.5005219578742981 train acc 0.8189935064935064\n",
            "epoch 4 batch id 513 loss 0.39537349343299866 train acc 0.8178606237816765\n",
            "epoch 4 batch id 641 loss 0.5904558897018433 train acc 0.8190327613104524\n",
            "\n",
            "======= T/F : Validation =======\n",
            "epoch 4 train acc 0.8185763888888888\n",
            "epoch 4 validation acc 0.6371527777777778\n",
            "\n",
            "======= T/F : Test =======\n",
            "Test Accuracy: 0.6319444444444444\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= T/F : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_TF.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].float().to(device)\n",
        "\n",
        "    optimizer_TF.zero_grad()\n",
        "\n",
        "    b_out = model_TF(b_input_id, b_input_mask)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_TF.parameters(), 1.0)\n",
        "\n",
        "    optimizer_TF.step()\n",
        "    scheduler_TF.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= T/F : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_TF.eval()\n",
        "  for step, batch in enumerate(val_dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    b_out = model_TF(b_input_id, b_input_mask)\n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_TF.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= T/F : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAC9NskL0dH4"
      },
      "outputs": [],
      "source": [
        "torch.save(model_TF, model_TF_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXSKggo2Hp6"
      },
      "source": [
        "##### 3-4-4. J vs. P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5MgXDxPB-ht"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_TF\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6uakYd-2Hp6",
        "outputId": "240746fb-8df7-4c2e-f6c8-b09ab4c0b070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= J/P : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.7527980804443359 train acc 0.375\n",
            "epoch 1 batch id 129 loss 0.7059968709945679 train acc 0.4791666666666667\n",
            "epoch 1 batch id 257 loss 0.7406200170516968 train acc 0.49464980544747084\n",
            "epoch 1 batch id 385 loss 0.7142237424850464 train acc 0.5003246753246753\n",
            "epoch 1 batch id 513 loss 0.6580074429512024 train acc 0.5043859649122807\n",
            "epoch 1 batch id 641 loss 0.7139447927474976 train acc 0.5084828393135725\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 1 train acc 0.5086805555555556\n",
            "epoch 1 validation acc 0.5017361111111112\n",
            "\n",
            "======= J/P : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7277507185935974 train acc 0.5\n",
            "epoch 2 batch id 129 loss 0.6368276476860046 train acc 0.5406976744186046\n",
            "epoch 2 batch id 257 loss 0.6004140377044678 train acc 0.5510700389105059\n",
            "epoch 2 batch id 385 loss 0.6674277782440186 train acc 0.5589285714285714\n",
            "epoch 2 batch id 513 loss 0.6724637746810913 train acc 0.5645711500974658\n",
            "epoch 2 batch id 641 loss 0.712556004524231 train acc 0.5733229329173167\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 2 train acc 0.5734953703703703\n",
            "epoch 2 validation acc 0.5416666666666666\n",
            "\n",
            "======= J/P : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5790579915046692 train acc 0.8125\n",
            "epoch 3 batch id 129 loss 0.4944325089454651 train acc 0.6468023255813954\n",
            "epoch 3 batch id 257 loss 0.6428264379501343 train acc 0.6536964980544747\n",
            "epoch 3 batch id 385 loss 0.48671698570251465 train acc 0.6616883116883117\n",
            "epoch 3 batch id 513 loss 0.5601004362106323 train acc 0.6641081871345029\n",
            "epoch 3 batch id 641 loss 0.5956019759178162 train acc 0.6661466458658346\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 3 train acc 0.6666666666666666\n",
            "epoch 3 validation acc 0.5052083333333334\n",
            "\n",
            "======= J/P : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.6010991930961609 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.5030874609947205 train acc 0.7587209302325582\n",
            "epoch 4 batch id 257 loss 0.49151933193206787 train acc 0.7609435797665369\n",
            "epoch 4 batch id 385 loss 0.6072123050689697 train acc 0.7592532467532468\n",
            "epoch 4 batch id 513 loss 0.4712899327278137 train acc 0.7607212475633528\n",
            "epoch 4 batch id 641 loss 0.5181556344032288 train acc 0.7609204368174727\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 4 train acc 0.7614776234567902\n",
            "epoch 4 validation acc 0.5017361111111112\n",
            "\n",
            "======= J/P : Test =======\n",
            "Test Accuracy: 0.6423611111111112\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= J/P : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_JP.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].float().to(device)\n",
        "\n",
        "    optimizer_JP.zero_grad()\n",
        "\n",
        "    b_out = model_JP(b_input_id, b_input_mask)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_JP.parameters(), 1.0)\n",
        "\n",
        "    optimizer_JP.step()\n",
        "    scheduler_JP.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= J/P : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_JP.eval()\n",
        "  for step, batch in enumerate(val_dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    b_out = model_JP(b_input_id, b_input_mask)\n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_JP.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= J/P : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEf_OouZ0fXP"
      },
      "outputs": [],
      "source": [
        "torch.save(model_JP, model_JP_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzECXdaC3Td_"
      },
      "source": [
        "##### 3-4-5. Total Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdDuG_GWCASe"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_JP\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX7k6h8y3TvY",
        "outputId": "92b7d03e-de8c-479e-fe62-c3205f4c1fab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-70-826a0e9db9d9>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.classifier(lin_output)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : Test =======\n",
            "Test Accuracy: 0.6267361111111112\n",
            "\n",
            "======= S/N : Test =======\n",
            "Test Accuracy: 0.6215277777777778\n",
            "\n",
            "======= T/F : Test =======\n",
            "Test Accuracy: 0.6319444444444444\n",
            "\n",
            "======= J/P : Test =======\n",
            "Test Accuracy: 0.6423611111111112\n"
          ]
        }
      ],
      "source": [
        "model_IE = torch.load(model_IE_dir).cuda()\n",
        "model_SN = torch.load(model_SN_dir).cuda()\n",
        "model_TF = torch.load(model_TF_dir).cuda()\n",
        "model_JP = torch.load(model_JP_dir).cuda()\n",
        "\n",
        "# Test: I vs. E\n",
        "model_IE.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= I/E : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: S vs. N\n",
        "model_SN.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= S/N : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: T vs. F\n",
        "model_TF.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= T/F : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: J vs. P\n",
        "model_JP.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= J/P : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r6aUUqFB4QcB"
      },
      "source": [
        "#### 3-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mly0ZcZJ69TI",
        "outputId": "d0f6243a-50f7-4bf9-d394-e61680bcae3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  answer = testing['Answer'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoLpownw4P9S"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks)\n",
        "\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = SequentialSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = SequentialSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = SequentialSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = SequentialSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM2eHuMr9T7E",
        "outputId": "04cdce3c-211e-43ee-9c17-0e136610a68f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-70-826a0e9db9d9>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.classifier(lin_output)\n"
          ]
        }
      ],
      "source": [
        "model_IE.eval()\n",
        "model_SN.eval()\n",
        "model_TF.eval()\n",
        "model_JP.eval()\n",
        "\n",
        "preds_IE = []\n",
        "preds_prob_IE = []\n",
        "preds_SN = []\n",
        "preds_prob_SN = []\n",
        "preds_TF = []\n",
        "preds_prob_TF = []\n",
        "preds_JP = []\n",
        "preds_prob_JP = []\n",
        "\n",
        "# Predict I vs. E\n",
        "for batch in dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_IE = preds_prob_IE + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_IE = preds_IE + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_IE = np.array(preds_IE)\n",
        "\n",
        "# Predict S vs. N\n",
        "for batch in dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_SN = preds_prob_SN + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_SN = preds_SN + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_SN = np.array(preds_SN)\n",
        "\n",
        "# Predict T vs. F\n",
        "for batch in dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_TF = preds_prob_TF + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_TF = preds_TF + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_TF = np.array(preds_TF)\n",
        "\n",
        "# Predict J vs. P\n",
        "for batch in dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_JP = preds_prob_JP + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_JP = preds_JP + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_JP = np.array(preds_JP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGdVXi7R-o50"
      },
      "outputs": [],
      "source": [
        "idx = range(1, len(preds_IE) + 1)\n",
        "# preds = {'idx': idx,'I/E': preds_IE.tolist(), 'S/N':preds_SN.tolist(), 'T/F':preds_TF.tolist(), 'J/P':preds_JP.tolist()}\n",
        "preds = {'idx': idx,'I/E': preds_IE, 'S/N':preds_SN, 'T/F':preds_TF, 'J/P':preds_JP}\n",
        "preds = pd.DataFrame(data=preds)\n",
        "preds = preds.set_index('idx')\n",
        "preds.to_csv('result.csv')\n",
        "\n",
        "preds_prob = {'idx': idx,'I/E': preds_prob_IE, 'S/N':preds_prob_SN, 'T/F':preds_prob_TF, 'J/P':preds_prob_JP}\n",
        "preds_prob = pd.DataFrame(data=preds_prob)\n",
        "preds_prob = preds_prob.set_index('idx')\n",
        "preds_prob.to_csv('result_prob.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oSBLYacx9rNf"
      },
      "source": [
        "### 3. Implementation of the BERT-based Model (Question number)\n",
        "Rather than using the question as string, just put the Question number!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "naCemFl69rNj"
      },
      "source": [
        "#### 3-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "d5X8ffSM9rNp",
        "outputId": "cf6de945-5782-45a4-c562-175234807f80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5888061e-a108-4f3b-bc9e-f32f699bd085\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q_number</th>\n",
              "      <th>Answer</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5888061e-a108-4f3b-bc9e-f32f699bd085')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5888061e-a108-4f3b-bc9e-f32f699bd085 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5888061e-a108-4f3b-bc9e-f32f699bd085');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Q_number                                             Answer  MBTI\n",
              "0         1  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...  INFP\n",
              "1         2  <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...  INFP\n",
              "2         3  <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...  INFP\n",
              "3         4  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...  INFP\n",
              "4         5  <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...  INFP"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training = pd.read_csv(os.path.join(root_dir, train_dir), encoding=\"CP949\")\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Q_number', 'Answer', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "OmsnSnZ09rNt",
        "outputId": "7af1d068-5f9d-485d-e96f-064697da37e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44328036-a80d-4efe-98ef-56f8a20e2cfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q_number</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>&lt;아니다&gt; 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>&lt;중립&gt; 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>&lt;그렇다&gt; 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>&lt;그렇다&gt; 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51</td>\n",
              "      <td>&lt;중립&gt; 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44328036-a80d-4efe-98ef-56f8a20e2cfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44328036-a80d-4efe-98ef-56f8a20e2cfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44328036-a80d-4efe-98ef-56f8a20e2cfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Q_number                                             Answer\n",
              "0        59  <아니다> 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...\n",
              "1        53  <중립> 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...\n",
              "2        56  <그렇다> 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...\n",
              "3        60  <그렇다> 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...\n",
              "4        51  <중립> 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_csv(os.path.join(root_dir, test_dir), encoding=\"CP949\")\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['Q_number', 'Answer']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qx9KPmK9rNv"
      },
      "source": [
        "#### 3-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "8154ac58d64949118eebb29cb9a8ae2c",
            "0ca96c1f9f94424d882a69d7d712ed70",
            "8a318f99b2174209bd3fcd3d77daea8b",
            "0fe578bbbce841f6bf9bee3c730ccbfb",
            "f670096f1af744ecb512e308e4ed423f",
            "1b61c33ba19343979cf9eeb47957ada5",
            "fdb9b28a4f274813a56c57537c1d9a03",
            "cf63db022724484eaf2d58e8a6eee104",
            "2c26640f1c874d80a9ea494479260e8f",
            "728481dbd970436e9d1ba8a71fe501fa",
            "bd73a5773fce42318f1cc70676df0f38",
            "35d552e9a95945e3ae4fe63a360e6c33",
            "4dd04ebbe30144ad81cdd63ff2fca145",
            "9c93444eedb74a8daef088a9ca29226c",
            "121ca9995142473f96356803b3434a12",
            "2c8e0f1a40564fd3acc1504e435b363b",
            "01c1a9fdf8b746cba3cedf5f8c0f3e6b",
            "750c5777dff8415e97a87b7246ff0fce",
            "19b91febd5404c92a573074546dde610",
            "104a7d4f0eb54dfda5f764df89edcf4e",
            "d2c7c626322d4836b5044ba2805d36f6",
            "70071c741df14ebdb5321cfecba52137",
            "406d37e6d35144b2814421bf9468da59",
            "f597380ecab24113a275f8329ba94750",
            "214bec3ec5cc4540b042037ab439efc2",
            "f8cdac3d36df46eab5b9bd1861982ac8",
            "1ff536b7843442a2b1042259bc5ed51e",
            "96426c8717ae46b5a774e1fc1137cb09",
            "8d27daf13e44462e83875e14ad73d1a1",
            "de4b7b4142ae441c86ad539af7f887c0",
            "71a6073cacf84c2aa7552b60c0befcac",
            "f2ec537286854445893f792c1612247b",
            "101f2e141c14415989868ac802311a00"
          ]
        },
        "id": "v1VK2W0x9rNz",
        "outputId": "87343845-1bd4-4034-93d1-6f5bcd2ed63f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8154ac58d64949118eebb29cb9a8ae2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35d552e9a95945e3ae4fe63a360e6c33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "406d37e6d35144b2814421bf9468da59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 206 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "q_nums = []\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  q_num = training['Q_number'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  q_nums.append(torch.tensor([[q_num]]))\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "q_nums = torch.cat(q_nums, dim=0)\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhyTraiK9rN3",
        "outputId": "47df4340-ee2f-4f7b-e3b9-b5f6475fbc11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2,  2030, 15345,  2032, 18430,  3463,  5724,  8423, 26850, 20699,\n",
            "        14204, 15916, 17729, 25878, 18895, 14045, 27024,  8107, 28669,  8120,\n",
            "         6266, 24832,  2016,     3,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1])\n",
            "tensor([1, 0])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "11520 11520 11520 11520\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(q_nums[0])\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(q_nums), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVfF_PDc9rN7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jeipchvF9rN9"
      },
      "source": [
        "#### 3-2. Data Split\n",
        "Currently, we do not have the answers for testing dataset, so we must split the training data to evaluate our model. (8:1:1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrnfuDzN9rN-",
        "outputId": "188fab93-f65f-4ea9-bd6c-5c831fe9bda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lengths are 10368:576:576\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, q_nums, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, q_nums, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, q_nums, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, q_nums, labels_JP)\n",
        "\n",
        "train_size = int(0.9 * len(dataset_IE))\n",
        "val_size = int(0.05 * len(dataset_IE))\n",
        "test_size = len(dataset_IE) - train_size - val_size\n",
        "\n",
        "print(f\"lengths are {train_size}:{val_size}:{test_size}\")\n",
        "\n",
        "# Split into train dataset, validation dataset and test dataset.\n",
        "train_dataset_IE, val_dataset_IE, test_dataset_IE = random_split(dataset_IE, [train_size, val_size, test_size])\n",
        "train_dataset_SN, val_dataset_SN, test_dataset_SN = random_split(dataset_SN, [train_size, val_size, test_size])\n",
        "train_dataset_TF, val_dataset_TF, test_dataset_TF = random_split(dataset_TF, [train_size, val_size, test_size])\n",
        "train_dataset_JP, val_dataset_JP, test_dataset_JP = random_split(dataset_JP, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataloader_IE = DataLoader(\n",
        "    train_dataset_IE,\n",
        "    sampler = RandomSampler(train_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_IE = DataLoader (\n",
        "    val_dataset_IE,\n",
        "    sampler = SequentialSampler(val_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_IE = DataLoader (\n",
        "    test_dataset_IE,\n",
        "    sampler = SequentialSampler(test_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_SN = DataLoader(\n",
        "    train_dataset_SN,\n",
        "    sampler = RandomSampler(train_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_SN = DataLoader (\n",
        "    val_dataset_SN,\n",
        "    sampler = SequentialSampler(val_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_SN = DataLoader (\n",
        "    test_dataset_SN,\n",
        "    sampler = SequentialSampler(test_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_TF = DataLoader(\n",
        "    train_dataset_TF,\n",
        "    sampler = RandomSampler(train_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_TF = DataLoader (\n",
        "    val_dataset_TF,\n",
        "    sampler = SequentialSampler(val_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_TF = DataLoader (\n",
        "    test_dataset_TF,\n",
        "    sampler = SequentialSampler(test_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_JP = DataLoader(\n",
        "    train_dataset_JP,\n",
        "    sampler = RandomSampler(train_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_JP = DataLoader (\n",
        "    val_dataset_JP,\n",
        "    sampler = SequentialSampler(val_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_JP = DataLoader (\n",
        "    test_dataset_JP,\n",
        "    sampler = SequentialSampler(test_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jxnkf9_a9rOA"
      },
      "source": [
        "#### 3-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOx_3xXX9rOC",
        "outputId": "fc4db9d0-3b15-47a8-b965-425e0bebaeed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.lin = nn.Linear(hidden_size + 1, 256)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(256, num_classes)\n",
        "    self.classifier = nn.Softmax(dim=1)\n",
        "\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks, q_nums):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    bert_output = torch.cat((bert_output, q_nums), dim=1)\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "\n",
        "    lin_output = self.lin(dr_output)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "    return self.classifier(lin2_output)\n",
        "\n",
        "model_bert_IE = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert_IE, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert_SN, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert_TF, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert_JP, dr_rate = 0.3)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters_IE = [\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_SN = [\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_TF = [\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_JP = [\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "learning_rate = 2e-5\n",
        "\n",
        "optimizer_IE = AdamW(optimizer_grouped_parameters_IE,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = AdamW(optimizer_grouped_parameters_SN,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = AdamW(optimizer_grouped_parameters_TF,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = AdamW(optimizer_grouped_parameters_JP,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4 # 2 or 4\n",
        "\n",
        "total_steps = len(train_dataloader_IE) * epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "scheduler_IE = get_cosine_schedule_with_warmup(optimizer_IE, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_SN = get_cosine_schedule_with_warmup(optimizer_SN, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_TF = get_cosine_schedule_with_warmup(optimizer_TF, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_JP = get_cosine_schedule_with_warmup(optimizer_JP, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nk9dqeRs9rOE"
      },
      "source": [
        "#### 3-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E38DvLfU9rOF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XYcYBHdO9rOH"
      },
      "source": [
        "##### 3-4-1. I vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP622qPz9rOI",
        "outputId": "c8dc5a51-6936-4c07-fe4b-130081459579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6961251497268677 train acc 0.5\n",
            "epoch 1 batch id 129 loss 0.6874635219573975 train acc 0.48207364341085274\n",
            "epoch 1 batch id 257 loss 0.7024554014205933 train acc 0.5002431906614786\n",
            "epoch 1 batch id 385 loss 0.7227259278297424 train acc 0.5060064935064935\n",
            "epoch 1 batch id 513 loss 0.693671703338623 train acc 0.5158382066276803\n",
            "epoch 1 batch id 641 loss 0.6802080869674683 train acc 0.5273010920436817\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 1 train acc 0.5283564814814815\n",
            "epoch 1 validation acc 0.5850694444444444\n",
            "\n",
            "======= I/E : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6020957827568054 train acc 0.75\n",
            "epoch 2 batch id 129 loss 0.7003815174102783 train acc 0.5935077519379846\n",
            "epoch 2 batch id 257 loss 0.6623760461807251 train acc 0.5994649805447471\n",
            "epoch 2 batch id 385 loss 0.7972474098205566 train acc 0.6058441558441559\n",
            "epoch 2 batch id 513 loss 0.6040309071540833 train acc 0.6092836257309941\n",
            "epoch 2 batch id 641 loss 0.6477915644645691 train acc 0.6120319812792512\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 2 train acc 0.6128472222222222\n",
            "epoch 2 validation acc 0.6163194444444444\n",
            "\n",
            "======= I/E : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5305457711219788 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.7948421835899353 train acc 0.7180232558139535\n",
            "epoch 3 batch id 257 loss 0.615050196647644 train acc 0.7086575875486382\n",
            "epoch 3 batch id 385 loss 0.6030962467193604 train acc 0.7113636363636363\n",
            "epoch 3 batch id 513 loss 0.5236082077026367 train acc 0.7071150097465887\n",
            "epoch 3 batch id 641 loss 0.7624807357788086 train acc 0.7094383775351014\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 3 train acc 0.7092978395061729\n",
            "epoch 3 validation acc 0.6388888888888888\n",
            "\n",
            "======= I/E : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.6066410541534424 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.4581112861633301 train acc 0.7926356589147286\n",
            "epoch 4 batch id 257 loss 0.5265978574752808 train acc 0.7903696498054474\n",
            "epoch 4 batch id 385 loss 0.6052656769752502 train acc 0.7860389610389611\n",
            "epoch 4 batch id 513 loss 0.5400018692016602 train acc 0.7853313840155945\n",
            "epoch 4 batch id 641 loss 0.7423083782196045 train acc 0.780811232449298\n",
            "\n",
            "======= I/E : Validation =======\n",
            "epoch 4 train acc 0.78125\n",
            "epoch 4 validation acc 0.6510416666666666\n",
            "\n",
            "======= I/E : Test =======\n",
            "Test Accuracy: 0.6510416666666666\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask, b_q_num)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  print(\"\\n======= I/E : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_IE.eval()\n",
        "  for step, batch in enumerate(val_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_q_num)\n",
        "    \n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_IE.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= I/E : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GybCz4wf9rOL"
      },
      "outputs": [],
      "source": [
        "torch.save(model_IE, model_IE_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GeFdVH9rON"
      },
      "source": [
        "##### 3-4-2. S vs. N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL7leVcA9rOO"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_IE\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpk07cGz9rOO",
        "outputId": "d5ba687a-336c-409d-e254-24d0b69b9d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= S/N : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6920459270477295 train acc 0.5625\n",
            "epoch 1 batch id 129 loss 0.7073368430137634 train acc 0.5266472868217055\n",
            "epoch 1 batch id 257 loss 0.6653560400009155 train acc 0.5313715953307393\n",
            "epoch 1 batch id 385 loss 0.6951838135719299 train acc 0.5387987012987013\n",
            "epoch 1 batch id 513 loss 0.7430845499038696 train acc 0.5483674463937622\n",
            "epoch 1 batch id 641 loss 0.6899130344390869 train acc 0.5530421216848674\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 1 train acc 0.5520833333333334\n",
            "epoch 1 validation acc 0.6180555555555556\n",
            "\n",
            "======= S/N : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.5626250505447388 train acc 0.875\n",
            "epoch 2 batch id 129 loss 0.6293864846229553 train acc 0.6206395348837209\n",
            "epoch 2 batch id 257 loss 0.5490229725837708 train acc 0.6208657587548638\n",
            "epoch 2 batch id 385 loss 0.7460149526596069 train acc 0.6227272727272727\n",
            "epoch 2 batch id 513 loss 0.5601366758346558 train acc 0.6269493177387915\n",
            "epoch 2 batch id 641 loss 0.7160625457763672 train acc 0.6304602184087363\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 2 train acc 0.630883487654321\n",
            "epoch 2 validation acc 0.6267361111111112\n",
            "\n",
            "======= S/N : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6829361915588379 train acc 0.5\n",
            "epoch 3 batch id 129 loss 0.5758628845214844 train acc 0.7243217054263565\n",
            "epoch 3 batch id 257 loss 0.5290520787239075 train acc 0.7186284046692607\n",
            "epoch 3 batch id 385 loss 0.5080336332321167 train acc 0.7256493506493507\n",
            "epoch 3 batch id 513 loss 0.5677457451820374 train acc 0.7286793372319688\n",
            "epoch 3 batch id 641 loss 0.6206254959106445 train acc 0.7322542901716068\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 3 train acc 0.7317708333333334\n",
            "epoch 3 validation acc 0.6579861111111112\n",
            "\n",
            "======= S/N : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.5643373727798462 train acc 0.75\n",
            "epoch 4 batch id 129 loss 0.5460938215255737 train acc 0.8062015503875969\n",
            "epoch 4 batch id 257 loss 0.33169469237327576 train acc 0.8069066147859922\n",
            "epoch 4 batch id 385 loss 0.4539508521556854 train acc 0.8053571428571429\n",
            "epoch 4 batch id 513 loss 0.5899423956871033 train acc 0.8054337231968811\n",
            "epoch 4 batch id 641 loss 0.5049894452095032 train acc 0.8055772230889235\n",
            "\n",
            "======= S/N : Validation =======\n",
            "epoch 4 train acc 0.8053626543209876\n",
            "epoch 4 validation acc 0.6527777777777778\n",
            "\n",
            "======= S/N : Test =======\n",
            "Test Accuracy: 0.6267361111111112\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= S/N : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_SN.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_SN.zero_grad()\n",
        "\n",
        "    b_out = model_SN(b_input_id, b_input_mask, b_q_num)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_SN.parameters(), 1.0)\n",
        "\n",
        "    optimizer_SN.step()\n",
        "    scheduler_SN.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  print(\"\\n======= S/N : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_SN.eval()\n",
        "  for step, batch in enumerate(val_dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_q_num)\n",
        "    \n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_SN.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= S/N : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN5OE6qZ9rOQ"
      },
      "outputs": [],
      "source": [
        "torch.save(model_SN, model_SN_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E0UG3kNd9rOR"
      },
      "source": [
        "##### 3-4-3. T vs. F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06cMQXH39rOS"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_SN\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "CdPX8LmM9rOS",
        "outputId": "05c092b2-3f1d-484c-83bb-fa8c5138c628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= T/F : 1 / 4 =======\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9b76b999108f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel_TF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader_TF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_TF' is not defined"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= T/F : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_TF.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_TF.zero_grad()\n",
        "\n",
        "    b_out = model_TF(b_input_id, b_input_mask, b_q_num)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_TF.parameters(), 1.0)\n",
        "\n",
        "    optimizer_TF.step()\n",
        "    scheduler_TF.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  print(\"\\n======= T/F : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_TF.eval()\n",
        "  for step, batch in enumerate(val_dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_q_num)\n",
        "    \n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_TF.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= T/F : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCUb5PIY9rOU"
      },
      "outputs": [],
      "source": [
        "torch.save(model_TF, model_TF_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2-53l5Pj9rOV"
      },
      "source": [
        "##### 3-4-4. J vs. P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqdodC8L9rOV"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_TF\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrerPpf_9rOX",
        "outputId": "47c19ca3-1289-4209-8396-fafc7278809d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= J/P : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6965028047561646 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.701758623123169 train acc 0.5130813953488372\n",
            "epoch 1 batch id 257 loss 0.6813562512397766 train acc 0.4995136186770428\n",
            "epoch 1 batch id 385 loss 0.7434478402137756 train acc 0.499512987012987\n",
            "epoch 1 batch id 513 loss 0.6941266059875488 train acc 0.5001218323586745\n",
            "epoch 1 batch id 641 loss 0.6772091388702393 train acc 0.5049726989079563\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 1 train acc 0.5055941358024691\n",
            "epoch 1 validation acc 0.5260416666666666\n",
            "\n",
            "======= J/P : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6907752752304077 train acc 0.5625\n",
            "epoch 2 batch id 129 loss 0.7362107038497925 train acc 0.5818798449612403\n",
            "epoch 2 batch id 257 loss 0.6972082853317261 train acc 0.5707684824902723\n",
            "epoch 2 batch id 385 loss 0.6782873868942261 train acc 0.5696428571428571\n",
            "epoch 2 batch id 513 loss 0.6424216032028198 train acc 0.5713937621832359\n",
            "epoch 2 batch id 641 loss 0.744220495223999 train acc 0.5747854914196567\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 2 train acc 0.5752314814814815\n",
            "epoch 2 validation acc 0.6006944444444444\n",
            "\n",
            "======= J/P : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.7357196807861328 train acc 0.4375\n",
            "epoch 3 batch id 129 loss 0.5927811861038208 train acc 0.6584302325581395\n",
            "epoch 3 batch id 257 loss 0.6905704736709595 train acc 0.6507782101167315\n",
            "epoch 3 batch id 385 loss 0.7056999206542969 train acc 0.6490259740259741\n",
            "epoch 3 batch id 513 loss 0.7054909467697144 train acc 0.6516812865497076\n",
            "epoch 3 batch id 641 loss 0.5957046747207642 train acc 0.6592238689547582\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 3 train acc 0.6593364197530864\n",
            "epoch 3 validation acc 0.6145833333333334\n",
            "\n",
            "======= J/P : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.5451738834381104 train acc 0.75\n",
            "epoch 4 batch id 129 loss 0.5752511620521545 train acc 0.7344961240310077\n",
            "epoch 4 batch id 257 loss 0.6130380630493164 train acc 0.743920233463035\n",
            "epoch 4 batch id 385 loss 0.5960537791252136 train acc 0.7472402597402598\n",
            "epoch 4 batch id 513 loss 0.652463972568512 train acc 0.7459795321637427\n",
            "epoch 4 batch id 641 loss 0.6482305526733398 train acc 0.7459048361934477\n",
            "\n",
            "======= J/P : Validation =======\n",
            "epoch 4 train acc 0.7454668209876543\n",
            "epoch 4 validation acc 0.6232638888888888\n",
            "\n",
            "======= J/P : Test =======\n",
            "Test Accuracy: 0.6180555555555556\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= J/P : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_JP.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_JP.zero_grad()\n",
        "\n",
        "    b_out = model_JP(b_input_id, b_input_mask, b_q_num)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_JP.parameters(), 1.0)\n",
        "\n",
        "    optimizer_JP.step()\n",
        "    scheduler_JP.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= J/P : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_JP.eval()\n",
        "  for step, batch in enumerate(val_dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_q_num = batch[2].to(device)\n",
        "    b_label = batch[3].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_q_num)\n",
        "    \n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_JP.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= J/P : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZObDmJdv9rOZ"
      },
      "outputs": [],
      "source": [
        "torch.save(model_JP, model_JP_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DvT7eXBz9rOa"
      },
      "source": [
        "##### 3-4-5. Total Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxk1SPyI9rOa"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del model_JP\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23FzglEh9rOb",
        "outputId": "5850d687-dffa-488e-f00f-4d69447ca3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : Test =======\n",
            "Test Accuracy: 0.6510416666666666\n",
            "\n",
            "======= S/N : Test =======\n",
            "Test Accuracy: 0.6267361111111112\n",
            "\n",
            "======= T/F : Test =======\n",
            "Test Accuracy: 0.6163194444444444\n",
            "\n",
            "======= J/P : Test =======\n",
            "Test Accuracy: 0.6180555555555556\n"
          ]
        }
      ],
      "source": [
        "model_IE = torch.load(model_IE_dir).cuda()\n",
        "model_SN = torch.load(model_SN_dir).cuda()\n",
        "model_TF = torch.load(model_TF_dir).cuda()\n",
        "model_JP = torch.load(model_JP_dir).cuda()\n",
        "\n",
        "# Test: I vs. E\n",
        "model_IE.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= I/E : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: S vs. N\n",
        "model_SN.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= S/N : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: T vs. F\n",
        "model_TF.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= T/F : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "# Test: J vs. P\n",
        "model_JP.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= J/P : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6UTL2irJ9rOb"
      },
      "source": [
        "#### 3-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH2huYBK9rOd",
        "outputId": "53faaa91-8e57-42ed-8afa-5c7ebee0bc79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "q_nums = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  q_num = testing['Q_number'][idx]\n",
        "  answer = testing['Answer'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  q_nums.append(torch.tensor([[q_num]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "q_nums = torch.cat(q_nums, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKxByBuB9rOe"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, q_nums)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, q_nums)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, q_nums)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, q_nums)\n",
        "\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = SequentialSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = SequentialSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = SequentialSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = SequentialSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeGVpKvg9rOg"
      },
      "outputs": [],
      "source": [
        "model_IE.eval()\n",
        "model_SN.eval()\n",
        "model_TF.eval()\n",
        "model_JP.eval()\n",
        "\n",
        "preds_IE = []\n",
        "preds_prob_IE = []\n",
        "preds_SN = []\n",
        "preds_prob_SN = []\n",
        "preds_TF = []\n",
        "preds_prob_TF = []\n",
        "preds_JP = []\n",
        "preds_prob_JP = []\n",
        "\n",
        "# Predict I vs. E\n",
        "for batch in dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_IE = preds_prob_IE + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_IE = preds_IE + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_IE = np.array(preds_IE)\n",
        "\n",
        "# Predict S vs. N\n",
        "for batch in dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_SN = preds_prob_SN + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_SN = preds_SN + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_SN = np.array(preds_SN)\n",
        "\n",
        "# Predict T vs. F\n",
        "for batch in dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_TF = preds_prob_TF + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_TF = preds_TF + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_TF = np.array(preds_TF)\n",
        "\n",
        "# Predict J vs. P\n",
        "for batch in dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_q_num = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_q_num)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_JP = preds_prob_JP + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_JP = preds_JP + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds_JP = np.array(preds_JP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMyLK4tG9rOi"
      },
      "outputs": [],
      "source": [
        "idx = range(1, len(preds_IE) + 1)\n",
        "# preds = {'idx': idx,'I/E': preds_IE.tolist(), 'S/N':preds_SN.tolist(), 'T/F':preds_TF.tolist(), 'J/P':preds_JP.tolist()}\n",
        "preds = {'idx': idx,'I/E': preds_IE, 'S/N':preds_SN, 'T/F':preds_TF, 'J/P':preds_JP}\n",
        "preds = pd.DataFrame(data=preds)\n",
        "preds = preds.set_index('idx')\n",
        "preds.to_csv('result.csv')\n",
        "\n",
        "preds_prob = {'idx': idx,'I/E': preds_prob_IE, 'S/N':preds_prob_SN, 'T/F':preds_prob_TF, 'J/P':preds_prob_JP}\n",
        "preds_prob = pd.DataFrame(data=preds_prob)\n",
        "preds_prob = preds_prob.set_index('idx')\n",
        "preds_prob.to_csv('result_prob.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IBattrTo5R0j"
      },
      "source": [
        "### 3. Implementation of the BERT-based Model (separated encoding)\n",
        "But this time, I will encode the question and the answer separately, instead of using \\<SEP\\> token."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5CDYwk2L5R0k"
      },
      "source": [
        "#### 3-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fD3OWf--5R0k",
        "outputId": "b535e430-e22e-422e-bda4-0d0c9cb82f95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1682bfa3-f073-4352-8e13-7c9c3bc02478\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1682bfa3-f073-4352-8e13-7c9c3bc02478')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1682bfa3-f073-4352-8e13-7c9c3bc02478 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1682bfa3-f073-4352-8e13-7c9c3bc02478');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y93Xo-q-5R0l",
        "outputId": "1a65b9c3-0c43-4746-eafb-e1d08f9902b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13f70569-4663-4dc7-b6d0-6b3260ce424c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f70569-4663-4dc7-b6d0-6b3260ce424c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13f70569-4663-4dc7-b6d0-6b3260ce424c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13f70569-4663-4dc7-b6d0-6b3260ce424c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...   \n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...   \n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...   \n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.   \n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.   \n",
              "\n",
              "                                              Answer  MBTI  \n",
              "0  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...  INFP  \n",
              "1  <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...  INFP  \n",
              "2  <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...  INFP  \n",
              "3  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...  INFP  \n",
              "4  <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...  INFP  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "\n",
        "training = pd.read_csv(os.path.join(root_dir, train_dir), encoding=\"CP949\")\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Answer', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "866F7Vdi5R0m",
        "outputId": "00ecd5f3-fa2b-48a5-d000-e6e5e3fa3f92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0f3574c3-32f9-4b55-9a28-cfa35257e26c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.</td>\n",
              "      <td>&lt;아니다&gt; 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...</td>\n",
              "      <td>&lt;중립&gt; 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...</td>\n",
              "      <td>&lt;그렇다&gt; 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.</td>\n",
              "      <td>&lt;그렇다&gt; 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.</td>\n",
              "      <td>&lt;중립&gt; 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f3574c3-32f9-4b55-9a28-cfa35257e26c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f3574c3-32f9-4b55-9a28-cfa35257e26c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f3574c3-32f9-4b55-9a28-cfa35257e26c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0                     마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.   \n",
              "1  조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...   \n",
              "2  단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...   \n",
              "3    일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.   \n",
              "4         대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.   \n",
              "\n",
              "                                              Answer  \n",
              "0  <아니다> 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...  \n",
              "1  <중립> 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...  \n",
              "2  <그렇다> 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...  \n",
              "3  <그렇다> 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...  \n",
              "4  <중립> 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_csv(os.path.join(root_dir, test_dir), encoding=\"CP949\")\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Gender', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['Question', 'Answer']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGJccIR5R0m"
      },
      "source": [
        "#### 3-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "4b30e212f6fc4fb78e57a3fb93d7bd99",
            "1acd0562bcdb4e8f8ae5f7e1a0b06188",
            "4ebe0d6b63f741c8a7b6ab034097bc57",
            "4b4c9f5bd2044bd28c495bcb8cb095b1",
            "6bce5b4d2f3c40c994b75e7c45c55d89",
            "ac5627427a304f50acbba4404bf77edc",
            "1967f89b4f6f47a39bfe6bac9b29a752",
            "adb63386d0d947c09ea0bc197fd66f8b",
            "07882d527a69414d8a8189e85c60252d",
            "2f85f0d8161e42b79dfa72b5588296a5",
            "9c11841a8a6d44829b5ce29c852a74f1",
            "b6cb8bb8132244c69baf132f242f749b",
            "418a865feab74f37917a624e96da0bb3",
            "084f8a5ea1a64c87a84c940ff8a645d5",
            "a16f117786bc4521ae560b8c5901dc42",
            "7220c444ef8e4642ab154087b4ec1b08",
            "b262d0bdc07b444c8d5e1a953ce11245",
            "09a29598952543a880c75a5f28792cc9",
            "a2c5bd9e0e734c8693e71b672471e8e8",
            "4bec0902671e4871a41e8f85d61a7753",
            "d3737d6efd0542ca8b26740ded255959",
            "155527cc147e42acb67e96c3ecbe2061",
            "72492b9ca9c3470db9dd3db4a0b11c82",
            "687619be7e0c478b8729b434e87d162d",
            "ffe882263cfe40cfb4d953a9e9188eaf",
            "81ddfc4bf4d84132b908d03913baf918",
            "e8a3921ca23a493fa3339a369de47d71",
            "337dcaafa91e41a7bcb61bdfef120ae5",
            "658ac41dbc584647a3166e4933c7c9e5",
            "2036231715e7430a8b12009357268de2",
            "c7cd50e46d31403986063c65fed50cab",
            "749d78bdfe8448af97f11e8aecffd5ea",
            "50f9124e7cd94ff88b017d6d53987e14"
          ]
        },
        "id": "H4cWhWzZ5R0n",
        "outputId": "b282dd55-f6cc-4265-9ee2-95a65221b9dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b30e212f6fc4fb78e57a3fb93d7bd99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6cb8bb8132244c69baf132f242f749b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72492b9ca9c3470db9dd3db4a0b11c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 206 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids_Q = []\n",
        "att_masks_Q = []\n",
        "\n",
        "input_ids_A = []\n",
        "att_masks_A = []\n",
        "\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  question = training['Question'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings_Q = tokenizer_bert(\n",
        "      question,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  encodings_A = tokenizer_bert(\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids_Q.append(encodings_Q['input_ids'])\n",
        "  att_masks_Q.append(encodings_Q['attention_mask'])\n",
        "\n",
        "  input_ids_A.append(encodings_A['input_ids'])\n",
        "  att_masks_A.append(encodings_A['attention_mask'])\n",
        "\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids_Q = torch.cat(input_ids_Q, dim=0)\n",
        "att_masks_Q = torch.cat(att_masks_Q, dim=0)\n",
        "\n",
        "input_ids_A = torch.cat(input_ids_A, dim=0)\n",
        "att_masks_A = torch.cat(att_masks_A, dim=0)\n",
        "\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdFfEOH5R0n",
        "outputId": "822ce5ee-47fb-4cbe-b564-3cced7246e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2, 25753, 14567, 28897, 18069, 14526,  2033, 19742, 22742,  8082,\n",
            "        31724,  3463, 32771,  8061, 19773, 16941, 24296,  8055,  2016,     3,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([    2,  2030, 15345,  2032, 18430,  3463,  5724,  8423, 26850, 20699,\n",
            "        14204, 15916, 17729, 25878, 18895, 14045, 27024,  8107, 28669,  8120,\n",
            "         6266, 24832,  2016,     3,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 0])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "11520 11520 11520 11520 11520\n"
          ]
        }
      ],
      "source": [
        "print(input_ids_Q[0])\n",
        "print(att_masks_Q[0])\n",
        "\n",
        "print(input_ids_A[0])\n",
        "print(att_masks_A[0])\n",
        "\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids_Q), len(att_masks_Q), len(input_ids_A), len(input_ids_A), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8zCUmI85R0o"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RLUFoXu25R0o"
      },
      "source": [
        "#### 3-2. Data Split\n",
        "To see the training progress, so I'm going to split some of our training data to evaluate our model. (9:1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NbQlFlW5R0q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A, labels_JP)\n",
        "\n",
        "# train_size = int(0.9 * len(dataset_IE))\n",
        "# val_size = len(dataset_IE) - train_size\n",
        "\n",
        "# print(f\"lengths are {train_size}:{val_size}\")\n",
        "\n",
        "# # Split into train dataset, validation dataset and test dataset.\n",
        "# train_dataset_IE, val_dataset_IE = random_split(dataset_IE, [train_size, val_size])\n",
        "# train_dataset_SN, val_dataset_SN = random_split(dataset_SN, [train_size, val_size])\n",
        "# train_dataset_TF, val_dataset_TF = random_split(dataset_TF, [train_size, val_size])\n",
        "# train_dataset_JP, val_dataset_JP = random_split(dataset_JP, [train_size, val_size])\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader_IE = DataLoader(\n",
        "    dataset_IE,\n",
        "    sampler = RandomSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader(\n",
        "    dataset_SN,\n",
        "    sampler = RandomSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader(\n",
        "    dataset_TF,\n",
        "    sampler = RandomSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader(\n",
        "    dataset_JP,\n",
        "    sampler = RandomSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "# # Define dataloaders\n",
        "# train_dataloader_IE = DataLoader(\n",
        "#     train_dataset_IE,\n",
        "#     sampler = RandomSampler(train_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_IE = DataLoader (\n",
        "#     val_dataset_IE,\n",
        "#     sampler = SequentialSampler(val_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_SN = DataLoader(\n",
        "#     train_dataset_SN,\n",
        "#     sampler = RandomSampler(train_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_SN = DataLoader (\n",
        "#     val_dataset_SN,\n",
        "#     sampler = SequentialSampler(val_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_TF = DataLoader(\n",
        "#     train_dataset_TF,\n",
        "#     sampler = RandomSampler(train_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_TF = DataLoader (\n",
        "#     val_dataset_TF,\n",
        "#     sampler = SequentialSampler(val_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_JP = DataLoader(\n",
        "#     train_dataset_JP,\n",
        "#     sampler = RandomSampler(train_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_JP = DataLoader (\n",
        "#     val_dataset_JP,\n",
        "#     sampler = SequentialSampler(val_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZVSlBx5R0q"
      },
      "source": [
        "#### 3-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just few layers on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWM--Q8q5R0q",
        "outputId": "13d1065b-496c-477e-a839-3f0e35d185d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bertq,\n",
        "                berta,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "\n",
        "    # Pretrained BERT model\n",
        "    self.bertq = bertq\n",
        "    self.berta = berta\n",
        "\n",
        "    # Fine-tuning\n",
        "    self.linq = nn.Linear(hidden_size, int(hidden_size / 4))\n",
        "    self.reluq = nn.ReLU()\n",
        "    self.lina = nn.Linear(hidden_size, hidden_size - int(hidden_size / 4))\n",
        "    self.relua = nn.ReLU()\n",
        "\n",
        "    self.lin = nn.Linear(hidden_size, 256)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(256, 256)\n",
        "    self.relu2  = nn.ReLU()\n",
        "    self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    # Drop out\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids_Q, att_masks_Q, input_ids_A, att_masks_A):\n",
        "    bert_output_Q = self.bertq(input_ids_Q, token_type_ids=None, attention_mask=att_masks_Q).pooler_output\n",
        "    bert_output_A = self.berta(input_ids_A, token_type_ids=None, attention_mask=att_masks_A).pooler_output\n",
        "\n",
        "    if self.dr_rate:\n",
        "      dr_output_Q = self.dropout(bert_output_Q)\n",
        "      dr_output_A = self.dropout(bert_output_A)\n",
        "    else:\n",
        "      dr_output_Q = bert_output_Q\n",
        "      dr_output_A = bert_output_A\n",
        "    \n",
        "    # Aggregation\n",
        "    lin_output_Q = self.linq(dr_output_Q)\n",
        "    relu_output_Q = self.reluq(lin_output_Q)\n",
        "\n",
        "    lin_output_A = self.lina(dr_output_A)\n",
        "    relu_output_A = self.relua(lin_output_A)\n",
        "\n",
        "    concated = torch.cat((relu_output_Q, relu_output_A), dim=1)\n",
        "\n",
        "    lin_output = self.lin(concated)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "    relu2_output = self.relu2(lin2_output)\n",
        "    return self.classifier(relu2_output)\n",
        "\n",
        "model_bert_IE_Q = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_IE_A = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN_Q = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN_A = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF_Q = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF_A = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP_Q = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP_A = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert_IE_Q, model_bert_IE_A, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert_SN_Q, model_bert_SN_A, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert_TF_Q, model_bert_TF_A, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert_JP_Q, model_bert_JP_A, dr_rate = 0.3)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "\n",
        "optimizer_IE = Adam(model_IE.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = Adam(model_SN.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = Adam(model_TF.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = Adam(model_JP.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 10 # 2 or 4\n",
        "\n",
        "total_steps = len(dataloader_IE) * epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "scheduler_IE = get_cosine_schedule_with_warmup(optimizer_IE, num_warmup_steps = warmup_steps, num_training_steps = total_steps) \n",
        "scheduler_SN = get_cosine_schedule_with_warmup(optimizer_SN, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_TF = get_cosine_schedule_with_warmup(optimizer_TF, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_JP = get_cosine_schedule_with_warmup(optimizer_JP, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "67Pax5DE5R0r"
      },
      "source": [
        "#### 3-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3Ki0rpX5R0r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bi2zwSqG5R0r"
      },
      "source": [
        "##### 3-4-1. I vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys2dlsID5R0r",
        "outputId": "d50ee2f2-d25a-4250-86c8-2efd506e9966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : 1 / 10 =======\n",
            "epoch 1 batch id 1 loss 0.6916688680648804 train acc 0.5\n",
            "epoch 1 batch id 129 loss 0.6978166103363037 train acc 0.498546511627907\n",
            "epoch 1 batch id 257 loss 0.685836911201477 train acc 0.5034046692607004\n",
            "epoch 1 batch id 385 loss 0.694135308265686 train acc 0.5\n",
            "epoch 1 batch id 513 loss 0.6947845220565796 train acc 0.49951267056530213\n",
            "epoch 1 batch id 641 loss 0.6909545660018921 train acc 0.501170046801872\n",
            "\n",
            "======= I/E : 2 / 10 =======\n",
            "epoch 2 batch id 1 loss 0.6867105960845947 train acc 0.6875\n",
            "epoch 2 batch id 129 loss 0.6913474798202515 train acc 0.5528100775193798\n",
            "epoch 2 batch id 257 loss 0.6633660197257996 train acc 0.555204280155642\n",
            "epoch 2 batch id 385 loss 0.7088248133659363 train acc 0.5603896103896104\n",
            "epoch 2 batch id 513 loss 0.7164874076843262 train acc 0.5651803118908382\n",
            "epoch 2 batch id 641 loss 0.6617848873138428 train acc 0.5728354134165367\n",
            "\n",
            "======= I/E : 3 / 10 =======\n",
            "epoch 3 batch id 1 loss 0.6355686187744141 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.779559314250946 train acc 0.6424418604651163\n",
            "epoch 3 batch id 257 loss 0.7704728245735168 train acc 0.6381322957198443\n",
            "epoch 3 batch id 385 loss 0.6368894577026367 train acc 0.6362012987012987\n",
            "epoch 3 batch id 513 loss 0.5817677974700928 train acc 0.6366959064327485\n",
            "epoch 3 batch id 641 loss 0.6236910223960876 train acc 0.6369929797191888\n",
            "\n",
            "======= I/E : 4 / 10 =======\n",
            "epoch 4 batch id 1 loss 0.5599059462547302 train acc 0.75\n",
            "epoch 4 batch id 129 loss 0.6027930974960327 train acc 0.690406976744186\n",
            "epoch 4 batch id 257 loss 0.6136412620544434 train acc 0.694795719844358\n",
            "epoch 4 batch id 385 loss 0.6603822708129883 train acc 0.6907467532467533\n",
            "epoch 4 batch id 513 loss 0.672258734703064 train acc 0.6945662768031189\n",
            "epoch 4 batch id 641 loss 0.8316285610198975 train acc 0.6936427457098284\n",
            "\n",
            "======= I/E : 5 / 10 =======\n",
            "epoch 5 batch id 1 loss 0.5160356760025024 train acc 0.75\n",
            "epoch 5 batch id 129 loss 0.5788365006446838 train acc 0.7446705426356589\n",
            "epoch 5 batch id 257 loss 0.6165652871131897 train acc 0.7373540856031129\n",
            "epoch 5 batch id 385 loss 0.5141153335571289 train acc 0.7363636363636363\n",
            "epoch 5 batch id 513 loss 0.594852089881897 train acc 0.7342836257309941\n",
            "epoch 5 batch id 641 loss 0.4122868776321411 train acc 0.7337168486739469\n",
            "\n",
            "======= I/E : 6 / 10 =======\n",
            "epoch 6 batch id 1 loss 0.5074809789657593 train acc 0.75\n",
            "epoch 6 batch id 129 loss 0.4189962148666382 train acc 0.7611434108527132\n",
            "epoch 6 batch id 257 loss 0.7720770835876465 train acc 0.7577821011673151\n",
            "epoch 6 batch id 385 loss 0.7044491171836853 train acc 0.7566558441558442\n",
            "epoch 6 batch id 513 loss 0.40070608258247375 train acc 0.7610867446393762\n",
            "epoch 6 batch id 641 loss 0.33237189054489136 train acc 0.7621879875195008\n",
            "\n",
            "======= I/E : 7 / 10 =======\n",
            "epoch 7 batch id 1 loss 0.5454897880554199 train acc 0.8125\n",
            "epoch 7 batch id 129 loss 0.42615264654159546 train acc 0.8028100775193798\n",
            "epoch 7 batch id 257 loss 0.2768436670303345 train acc 0.8032587548638133\n",
            "epoch 7 batch id 385 loss 0.3424292802810669 train acc 0.7991883116883117\n",
            "epoch 7 batch id 513 loss 0.6598596572875977 train acc 0.7966617933723197\n",
            "epoch 7 batch id 641 loss 0.5831859707832336 train acc 0.795729329173167\n",
            "\n",
            "======= I/E : 8 / 10 =======\n",
            "epoch 8 batch id 1 loss 0.5694204568862915 train acc 0.75\n",
            "epoch 8 batch id 129 loss 0.44719168543815613 train acc 0.8047480620155039\n",
            "epoch 8 batch id 257 loss 0.40872612595558167 train acc 0.8030155642023347\n",
            "epoch 8 batch id 385 loss 0.5671892762184143 train acc 0.811038961038961\n",
            "epoch 8 batch id 513 loss 0.4966100752353668 train acc 0.8110380116959064\n",
            "epoch 8 batch id 641 loss 0.7419630885124207 train acc 0.8093798751950078\n",
            "\n",
            "======= I/E : 9 / 10 =======\n",
            "epoch 9 batch id 1 loss 0.3742159605026245 train acc 0.875\n",
            "epoch 9 batch id 129 loss 0.6737496852874756 train acc 0.815406976744186\n",
            "epoch 9 batch id 257 loss 0.7608505487442017 train acc 0.8168774319066148\n",
            "epoch 9 batch id 385 loss 0.4076804220676422 train acc 0.8170454545454545\n",
            "epoch 9 batch id 513 loss 0.5012129545211792 train acc 0.8162768031189084\n",
            "epoch 9 batch id 641 loss 0.1494813859462738 train acc 0.8187402496099844\n",
            "\n",
            "======= I/E : 10 / 10 =======\n",
            "epoch 10 batch id 1 loss 0.5016491413116455 train acc 0.75\n",
            "epoch 10 batch id 129 loss 0.32403063774108887 train acc 0.815406976744186\n",
            "epoch 10 batch id 257 loss 0.1426333338022232 train acc 0.8214980544747081\n",
            "epoch 10 batch id 385 loss 0.20854873955249786 train acc 0.8285714285714286\n",
            "epoch 10 batch id 513 loss 0.44845056533813477 train acc 0.8304093567251462\n",
            "epoch 10 batch id 641 loss 0.6463855504989624 train acc 0.827808112324493\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_IE):\n",
        "    b_input_id_Q = batch[0].to(device)\n",
        "    b_input_mask_Q = batch[1].to(device)\n",
        "    b_input_id_A = batch[2].to(device)\n",
        "    b_input_mask_A = batch[3].to(device)\n",
        "    b_label = batch[4].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "\n",
        "  # print(\"\\n======= I/E : Validation =======\")\n",
        "  # print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  # model_IE.eval()\n",
        "  # for step, batch in enumerate(val_dataloader_IE):\n",
        "  #   b_input_id_Q = batch[0].to(device)\n",
        "  #   b_input_mask_Q = batch[1].to(device)\n",
        "  #   b_input_id_A = batch[2].to(device)\n",
        "  #   b_input_mask_A = batch[3].to(device)\n",
        "  #   b_label = batch[4].to(device)\n",
        "\n",
        "  #   with torch.no_grad():\n",
        "  #     b_out = model_IE(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "  #   val_acc += calc_accuracy(b_out, b_label)\n",
        "  # print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_IE, model_IE_dir)\n",
        "del(model_IE)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJEM-qZ25R0s"
      },
      "source": [
        "##### 3-4-2. S vs. N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32n51tH5R0s",
        "outputId": "25bc86d7-82b5-41d9-9b4d-2aeb5038a0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= S/N : 1 / 10 =======\n",
            "epoch 1 batch id 1 loss 0.6934932470321655 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.6960813403129578 train acc 0.4946705426356589\n",
            "epoch 1 batch id 257 loss 0.6902273893356323 train acc 0.5077821011673151\n",
            "epoch 1 batch id 385 loss 0.6975000500679016 train acc 0.5097402597402597\n",
            "epoch 1 batch id 513 loss 0.6904122233390808 train acc 0.515229044834308\n",
            "epoch 1 batch id 641 loss 0.6761630773544312 train acc 0.5217433697347894\n",
            "\n",
            "======= S/N : 2 / 10 =======\n",
            "epoch 2 batch id 1 loss 0.6965057849884033 train acc 0.5\n",
            "epoch 2 batch id 129 loss 0.6623672246932983 train acc 0.5828488372093024\n",
            "epoch 2 batch id 257 loss 0.639825701713562 train acc 0.5916828793774319\n",
            "epoch 2 batch id 385 loss 0.7330557107925415 train acc 0.589935064935065\n",
            "epoch 2 batch id 513 loss 0.6399783492088318 train acc 0.5884502923976608\n",
            "epoch 2 batch id 641 loss 0.6962334513664246 train acc 0.5900936037441498\n",
            "\n",
            "======= S/N : 3 / 10 =======\n",
            "epoch 3 batch id 1 loss 0.6622306108474731 train acc 0.5625\n",
            "epoch 3 batch id 129 loss 0.681347131729126 train acc 0.6308139534883721\n",
            "epoch 3 batch id 257 loss 0.6786671876907349 train acc 0.6403210116731517\n",
            "epoch 3 batch id 385 loss 0.52225661277771 train acc 0.6410714285714286\n",
            "epoch 3 batch id 513 loss 0.5156102180480957 train acc 0.6410818713450293\n",
            "epoch 3 batch id 641 loss 0.621897280216217 train acc 0.641575663026521\n",
            "\n",
            "======= S/N : 4 / 10 =======\n",
            "epoch 4 batch id 1 loss 0.5746726393699646 train acc 0.75\n",
            "epoch 4 batch id 129 loss 0.5234760046005249 train acc 0.6739341085271318\n",
            "epoch 4 batch id 257 loss 0.7275832891464233 train acc 0.6699902723735408\n",
            "epoch 4 batch id 385 loss 0.5172750949859619 train acc 0.6702922077922078\n",
            "epoch 4 batch id 513 loss 0.6289407014846802 train acc 0.6728801169590644\n",
            "epoch 4 batch id 641 loss 0.7339677810668945 train acc 0.6763845553822153\n",
            "\n",
            "======= S/N : 5 / 10 =======\n",
            "epoch 5 batch id 1 loss 0.506254255771637 train acc 0.8125\n",
            "epoch 5 batch id 129 loss 0.6324405670166016 train acc 0.7068798449612403\n",
            "epoch 5 batch id 257 loss 0.7560708522796631 train acc 0.7154669260700389\n",
            "epoch 5 batch id 385 loss 0.6168025732040405 train acc 0.7183441558441559\n",
            "epoch 5 batch id 513 loss 0.7519000768661499 train acc 0.7201510721247564\n",
            "epoch 5 batch id 641 loss 0.7195969820022583 train acc 0.7200663026521061\n",
            "\n",
            "======= S/N : 6 / 10 =======\n",
            "epoch 6 batch id 1 loss 0.4297921061515808 train acc 0.875\n",
            "epoch 6 batch id 129 loss 0.39783066511154175 train acc 0.7461240310077519\n",
            "epoch 6 batch id 257 loss 0.5590689778327942 train acc 0.7553501945525292\n",
            "epoch 6 batch id 385 loss 0.5136191844940186 train acc 0.7564935064935064\n",
            "epoch 6 batch id 513 loss 0.4713183343410492 train acc 0.7541423001949318\n",
            "epoch 6 batch id 641 loss 0.29755622148513794 train acc 0.7517550702028081\n",
            "\n",
            "======= S/N : 7 / 10 =======\n",
            "epoch 7 batch id 1 loss 0.474023699760437 train acc 0.8125\n",
            "epoch 7 batch id 129 loss 0.41177815198898315 train acc 0.7708333333333334\n",
            "epoch 7 batch id 257 loss 0.3579583466053009 train acc 0.7789396887159533\n",
            "epoch 7 batch id 385 loss 0.5203862190246582 train acc 0.7808441558441559\n",
            "epoch 7 batch id 513 loss 0.3768917918205261 train acc 0.7811890838206628\n",
            "epoch 7 batch id 641 loss 0.5310969352722168 train acc 0.7827613104524181\n",
            "\n",
            "======= S/N : 8 / 10 =======\n",
            "epoch 8 batch id 1 loss 0.3594481348991394 train acc 0.875\n",
            "epoch 8 batch id 129 loss 0.32861316204071045 train acc 0.8091085271317829\n",
            "epoch 8 batch id 257 loss 0.4687267243862152 train acc 0.806420233463035\n",
            "epoch 8 batch id 385 loss 0.3189741373062134 train acc 0.8058441558441558\n",
            "epoch 8 batch id 513 loss 0.5520673990249634 train acc 0.8053118908382066\n",
            "epoch 8 batch id 641 loss 0.6435537338256836 train acc 0.8057722308892356\n",
            "\n",
            "======= S/N : 9 / 10 =======\n",
            "epoch 9 batch id 1 loss 0.46715420484542847 train acc 0.875\n",
            "epoch 9 batch id 129 loss 0.3261219561100006 train acc 0.8168604651162791\n",
            "epoch 9 batch id 257 loss 0.4825662672519684 train acc 0.806420233463035\n",
            "epoch 9 batch id 385 loss 0.5543095469474792 train acc 0.8047077922077922\n",
            "epoch 9 batch id 513 loss 0.44929903745651245 train acc 0.8086013645224172\n",
            "epoch 9 batch id 641 loss 0.4486004412174225 train acc 0.8088923556942278\n",
            "\n",
            "======= S/N : 10 / 10 =======\n",
            "epoch 10 batch id 1 loss 0.46287238597869873 train acc 0.8125\n",
            "epoch 10 batch id 129 loss 0.49275821447372437 train acc 0.812984496124031\n",
            "epoch 10 batch id 257 loss 0.33612868189811707 train acc 0.8115272373540856\n",
            "epoch 10 batch id 385 loss 0.38822078704833984 train acc 0.813474025974026\n",
            "epoch 10 batch id 513 loss 0.5129302740097046 train acc 0.8153021442495126\n",
            "epoch 10 batch id 641 loss 0.3488835096359253 train acc 0.8147425897035881\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= S/N : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_SN.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_SN):\n",
        "    b_input_id_Q = batch[0].to(device)\n",
        "    b_input_mask_Q = batch[1].to(device)\n",
        "    b_input_id_A = batch[2].to(device)\n",
        "    b_input_mask_A = batch[3].to(device)\n",
        "    b_label = batch[4].float().to(device)\n",
        "\n",
        "    optimizer_SN.zero_grad()\n",
        "\n",
        "    b_out = model_SN(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_SN.parameters(), 1.0)\n",
        "\n",
        "    optimizer_SN.step()\n",
        "    scheduler_SN.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  # print(\"\\n======= S/N : Validation =======\")\n",
        "  # print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  # model_SN.eval()\n",
        "  # for step, batch in enumerate(val_dataloader_SN):\n",
        "  #   b_input_id_Q = batch[0].to(device)\n",
        "  #   b_input_mask_Q = batch[1].to(device)\n",
        "  #   b_input_id_A = batch[2].to(device)\n",
        "  #   b_input_mask_A = batch[3].to(device)\n",
        "  #   b_label = batch[4].to(device)\n",
        "\n",
        "  #   with torch.no_grad():\n",
        "  #     b_out = model_SN(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "  #   val_acc += calc_accuracy(b_out, b_label)\n",
        "  # print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_SN, model_SN_dir)\n",
        "del(model_SN)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HSXxePV65R0t"
      },
      "source": [
        "##### 3-4-3. T vs. F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olLJYyH-5R0t",
        "outputId": "df9b3ef7-fa5d-4030-8dd0-5bf194303b87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= T/F : 1 / 10 =======\n",
            "epoch 1 batch id 1 loss 0.6950359344482422 train acc 0.375\n",
            "epoch 1 batch id 129 loss 0.6957096457481384 train acc 0.5092054263565892\n",
            "epoch 1 batch id 257 loss 0.6945512294769287 train acc 0.5080252918287937\n",
            "epoch 1 batch id 385 loss 0.6828789114952087 train acc 0.5159090909090909\n",
            "epoch 1 batch id 513 loss 0.6837758421897888 train acc 0.515229044834308\n",
            "epoch 1 batch id 641 loss 0.688495934009552 train acc 0.516575663026521\n",
            "\n",
            "======= T/F : 2 / 10 =======\n",
            "epoch 2 batch id 1 loss 0.6804612278938293 train acc 0.625\n",
            "epoch 2 batch id 129 loss 0.6863966584205627 train acc 0.5106589147286822\n",
            "epoch 2 batch id 257 loss 0.6868886947631836 train acc 0.5155642023346303\n",
            "epoch 2 batch id 385 loss 0.6883941888809204 train acc 0.5301948051948052\n",
            "epoch 2 batch id 513 loss 0.6990481615066528 train acc 0.5346003898635477\n",
            "epoch 2 batch id 641 loss 0.7167924642562866 train acc 0.5408541341653667\n",
            "\n",
            "======= T/F : 3 / 10 =======\n",
            "epoch 3 batch id 1 loss 0.6528586149215698 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.7005738019943237 train acc 0.5833333333333334\n",
            "epoch 3 batch id 257 loss 0.7154573202133179 train acc 0.5785505836575876\n",
            "epoch 3 batch id 385 loss 0.7613030672073364 train acc 0.5863636363636363\n",
            "epoch 3 batch id 513 loss 0.6499345302581787 train acc 0.5866228070175439\n",
            "epoch 3 batch id 641 loss 0.6523798108100891 train acc 0.5923361934477379\n",
            "\n",
            "======= T/F : 4 / 10 =======\n",
            "epoch 4 batch id 1 loss 0.6776325702667236 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.6100447177886963 train acc 0.6371124031007752\n",
            "epoch 4 batch id 257 loss 0.6530687808990479 train acc 0.6391050583657587\n",
            "epoch 4 batch id 385 loss 0.6654585599899292 train acc 0.6353896103896104\n",
            "epoch 4 batch id 513 loss 0.6207619905471802 train acc 0.6354775828460039\n",
            "epoch 4 batch id 641 loss 0.7012509107589722 train acc 0.6353354134165367\n",
            "\n",
            "======= T/F : 5 / 10 =======\n",
            "epoch 5 batch id 1 loss 0.671148419380188 train acc 0.5625\n",
            "epoch 5 batch id 129 loss 0.7444775700569153 train acc 0.6516472868217055\n",
            "epoch 5 batch id 257 loss 0.6637206077575684 train acc 0.664396887159533\n",
            "epoch 5 batch id 385 loss 0.5439712405204773 train acc 0.660064935064935\n",
            "epoch 5 batch id 513 loss 0.5450876951217651 train acc 0.6642300194931774\n",
            "epoch 5 batch id 641 loss 0.6197788715362549 train acc 0.6641965678627145\n",
            "\n",
            "======= T/F : 6 / 10 =======\n",
            "epoch 6 batch id 1 loss 0.6137806177139282 train acc 0.6875\n",
            "epoch 6 batch id 129 loss 0.6578581929206848 train acc 0.6787790697674418\n",
            "epoch 6 batch id 257 loss 0.47960802912712097 train acc 0.6828793774319066\n",
            "epoch 6 batch id 385 loss 0.42478033900260925 train acc 0.687987012987013\n",
            "epoch 6 batch id 513 loss 0.5534456968307495 train acc 0.6896929824561403\n",
            "epoch 6 batch id 641 loss 0.6512496471405029 train acc 0.6939352574102964\n",
            "\n",
            "======= T/F : 7 / 10 =======\n",
            "epoch 7 batch id 1 loss 0.5963566303253174 train acc 0.6875\n",
            "epoch 7 batch id 129 loss 0.448681116104126 train acc 0.7252906976744186\n",
            "epoch 7 batch id 257 loss 0.5928211212158203 train acc 0.7123054474708171\n",
            "epoch 7 batch id 385 loss 0.6438359022140503 train acc 0.7118506493506493\n",
            "epoch 7 batch id 513 loss 0.801067590713501 train acc 0.7157651072124757\n",
            "epoch 7 batch id 641 loss 0.6806962490081787 train acc 0.7129485179407177\n",
            "\n",
            "======= T/F : 8 / 10 =======\n",
            "epoch 8 batch id 1 loss 0.4203166365623474 train acc 0.8125\n",
            "epoch 8 batch id 129 loss 0.5579043030738831 train acc 0.7349806201550387\n",
            "epoch 8 batch id 257 loss 0.508343517780304 train acc 0.7371108949416343\n",
            "epoch 8 batch id 385 loss 0.5567859411239624 train acc 0.734577922077922\n",
            "epoch 8 batch id 513 loss 0.5864139795303345 train acc 0.7346491228070176\n",
            "epoch 8 batch id 641 loss 0.5901525616645813 train acc 0.734496879875195\n",
            "\n",
            "======= T/F : 9 / 10 =======\n",
            "epoch 9 batch id 1 loss 0.46895623207092285 train acc 0.8125\n",
            "epoch 9 batch id 129 loss 0.6283180713653564 train acc 0.7320736434108527\n",
            "epoch 9 batch id 257 loss 0.4203219413757324 train acc 0.7422178988326849\n",
            "epoch 9 batch id 385 loss 0.5735488533973694 train acc 0.7444805194805195\n",
            "epoch 9 batch id 513 loss 0.5839173793792725 train acc 0.7462231968810916\n",
            "epoch 9 batch id 641 loss 0.48150548338890076 train acc 0.750195007800312\n",
            "\n",
            "======= T/F : 10 / 10 =======\n",
            "epoch 10 batch id 1 loss 0.6867292523384094 train acc 0.6875\n",
            "epoch 10 batch id 129 loss 0.39085134863853455 train acc 0.7596899224806202\n",
            "epoch 10 batch id 257 loss 0.6941825151443481 train acc 0.7580252918287937\n",
            "epoch 10 batch id 385 loss 0.4515378475189209 train acc 0.7532467532467533\n",
            "epoch 10 batch id 513 loss 0.6258360147476196 train acc 0.7569444444444444\n",
            "epoch 10 batch id 641 loss 0.262218713760376 train acc 0.7545826833073322\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= T/F : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_TF.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_TF):\n",
        "    b_input_id_Q = batch[0].to(device)\n",
        "    b_input_mask_Q = batch[1].to(device)\n",
        "    b_input_id_A = batch[2].to(device)\n",
        "    b_input_mask_A = batch[3].to(device)\n",
        "    b_label = batch[4].float().to(device)\n",
        "\n",
        "    optimizer_TF.zero_grad()\n",
        "\n",
        "    b_out = model_TF(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_TF.parameters(), 1.0)\n",
        "\n",
        "    optimizer_TF.step()\n",
        "    scheduler_TF.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  # print(\"\\n======= T/F : Validation =======\")\n",
        "  # print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  # model_TF.eval()\n",
        "  # for step, batch in enumerate(val_dataloader_TF):\n",
        "  #   b_input_id_Q = batch[0].to(device)\n",
        "  #   b_input_mask_Q = batch[1].to(device)\n",
        "  #   b_input_id_A = batch[2].to(device)\n",
        "  #   b_input_mask_A = batch[3].to(device)\n",
        "  #   b_label = batch[4].to(device)\n",
        "\n",
        "  #   with torch.no_grad():\n",
        "  #     b_out = model_TF(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "  #   val_acc += calc_accuracy(b_out, b_label)\n",
        "  # print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_TF, model_TF_dir)\n",
        "del(model_TF)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl1lIvWG5R0t"
      },
      "source": [
        "##### 3-4-4. J vs. P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seLNFZGS5R0u",
        "outputId": "b442d3e5-5ed7-4728-d4ff-68493fbd6186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= J/P : 1 / 10 =======\n",
            "epoch 1 batch id 1 loss 0.6873605847358704 train acc 0.625\n",
            "epoch 1 batch id 129 loss 0.6820535659790039 train acc 0.5048449612403101\n",
            "epoch 1 batch id 257 loss 0.691504716873169 train acc 0.5065661478599222\n",
            "epoch 1 batch id 385 loss 0.692514955997467 train acc 0.500974025974026\n",
            "epoch 1 batch id 513 loss 0.6873648166656494 train acc 0.5015838206627681\n",
            "epoch 1 batch id 641 loss 0.687645673751831 train acc 0.5013650546021841\n",
            "\n",
            "======= J/P : 2 / 10 =======\n",
            "epoch 2 batch id 1 loss 0.6804591417312622 train acc 0.6875\n",
            "epoch 2 batch id 129 loss 0.694011926651001 train acc 0.5387596899224806\n",
            "epoch 2 batch id 257 loss 0.6792239546775818 train acc 0.5474221789883269\n",
            "epoch 2 batch id 385 loss 0.6815439462661743 train acc 0.5423701298701299\n",
            "epoch 2 batch id 513 loss 0.7429770827293396 train acc 0.5423976608187134\n",
            "epoch 2 batch id 641 loss 0.7678124308586121 train acc 0.5497269890795632\n",
            "\n",
            "======= J/P : 3 / 10 =======\n",
            "epoch 3 batch id 1 loss 0.6022226810455322 train acc 0.875\n",
            "epoch 3 batch id 129 loss 0.6706632375717163 train acc 0.5968992248062015\n",
            "epoch 3 batch id 257 loss 0.7025556564331055 train acc 0.5965466926070039\n",
            "epoch 3 batch id 385 loss 0.7052879929542542 train acc 0.5969155844155845\n",
            "epoch 3 batch id 513 loss 0.6554152369499207 train acc 0.5963693957115009\n",
            "epoch 3 batch id 641 loss 0.6699234247207642 train acc 0.5970163806552262\n",
            "\n",
            "======= J/P : 4 / 10 =======\n",
            "epoch 4 batch id 1 loss 0.6116952896118164 train acc 0.75\n",
            "epoch 4 batch id 129 loss 0.6318592429161072 train acc 0.6390503875968992\n",
            "epoch 4 batch id 257 loss 0.619530439376831 train acc 0.6313229571984436\n",
            "epoch 4 batch id 385 loss 0.5205354690551758 train acc 0.6290584415584416\n",
            "epoch 4 batch id 513 loss 0.6221526861190796 train acc 0.6295077972709552\n",
            "epoch 4 batch id 641 loss 0.7346396446228027 train acc 0.6295826833073322\n",
            "\n",
            "======= J/P : 5 / 10 =======\n",
            "epoch 5 batch id 1 loss 0.5787644386291504 train acc 0.75\n",
            "epoch 5 batch id 129 loss 0.5225923657417297 train acc 0.6627906976744186\n",
            "epoch 5 batch id 257 loss 0.6532617807388306 train acc 0.6719357976653697\n",
            "epoch 5 batch id 385 loss 0.5386390089988708 train acc 0.6681818181818182\n",
            "epoch 5 batch id 513 loss 0.47372329235076904 train acc 0.6743421052631579\n",
            "epoch 5 batch id 641 loss 0.7075598239898682 train acc 0.6749219968798752\n",
            "\n",
            "======= J/P : 6 / 10 =======\n",
            "epoch 6 batch id 1 loss 0.5266577005386353 train acc 0.875\n",
            "epoch 6 batch id 129 loss 0.6084340214729309 train acc 0.7170542635658915\n",
            "epoch 6 batch id 257 loss 0.6609996557235718 train acc 0.7108463035019456\n",
            "epoch 6 batch id 385 loss 0.4326760172843933 train acc 0.7123376623376624\n",
            "epoch 6 batch id 513 loss 0.4528064727783203 train acc 0.7158869395711501\n",
            "epoch 6 batch id 641 loss 0.5750459432601929 train acc 0.7145085803432137\n",
            "\n",
            "======= J/P : 7 / 10 =======\n",
            "epoch 7 batch id 1 loss 0.5275031328201294 train acc 0.8125\n",
            "epoch 7 batch id 129 loss 0.6418883204460144 train acc 0.7315891472868217\n",
            "epoch 7 batch id 257 loss 0.7484518885612488 train acc 0.7332198443579766\n",
            "epoch 7 batch id 385 loss 0.7354719638824463 train acc 0.7415584415584415\n",
            "epoch 7 batch id 513 loss 0.45856326818466187 train acc 0.7406189083820662\n",
            "epoch 7 batch id 641 loss 0.5870740413665771 train acc 0.7402496099843994\n",
            "\n",
            "======= J/P : 8 / 10 =======\n",
            "epoch 8 batch id 1 loss 0.32911816239356995 train acc 0.9375\n",
            "epoch 8 batch id 129 loss 0.4954042434692383 train acc 0.7640503875968992\n",
            "epoch 8 batch id 257 loss 0.3616955280303955 train acc 0.7624027237354085\n",
            "epoch 8 batch id 385 loss 0.28637266159057617 train acc 0.7672077922077922\n",
            "epoch 8 batch id 513 loss 0.5886702537536621 train acc 0.7703460038986355\n",
            "epoch 8 batch id 641 loss 0.4800550639629364 train acc 0.7635530421216848\n",
            "\n",
            "======= J/P : 9 / 10 =======\n",
            "epoch 9 batch id 1 loss 0.4011097550392151 train acc 0.8125\n",
            "epoch 9 batch id 129 loss 0.4141350984573364 train acc 0.7824612403100775\n",
            "epoch 9 batch id 257 loss 0.5246400833129883 train acc 0.7796692607003891\n",
            "epoch 9 batch id 385 loss 0.43138015270233154 train acc 0.773538961038961\n",
            "epoch 9 batch id 513 loss 0.36657509207725525 train acc 0.7759502923976608\n",
            "epoch 9 batch id 641 loss 0.9022326469421387 train acc 0.7743759750390016\n",
            "\n",
            "======= J/P : 10 / 10 =======\n",
            "epoch 10 batch id 1 loss 0.6526426076889038 train acc 0.6875\n",
            "epoch 10 batch id 129 loss 0.64159095287323 train acc 0.7800387596899225\n",
            "epoch 10 batch id 257 loss 0.5249775052070618 train acc 0.7774805447470817\n",
            "epoch 10 batch id 385 loss 0.5388355255126953 train acc 0.7748376623376624\n",
            "epoch 10 batch id 513 loss 0.554296612739563 train acc 0.7776559454191033\n",
            "epoch 10 batch id 641 loss 0.43916893005371094 train acc 0.7766185647425897\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= J/P : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_JP.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_JP):\n",
        "    b_input_id_Q = batch[0].to(device)\n",
        "    b_input_mask_Q = batch[1].to(device)\n",
        "    b_input_id_A = batch[2].to(device)\n",
        "    b_input_mask_A = batch[3].to(device)\n",
        "    b_label = batch[4].float().to(device)\n",
        "\n",
        "    optimizer_JP.zero_grad()\n",
        "\n",
        "    b_out = model_JP(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_JP.parameters(), 1.0)\n",
        "\n",
        "    optimizer_JP.step()\n",
        "    scheduler_JP.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  # print(\"\\n======= J/P : Validation =======\")\n",
        "  # print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  # model_JP.eval()\n",
        "  # for step, batch in enumerate(val_dataloader_JP):\n",
        "  #   b_input_id_Q = batch[0].to(device)\n",
        "  #   b_input_mask_Q = batch[1].to(device)\n",
        "  #   b_input_id_A = batch[2].to(device)\n",
        "  #   b_input_mask_A = batch[3].to(device)\n",
        "  #   b_label = batch[4].to(device)\n",
        "\n",
        "  #   with torch.no_grad():\n",
        "  #     b_out = model_JP(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "  #   val_acc += calc_accuracy(b_out, b_label)\n",
        "  # print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_JP, model_JP_dir)\n",
        "del(model_JP)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oISmk_xt5R0u"
      },
      "source": [
        "#### 3-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKT4otMR5R0v",
        "outputId": "6b3cc777-e6ad-4be4-bb57-8514083b7bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids_Q = []\n",
        "att_masks_Q = []\n",
        "\n",
        "input_ids_A = []\n",
        "att_masks_A = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  answer = testing['Answer'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings_Q = tokenizer_bert(\n",
        "      question,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  encodings_A = tokenizer_bert(\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids_Q.append(encodings_Q['input_ids'])\n",
        "  att_masks_Q.append(encodings_Q['attention_mask'])\n",
        "\n",
        "  input_ids_A.append(encodings_A['input_ids'])\n",
        "  att_masks_A.append(encodings_A['attention_mask'])\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids_Q = torch.cat(input_ids_Q, dim=0)\n",
        "att_masks_Q = torch.cat(att_masks_Q, dim=0)\n",
        "\n",
        "input_ids_A = torch.cat(input_ids_A, dim=0)\n",
        "att_masks_A = torch.cat(att_masks_A, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF4CtNR-5R0v"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A)\n",
        "dataset_SN = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A)\n",
        "dataset_TF = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A)\n",
        "dataset_JP = TensorDataset(input_ids_Q, att_masks_Q, input_ids_A, att_masks_A)\n",
        "\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = SequentialSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = SequentialSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = SequentialSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = SequentialSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sTDGM8p5R0v"
      },
      "outputs": [],
      "source": [
        "model_IE = torch.load(model_IE_dir)\n",
        "model_SN = torch.load(model_SN_dir)\n",
        "model_TF = torch.load(model_TF_dir)\n",
        "model_JP = torch.load(model_JP_dir)\n",
        "\n",
        "model_IE.eval()\n",
        "model_SN.eval()\n",
        "model_TF.eval()\n",
        "model_JP.eval()\n",
        "\n",
        "preds_IE = []\n",
        "preds_prob_IE = []\n",
        "preds_SN = []\n",
        "preds_prob_SN = []\n",
        "preds_TF = []\n",
        "preds_prob_TF = []\n",
        "preds_JP = []\n",
        "preds_prob_JP = []\n",
        "\n",
        "# Predict I vs. E\n",
        "for batch in dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_IE = preds_prob_IE + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_IE = preds_IE + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict S vs. N\n",
        "for batch in dataloader_SN:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_SN = preds_prob_SN + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_SN = preds_SN + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict T vs. F\n",
        "for batch in dataloader_TF:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_TF = preds_prob_TF + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_TF = preds_TF + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict J vs. P\n",
        "for batch in dataloader_JP:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id_Q, b_input_mask_Q, b_input_id_A, b_input_mask_A)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_JP = preds_prob_JP + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_JP = preds_JP + np.argmax(b_out_np, axis=1).flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPZGqzqf5R0v"
      },
      "outputs": [],
      "source": [
        "idx = range(1, len(preds_IE) + 1)\n",
        "preds = {'idx': idx,'I/E': preds_IE, 'S/N':preds_SN, 'T/F':preds_TF, 'J/P':preds_JP}\n",
        "preds = pd.DataFrame(data=preds)\n",
        "preds = preds.set_index('idx')\n",
        "preds.to_csv('result.csv')\n",
        "\n",
        "preds_prob = {'idx': idx,'I/E': preds_prob_IE, 'S/N':preds_prob_SN, 'T/F':preds_prob_TF, 'J/P':preds_prob_JP}\n",
        "preds_prob = pd.DataFrame(data=preds_prob)\n",
        "preds_prob = preds_prob.set_index('idx')\n",
        "preds_prob.to_csv('result_prob.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2chO2kJvNHy"
      },
      "source": [
        "#### Google?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd49U7UQtliv"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 465 in tokens, so set max_length as 600, safely\n",
        "max_len = 500\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  question = training['Question'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnRXbtG8t-Qn"
      },
      "outputs": [],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBJEksD3uhrx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d34LOikUupEx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, labels_JP)\n",
        "\n",
        "train_size = int(0.8 * len(dataset_IE))\n",
        "val_size = int(0.1 * len(dataset_IE))\n",
        "test_size = len(dataset_IE) - train_size - val_size\n",
        "\n",
        "print(f\"lengths are {train_size}:{val_size}:{test_size}\")\n",
        "\n",
        "# Split into train dataset, validation dataset and test dataset.\n",
        "train_dataset_IE, val_dataset_IE, test_dataset_IE = random_split(dataset_IE, [train_size, val_size, test_size])\n",
        "train_dataset_SN, val_dataset_SN, test_dataset_SN = random_split(dataset_SN, [train_size, val_size, test_size])\n",
        "train_dataset_TF, val_dataset_TF, test_dataset_TF = random_split(dataset_TF, [train_size, val_size, test_size])\n",
        "train_dataset_JP, val_dataset_JP, test_dataset_JP = random_split(dataset_JP, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataloader_IE = DataLoader(\n",
        "    train_dataset_IE,\n",
        "    sampler = RandomSampler(train_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_IE = DataLoader (\n",
        "    val_dataset_IE,\n",
        "    sampler = SequentialSampler(val_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_IE = DataLoader (\n",
        "    test_dataset_IE,\n",
        "    sampler = SequentialSampler(test_dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_SN = DataLoader(\n",
        "    train_dataset_SN,\n",
        "    sampler = RandomSampler(train_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_SN = DataLoader (\n",
        "    val_dataset_SN,\n",
        "    sampler = SequentialSampler(val_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_SN = DataLoader (\n",
        "    test_dataset_SN,\n",
        "    sampler = SequentialSampler(test_dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_TF = DataLoader(\n",
        "    train_dataset_TF,\n",
        "    sampler = RandomSampler(train_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_TF = DataLoader (\n",
        "    val_dataset_TF,\n",
        "    sampler = SequentialSampler(val_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_TF = DataLoader (\n",
        "    test_dataset_TF,\n",
        "    sampler = SequentialSampler(test_dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "train_dataloader_JP = DataLoader(\n",
        "    train_dataset_JP,\n",
        "    sampler = RandomSampler(train_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_dataloader_JP = DataLoader (\n",
        "    val_dataset_JP,\n",
        "    sampler = SequentialSampler(val_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_dataloader_JP = DataLoader (\n",
        "    test_dataset_JP,\n",
        "    sampler = SequentialSampler(test_dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE0TyFaQuuSI"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, get_linear_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.lin = nn.Linear(hidden_size, 512)\n",
        "    self.lin2 = nn.Linear(512, 256)\n",
        "    self.lin3 = nn.Linear(256, 64)\n",
        "    self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    # Model 0.\n",
        "    # self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    # Model 1.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.lin2 = nn.Linear(256, 128)\n",
        "    # self.lin3 = nn.Linear(128, 64)\n",
        "    # self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    # Model 2.\n",
        "    # self.lin = nn.Linear(hidden_size, 256)\n",
        "    # self.lin2 = nn.Linear(256, 128)\n",
        "    # self.lin3 = nn.Linear(128, 64)\n",
        "    # self.lin4 = nn.Linear(64, num_classes)\n",
        "    # self.classifier = nn.Softmax(dim=0)\n",
        "\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "    \n",
        "    lin_output = self.lin(dr_output)\n",
        "    lin2_output = self.lin2(lin_output)\n",
        "    lin3_output = self.lin3(lin2_output)\n",
        "    return self.classifier(lin3_output)\n",
        "\n",
        "    # Model 0.\n",
        "    # return self.classifier(dr_output)\n",
        "\n",
        "    # Model 1.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # lin2_output = self.lin2(lin_output)\n",
        "    # lin3_output = self.lin3(lin2_output)\n",
        "    # return self.classifier(lin3_output)\n",
        "\n",
        "    # Model 2.\n",
        "    # lin_output = self.lin(dr_output)\n",
        "    # lin2_output = self.lin2(lin_output)\n",
        "    # lin3_output = self.lin3(lin2_output)\n",
        "    # lin4_output = self.lin4(lin3_output)\n",
        "    # return self.classifier(lin4_output)\n",
        "\n",
        "model_bert = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert, dr_rate = 0.3)\n",
        "\n",
        "optimizer_IE = AdamW(model_IE.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = AdamW(model_SN.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = AdamW(model_TF.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = AdamW(model_JP.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4 # 2 or 4\n",
        "\n",
        "total_steps = len(train_dataloader_IE) * epochs\n",
        "\n",
        "scheduler_IE = get_linear_schedule_with_warmup(optimizer_IE, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "scheduler_SN = get_linear_schedule_with_warmup(optimizer_SN, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "scheduler_TF = get_linear_schedule_with_warmup(optimizer_TF, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "scheduler_JP = get_linear_schedule_with_warmup(optimizer_JP, num_warmup_steps = 0, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjgi5bzSu2z5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# def calc_accuracy(X,Y):\n",
        "#     max_vals, max_indices = torch.max(X, 1)\n",
        "#     train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "#     return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUwB9fDuu5ST"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  print(\"\\n======= I/E : Validation =======\")\n",
        "  print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "  model_IE.eval()\n",
        "  for step, batch in enumerate(val_dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_label = batch[2].to(device)\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask)\n",
        "    val_acc += calc_accuracy(b_out, b_label)\n",
        "  print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# Test\n",
        "model_IE.eval()\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in test_dataloader_IE:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_id, b_input_mask, b_label = batch\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  b_label_np = b_label.detach().cpu().numpy()\n",
        "  preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"\\n======= I/E : Test =======\")\n",
        "print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ia-vXwEdc5VZ"
      },
      "source": [
        "### 4. BASELINE + AGE (Submitted Model!)\n",
        "This time, add 'age' as the input"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3LLsdk8zdGFW"
      },
      "source": [
        "#### 4-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Qz4RT0C-dGFX",
        "outputId": "8ac58505-1fdd-465f-85f7-18c9d0a16a60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-886539c2-0632-439c-a01d-194824787b72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-886539c2-0632-439c-a01d-194824787b72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-886539c2-0632-439c-a01d-194824787b72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-886539c2-0632-439c-a01d-194824787b72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Es8_8HBYdGFX",
        "outputId": "3304372f-54b9-466b-b582-c5dbfb5e842d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-968405c3-4fda-4b71-9344-61a3151eb7fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Age</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
              "      <td>30</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
              "      <td>30</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
              "      <td>30</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
              "      <td>30</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
              "      <td>30</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-968405c3-4fda-4b71-9344-61a3151eb7fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-968405c3-4fda-4b71-9344-61a3151eb7fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-968405c3-4fda-4b71-9344-61a3151eb7fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...   \n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...   \n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...   \n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.   \n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.   \n",
              "\n",
              "                                              Answer  Age  MBTI  \n",
              "0  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...   30  INFP  \n",
              "1  <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...   30  INFP  \n",
              "2  <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...   30  INFP  \n",
              "3  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...   30  INFP  \n",
              "4  <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...   30  INFP  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "\n",
        "training = pd.read_csv(os.path.join(root_dir, train_dir), encoding=\"CP949\")\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Gender'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Answer', 'Age', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4nCyV8SndGFY",
        "outputId": "aeb1e2d9-aca8-4420-8f5f-ddd7397e9e20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-12ef4ea8-5119-4b70-b493-b4864cf293e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.</td>\n",
              "      <td>&lt;아니다&gt; 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...</td>\n",
              "      <td>&lt;중립&gt; 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...</td>\n",
              "      <td>&lt;그렇다&gt; 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.</td>\n",
              "      <td>&lt;그렇다&gt; 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.</td>\n",
              "      <td>&lt;중립&gt; 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12ef4ea8-5119-4b70-b493-b4864cf293e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12ef4ea8-5119-4b70-b493-b4864cf293e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12ef4ea8-5119-4b70-b493-b4864cf293e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0                     마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.   \n",
              "1  조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...   \n",
              "2  단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...   \n",
              "3    일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.   \n",
              "4         대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.   \n",
              "\n",
              "                                              Answer  Age  \n",
              "0  <아니다> 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...   30  \n",
              "1  <중립> 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...   40  \n",
              "2  <그렇다> 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...   40  \n",
              "3  <그렇다> 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...   40  \n",
              "4  <중립> 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...   30  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_csv(os.path.join(root_dir, test_dir), encoding=\"CP949\")\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Gender'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['Question', 'Answer', 'Age']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAqgNJGdgwK"
      },
      "source": [
        "#### 4-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "2c112e18eb3141e6a8f5bd28f3ad7649",
            "193909d95f0240b8b4454dea37205f78",
            "fe85e4863273498fa21968929db13755",
            "dcafd6ba0d96450d8406e78ba6f7621b",
            "d9b71b7cbd9e409bb3d7658fc548c347",
            "9f3493099bc74c5397ef4314bd0801d4",
            "ccd3c75325fe40068c3c0f5aad118169",
            "7524089cb5ce4a4d9343c0decd53b2ba",
            "df965057c5da44ab9c21ffa4f12a1db8",
            "31bfc49f7a5d444cae6b924963f1584f",
            "0fb60144db4943df851134e8088eeac1",
            "3e94eeebfed9493c88961914437532a1",
            "1047f42ba6f6496a96ca544efcef2d5e",
            "0fa88787afac4f0897308b2f56f117da",
            "6455ef8005ee405aaca37b069c0b8d2b",
            "df227ea2cafc49189e72f224bc49fa7d",
            "b7ee3f6d38194482af3310e9d0920b0c",
            "4f3944c736a948c4ac9c1f1bd5e91e69",
            "27089c0ff2a1490b89e013199e0846ad",
            "9cfbde0070de4cb8a024fbb0188696f9",
            "684356e428334eb48ac3cb596430e69b",
            "b933947e1398495287f131ca08a1823b",
            "fc6fafcfb2a5455e80898f31da6d93c2",
            "b5905ce2b26542bd950190eef243fe4b",
            "3635ac7aab7640a080a0d24ef0360515",
            "fc20f0dff5bf4ae98e38948f5f93a8e8",
            "faf70ebe806d4368a6e77bbc1376d7c1",
            "9f4f679916db4aa1b5cd2215d38fd2a0",
            "83b357c82c444f57b7f590f1eabd5fe4",
            "8d5619a62e7b4f67b43ffd1647d7963b",
            "b55d69dfea494a11a804f1f6c5b19f7b",
            "d1e800112f90461ab51fda1a02ae3b96",
            "469365e6ac7340cd85a03e59c9552216"
          ]
        },
        "id": "ZLWTyiWldgwM",
        "outputId": "92fa679b-784e-438c-bdcc-757bd198bd37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c112e18eb3141e6a8f5bd28f3ad7649",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e94eeebfed9493c88961914437532a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc6fafcfb2a5455e80898f31da6d93c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 206 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "ages = []\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  question = training['Question'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  age = training['Age'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  ages.append(torch.tensor([[age]]))\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "ages = torch.cat(ages, dim=0)\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vugdn9_LdgwN",
        "outputId": "14f6957d-d79d-4294-8af1-353f153bc8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2, 25753, 14567, 28897, 18069, 14526,  2033, 19742, 22742,  8082,\n",
            "        31724,  3463, 32771,  8061, 19773, 16941, 24296,  8055,  2016,     3,\n",
            "         2030, 15345,  2032, 18430,  3463,  5724,  8423, 26850, 20699, 14204,\n",
            "        15916, 17729, 25878, 18895, 14045, 27024,  8107, 28669,  8120,  6266,\n",
            "        24832,  2016,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([30])\n",
            "tensor([1, 0])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "11520 11520 11520 11520\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(ages[0])\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(ages), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny-u52DcdgwO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0u6Rr5l7dgwO"
      },
      "source": [
        "#### 4-2. Data Split\n",
        "Currently, we do not have the answers for testing dataset, so we must split the training data to evaluate our model. (18:1:1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQBTZ0LddgwP"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, ages, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, ages, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, ages, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, ages, labels_JP)\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = RandomSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = RandomSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = RandomSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = RandomSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "# \"\"train_size = int(0.9 * len(dataset_IE))\n",
        "# val_size = int(0.05 * len(dataset_IE))\n",
        "# test_size = len(dataset_IE) - train_size - val_size\n",
        "\n",
        "# print(f\"lengths are {train_size}:{val_size}:{test_size}\")\n",
        "\n",
        "# # Split into train dataset, validation dataset and test dataset.\n",
        "# train_dataset_IE, val_dataset_IE, test_dataset_IE = random_split(dataset_IE, [train_size, val_size, test_size])\n",
        "# train_dataset_SN, val_dataset_SN, test_dataset_SN = random_split(dataset_SN, [train_size, val_size, test_size])\n",
        "# train_dataset_TF, val_dataset_TF, test_dataset_TF = random_split(dataset_TF, [train_size, val_size, test_size])\n",
        "# train_dataset_JP, val_dataset_JP, test_dataset_JP = random_split(dataset_JP, [train_size, val_size, test_size])\n",
        "\n",
        "# batch_size = 16 # 16 or 32\n",
        "\n",
        "# # Define dataloaders\n",
        "# train_dataloader_IE = DataLoader(\n",
        "#     train_dataset_IE,\n",
        "#     sampler = RandomSampler(train_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_IE = DataLoader (\n",
        "#     val_dataset_IE,\n",
        "#     sampler = SequentialSampler(val_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_IE = DataLoader (\n",
        "#     test_dataset_IE,\n",
        "#     sampler = SequentialSampler(test_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_SN = DataLoader(\n",
        "#     train_dataset_SN,\n",
        "#     sampler = RandomSampler(train_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_SN = DataLoader (\n",
        "#     val_dataset_SN,\n",
        "#     sampler = SequentialSampler(val_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_SN = DataLoader (\n",
        "#     test_dataset_SN,\n",
        "#     sampler = SequentialSampler(test_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_TF = DataLoader(\n",
        "#     train_dataset_TF,\n",
        "#     sampler = RandomSampler(train_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_TF = DataLoader (\n",
        "#     val_dataset_TF,\n",
        "#     sampler = SequentialSampler(val_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_TF = DataLoader (\n",
        "#     test_dataset_TF,\n",
        "#     sampler = SequentialSampler(test_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_JP = DataLoader(\n",
        "#     train_dataset_JP,\n",
        "#     sampler = RandomSampler(train_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_JP = DataLoader (\n",
        "#     val_dataset_JP,\n",
        "#     sampler = SequentialSampler(val_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_JP = DataLoader (\n",
        "#     test_dataset_JP,\n",
        "#     sampler = SequentialSampler(test_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z-6gP2JldgwP"
      },
      "source": [
        "#### 4-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "2bfe16b12e65411f998e1bccff382486",
            "eee870da3041427d870266d640ccdb25",
            "dd7566a5ed854fa8b23ab6d661cf6a49",
            "5adbafcd77f54b81a91cc7b5254150a3",
            "31d86153f4bf4c1197003a31064cd098",
            "1bb4f6412f48454fac0eba12352e22ed",
            "36e0fe9f289a48778758124a2600fb56",
            "6a3ecd0fb03c49bfb391bfcf7b1ade5e",
            "0e122a61a3954c41b02d5be7ed1c2802",
            "95f1dd2b0c9843a6a22b914cf218312f",
            "8d677659a9e0466aa535bd04f87ea4f1"
          ]
        },
        "id": "UiqupNc3dgwQ",
        "outputId": "2edc96d8-5da8-4d54-d60e-1f903e96922d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bfe16b12e65411f998e1bccff382486",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.linstr = nn.Linear(hidden_size, (int)(hidden_size * (127 / 128)))\n",
        "    self.linage = nn.Linear(1, hidden_size - (int)(hidden_size * (127 / 128)))\n",
        "    self.lin = nn.Linear(hidden_size, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(128, num_classes)\n",
        "    self.classifier = nn.Softmax(dim = 1)\n",
        "\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks, ages):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "\n",
        "    linstr_output = self.linstr(dr_output)\n",
        "    linage_output = self.linage(ages)\n",
        "\n",
        "    age_added = torch.cat((linstr_output, linage_output), dim=1)\n",
        "\n",
        "    lin_output = self.lin(age_added)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "    \n",
        "    return self.classifier(lin2_output)\n",
        "\n",
        "model_bert_IE = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert_IE, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert_SN, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert_TF, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert_JP, dr_rate = 0.3)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters_IE = [\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_SN = [\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_TF = [\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_JP = [\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "learning_rate = 2e-5\n",
        "\n",
        "optimizer_IE = AdamW(optimizer_grouped_parameters_IE,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = AdamW(optimizer_grouped_parameters_SN,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = AdamW(optimizer_grouped_parameters_TF,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = AdamW(optimizer_grouped_parameters_JP,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4 # 2 or 4\n",
        "\n",
        "total_steps = len(dataloader_IE) * epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "scheduler_IE = get_cosine_schedule_with_warmup(optimizer_IE, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_SN = get_cosine_schedule_with_warmup(optimizer_SN, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_TF = get_cosine_schedule_with_warmup(optimizer_TF, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_JP = get_cosine_schedule_with_warmup(optimizer_JP, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lw9nSDVfdgwQ"
      },
      "source": [
        "#### 4-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUx9Ww9jdgwQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "feRPcgJWdgwR"
      },
      "source": [
        "##### 4-4-1. I vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PLb7aFDdgwS",
        "outputId": "869ff9bc-504e-49b6-b79e-67ed2229949e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.7194489240646362 train acc 0.3125\n",
            "epoch 1 batch id 129 loss 0.6795001029968262 train acc 0.5310077519379846\n",
            "epoch 1 batch id 257 loss 0.6759179830551147 train acc 0.5445038910505836\n",
            "epoch 1 batch id 385 loss 0.6805075407028198 train acc 0.5573051948051948\n",
            "epoch 1 batch id 513 loss 0.7062772512435913 train acc 0.5666423001949318\n",
            "epoch 1 batch id 641 loss 0.60877525806427 train acc 0.5750780031201248\n",
            "\n",
            "======= I/E : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6210188269615173 train acc 0.75\n",
            "epoch 2 batch id 129 loss 0.6021895408630371 train acc 0.6778100775193798\n",
            "epoch 2 batch id 257 loss 0.6020365357398987 train acc 0.6629377431906615\n",
            "epoch 2 batch id 385 loss 0.6168845295906067 train acc 0.6618506493506493\n",
            "epoch 2 batch id 513 loss 0.5124933123588562 train acc 0.6648391812865497\n",
            "epoch 2 batch id 641 loss 0.5566591620445251 train acc 0.6646840873634945\n",
            "\n",
            "======= I/E : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5883232951164246 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.46246060729026794 train acc 0.751453488372093\n",
            "epoch 3 batch id 257 loss 0.44117552042007446 train acc 0.754863813229572\n",
            "epoch 3 batch id 385 loss 0.4877300262451172 train acc 0.7603896103896104\n",
            "epoch 3 batch id 513 loss 0.5882309079170227 train acc 0.7632797270955166\n",
            "epoch 3 batch id 641 loss 0.514145016670227 train acc 0.766575663026521\n",
            "\n",
            "======= I/E : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.45401930809020996 train acc 0.875\n",
            "epoch 4 batch id 129 loss 0.5854650735855103 train acc 0.8304263565891473\n",
            "epoch 4 batch id 257 loss 0.4542427062988281 train acc 0.8280642023346303\n",
            "epoch 4 batch id 385 loss 0.561932384967804 train acc 0.8284090909090909\n",
            "epoch 4 batch id 513 loss 0.44486144185066223 train acc 0.8291910331384016\n",
            "epoch 4 batch id 641 loss 0.4146255850791931 train acc 0.8327808112324493\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_IE, model_IE_dir)\n",
        "del(model_IE)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "igqJy1xGdgwS"
      },
      "source": [
        "##### 4-4-2. S vs. N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtphn6s2dgwS",
        "outputId": "bbae2ae5-56dc-4771-de0f-6211f2b50ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= S/N : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.687963604927063 train acc 0.5\n",
            "epoch 1 batch id 129 loss 0.7039042115211487 train acc 0.5067829457364341\n",
            "epoch 1 batch id 257 loss 0.6926409006118774 train acc 0.5175097276264592\n",
            "epoch 1 batch id 385 loss 0.7238081693649292 train acc 0.5188311688311689\n",
            "epoch 1 batch id 513 loss 0.6786636710166931 train acc 0.5142543859649122\n",
            "epoch 1 batch id 641 loss 0.6723315715789795 train acc 0.5141380655226209\n",
            "\n",
            "======= S/N : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6336004137992859 train acc 0.75\n",
            "epoch 2 batch id 129 loss 0.671259880065918 train acc 0.6027131782945736\n",
            "epoch 2 batch id 257 loss 0.7547507286071777 train acc 0.601896887159533\n",
            "epoch 2 batch id 385 loss 0.6676262021064758 train acc 0.5998376623376623\n",
            "epoch 2 batch id 513 loss 0.7391057014465332 train acc 0.6048976608187134\n",
            "epoch 2 batch id 641 loss 0.6585123538970947 train acc 0.6054017160686428\n",
            "\n",
            "======= S/N : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6320949196815491 train acc 0.625\n",
            "epoch 3 batch id 129 loss 0.5564478635787964 train acc 0.6957364341085271\n",
            "epoch 3 batch id 257 loss 0.5771166086196899 train acc 0.693579766536965\n",
            "epoch 3 batch id 385 loss 0.45514625310897827 train acc 0.7011363636363637\n",
            "epoch 3 batch id 513 loss 0.6257954835891724 train acc 0.7017543859649122\n",
            "epoch 3 batch id 641 loss 0.656299352645874 train acc 0.7073907956318253\n",
            "\n",
            "======= S/N : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.581279456615448 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.5228753089904785 train acc 0.7950581395348837\n",
            "epoch 4 batch id 257 loss 0.5137299299240112 train acc 0.7855058365758755\n",
            "epoch 4 batch id 385 loss 0.46244779229164124 train acc 0.7849025974025974\n",
            "epoch 4 batch id 513 loss 0.6009995937347412 train acc 0.7827729044834308\n",
            "epoch 4 batch id 641 loss 0.5347466468811035 train acc 0.7853939157566303\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= S/N : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_SN.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_SN.zero_grad()\n",
        "\n",
        "    b_out = model_SN(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_SN.parameters(), 1.0)\n",
        "\n",
        "    optimizer_SN.step()\n",
        "    scheduler_SN.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "  #   print(\"\\n======= S/N : Validation =======\")\n",
        "  #   print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "    \n",
        "  #   model_SN.eval()\n",
        "  #   for step, batch in enumerate(val_dataloader_SN):\n",
        "  #     b_input_id = batch[0].to(device)\n",
        "  #     b_input_mask = batch[1].to(device)\n",
        "  #     b_age = batch[2].to(device)\n",
        "  #     b_label = batch[3].to(device)\n",
        "\n",
        "  #     b_out = model_IE(b_input_id, b_input_mask, b_age)\n",
        "  #     val_acc += calc_accuracy(b_out, b_label)\n",
        "  #   print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "  # # Test\n",
        "  # model_SN.eval()\n",
        "  # preds = []\n",
        "  # labels = []\n",
        "\n",
        "  # for batch in test_dataloader_SN:\n",
        "  #   batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  #   b_input_id, b_input_mask, b_age, b_label = batch\n",
        "  #   with torch.no_grad():\n",
        "  #       b_out = model_IE(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "  #   b_out_np = b_out.detach().cpu().numpy()\n",
        "  #   b_label_np = b_label.detach().cpu().numpy()\n",
        "  #   preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "  #   labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "  # preds = np.array(preds)\n",
        "  # labels = np.array(labels)\n",
        "\n",
        "  # print(\"\\n======= S/N : Test =======\")\n",
        "  # print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "torch.save(model_SN, model_SN_dir)\n",
        "del(model_SN)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "weazlN-tdgwT"
      },
      "source": [
        "##### 4-4-3. T vs. F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRdECvLtdgwT",
        "outputId": "d17fc99b-eb5b-4d30-9515-5e5aa65f3ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= T/F : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6931931376457214 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.6895471811294556 train acc 0.5092054263565892\n",
            "epoch 1 batch id 257 loss 0.6907410621643066 train acc 0.5080252918287937\n",
            "epoch 1 batch id 385 loss 0.668999969959259 train acc 0.5178571428571429\n",
            "epoch 1 batch id 513 loss 0.6740896701812744 train acc 0.533625730994152\n",
            "epoch 1 batch id 641 loss 0.6554639339447021 train acc 0.5405616224648986\n",
            "\n",
            "======= T/F : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7444543838500977 train acc 0.4375\n",
            "epoch 2 batch id 129 loss 0.5511295795440674 train acc 0.6182170542635659\n",
            "epoch 2 batch id 257 loss 0.661710262298584 train acc 0.6164883268482491\n",
            "epoch 2 batch id 385 loss 0.7881341576576233 train acc 0.6196428571428572\n",
            "epoch 2 batch id 513 loss 0.6297006011009216 train acc 0.6207358674463938\n",
            "epoch 2 batch id 641 loss 0.6734533905982971 train acc 0.6229524180967239\n",
            "\n",
            "======= T/F : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6386224031448364 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.6151292324066162 train acc 0.7059108527131783\n",
            "epoch 3 batch id 257 loss 0.586573600769043 train acc 0.704523346303502\n",
            "epoch 3 batch id 385 loss 0.7595279216766357 train acc 0.7178571428571429\n",
            "epoch 3 batch id 513 loss 0.6403175592422485 train acc 0.7178362573099415\n",
            "epoch 3 batch id 641 loss 0.6761391162872314 train acc 0.719188767550702\n",
            "\n",
            "======= T/F : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.48896580934524536 train acc 0.875\n",
            "epoch 4 batch id 129 loss 0.587510347366333 train acc 0.7868217054263565\n",
            "epoch 4 batch id 257 loss 0.42488718032836914 train acc 0.7891536964980544\n",
            "epoch 4 batch id 385 loss 0.45939409732818604 train acc 0.7928571428571428\n",
            "epoch 4 batch id 513 loss 0.5597132444381714 train acc 0.7951998050682261\n",
            "epoch 4 batch id 641 loss 0.5008558630943298 train acc 0.7935842433697348\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= T/F : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_TF.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_TF.zero_grad()\n",
        "\n",
        "    b_out = model_TF(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_TF.parameters(), 1.0)\n",
        "\n",
        "    optimizer_TF.step()\n",
        "    scheduler_TF.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "#   print(\"\\n======= T/F : Validation =======\")\n",
        "#   print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "#   model_TF.eval()\n",
        "#   for step, batch in enumerate(val_dataloader_TF):\n",
        "#     b_input_id = batch[0].to(device)\n",
        "#     b_input_mask = batch[1].to(device)\n",
        "#     b_age = batch[2].to(device)\n",
        "#     b_label = batch[3].to(device)\n",
        "\n",
        "#     b_out = model_TF(b_input_id, b_input_mask, b_age)\n",
        "#     val_acc += calc_accuracy(b_out, b_label)\n",
        "#   print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# # Test\n",
        "# model_TF.eval()\n",
        "# preds = []\n",
        "# labels = []\n",
        "\n",
        "# for batch in test_dataloader_TF:\n",
        "#   batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "#   b_input_id, b_input_mask, b_age, b_label = batch\n",
        "#   with torch.no_grad():\n",
        "#       b_out = model_TF(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "#   b_out_np = b_out.detach().cpu().numpy()\n",
        "#   b_label_np = b_label.detach().cpu().numpy()\n",
        "#   preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "#   labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds = np.array(preds)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# print(\"\\n======= T/F : Test =======\")\n",
        "# print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "torch.save(model_TF, model_TF_dir)\n",
        "del(model_TF)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D78BVibBdgwT"
      },
      "source": [
        "##### 4-4-4. J vs. P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZT7A4zVdgwU",
        "outputId": "baec002e-5477-4d9a-8edf-b0e1581dae25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= J/P : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6815391778945923 train acc 0.6875\n",
            "epoch 1 batch id 129 loss 0.7205455303192139 train acc 0.4844961240310077\n",
            "epoch 1 batch id 257 loss 0.6941466331481934 train acc 0.48662451361867703\n",
            "epoch 1 batch id 385 loss 0.708249568939209 train acc 0.5030844155844156\n",
            "epoch 1 batch id 513 loss 0.6934715509414673 train acc 0.5120614035087719\n",
            "epoch 1 batch id 641 loss 0.7067888975143433 train acc 0.5218408736349454\n",
            "\n",
            "======= J/P : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6871119141578674 train acc 0.4375\n",
            "epoch 2 batch id 129 loss 0.5505716800689697 train acc 0.6061046511627907\n",
            "epoch 2 batch id 257 loss 0.6656162738800049 train acc 0.6077334630350194\n",
            "epoch 2 batch id 385 loss 0.6202939748764038 train acc 0.6092532467532468\n",
            "epoch 2 batch id 513 loss 0.7046873569488525 train acc 0.6122076023391813\n",
            "epoch 2 batch id 641 loss 0.7349381446838379 train acc 0.6135920436817472\n",
            "\n",
            "======= J/P : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6387790441513062 train acc 0.6875\n",
            "epoch 3 batch id 129 loss 0.5102549195289612 train acc 0.7122093023255814\n",
            "epoch 3 batch id 257 loss 0.7217386960983276 train acc 0.7178988326848249\n",
            "epoch 3 batch id 385 loss 0.4371684789657593 train acc 0.7172077922077922\n",
            "epoch 3 batch id 513 loss 0.5363610982894897 train acc 0.7240497076023392\n",
            "epoch 3 batch id 641 loss 0.5257965326309204 train acc 0.7225039001560063\n",
            "\n",
            "======= J/P : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.5081303119659424 train acc 0.8125\n",
            "epoch 4 batch id 129 loss 0.4600812792778015 train acc 0.8037790697674418\n",
            "epoch 4 batch id 257 loss 0.3804541826248169 train acc 0.7969357976653697\n",
            "epoch 4 batch id 385 loss 0.6244236826896667 train acc 0.8008116883116884\n",
            "epoch 4 batch id 513 loss 0.4142385721206665 train acc 0.8022660818713451\n",
            "epoch 4 batch id 641 loss 0.5729209780693054 train acc 0.8010920436817472\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= J/P : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_JP.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_JP.zero_grad()\n",
        "\n",
        "    b_out = model_JP(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_JP.parameters(), 1.0)\n",
        "\n",
        "    optimizer_JP.step()\n",
        "    scheduler_JP.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "#   print(\"\\n======= J/P : Validation =======\")\n",
        "#   print(\"epoch {} train acc {}\".format(epoch + 1, train_acc / (step + 1)))\n",
        "  \n",
        "#   model_JP.eval()\n",
        "#   for step, batch in enumerate(val_dataloader_SN):\n",
        "#     b_input_id = batch[0].to(device)\n",
        "#     b_input_mask = batch[1].to(device)\n",
        "#     b_age = batch[2].to(device)\n",
        "#     b_label = batch[3].to(device)\n",
        "\n",
        "#     b_out = model_JP(b_input_id, b_input_mask, b_age)\n",
        "#     val_acc += calc_accuracy(b_out, b_label)\n",
        "#   print(\"epoch {} validation acc {}\".format(epoch + 1, val_acc / (step + 1)))\n",
        "\n",
        "# # Test\n",
        "# model_JP.eval()\n",
        "# preds = []\n",
        "# labels = []\n",
        "\n",
        "# for batch in test_dataloader_JP:\n",
        "#   batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "#   b_input_id, b_input_mask, b_age, b_label = batch\n",
        "#   with torch.no_grad():\n",
        "#       b_out = model_JP(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "#   b_out_np = b_out.detach().cpu().numpy()\n",
        "#   b_label_np = b_label.detach().cpu().numpy()\n",
        "#   preds = preds + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "#   labels = labels + np.argmax(b_label_np, axis=1).flatten().tolist()\n",
        "\n",
        "# preds = np.array(preds)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# print(\"\\n======= J/P : Test =======\")\n",
        "# print(f\"Test Accuracy: {np.sum(preds == labels) / len(labels)}\")\n",
        "\n",
        "torch.save(model_JP, model_JP_dir)\n",
        "del(model_JP)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ek-hKMBfdgwV"
      },
      "source": [
        "#### 4-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGwgQnbRdgwV",
        "outputId": "0f9d7117-6350-4f1e-e6e6-357c9c637293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "ages = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  answer = testing['Answer'][idx]\n",
        "  age = training['Age'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  ages.append(torch.tensor([[age]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "ages = torch.cat(ages, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFWHwnSkdgwV"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, ages)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, ages)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, ages)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, ages)\n",
        "\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = SequentialSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = SequentialSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = SequentialSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = SequentialSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC2K83SpdgwW"
      },
      "outputs": [],
      "source": [
        "model_IE = torch.load(model_IE_dir)\n",
        "model_SN = torch.load(model_SN_dir)\n",
        "model_TF = torch.load(model_TF_dir)\n",
        "model_JP = torch.load(model_JP_dir)\n",
        "\n",
        "model_IE.eval()\n",
        "model_SN.eval()\n",
        "model_TF.eval()\n",
        "model_JP.eval()\n",
        "\n",
        "preds_IE = []\n",
        "preds_prob_IE = []\n",
        "preds_SN = []\n",
        "preds_prob_SN = []\n",
        "preds_TF = []\n",
        "preds_prob_TF = []\n",
        "preds_JP = []\n",
        "preds_prob_JP = []\n",
        "\n",
        "# Predict I vs. E\n",
        "for batch in dataloader_IE:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_age = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_IE = preds_prob_IE + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_IE = preds_IE + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict S vs. N\n",
        "for batch in dataloader_SN:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_age = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_SN = preds_prob_SN + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_SN = preds_SN + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict T vs. F\n",
        "for batch in dataloader_TF:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_age = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_TF = preds_prob_TF + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_TF = preds_TF + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict J vs. P\n",
        "for batch in dataloader_JP:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_age = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_age)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_JP = preds_prob_JP + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_JP = preds_JP + np.argmax(b_out_np, axis=1).flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sprln2OudgwW"
      },
      "outputs": [],
      "source": [
        "idx = range(1, len(preds_IE) + 1)\n",
        "\n",
        "preds = {'idx': idx,'I/E': preds_IE, 'S/N':preds_SN, 'T/F':preds_TF, 'J/P':preds_JP}\n",
        "preds = pd.DataFrame(data=preds)\n",
        "preds = preds.set_index('idx')\n",
        "preds.to_csv('result.csv')\n",
        "\n",
        "preds_prob = {'idx': idx,'I/E': preds_prob_IE, 'S/N':preds_prob_SN, 'T/F':preds_prob_TF, 'J/P':preds_prob_JP}\n",
        "preds_prob = pd.DataFrame(data=preds_prob)\n",
        "preds_prob = preds_prob.set_index('idx')\n",
        "preds_prob.to_csv('result_prob.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG4-6c_2MOSp"
      },
      "source": [
        "### 5. BASELINE + GENDER\n",
        "This time, add 'gender' as the input"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S11ZIoddMOSq"
      },
      "source": [
        "#### 5-0. Data Setup\n",
        "First of all, we should organize our data with some organized logics.  \n",
        "In this section, I will load three datasets and aggregate them into two datasets: Questions, Training Data and Test Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p1XkmCpaMOSr",
        "outputId": "11e2f5c3-affd-4827-a38e-e1746e0a158a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56b920a5-9c41-44c6-8add-fbd81c78cbed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56b920a5-9c41-44c6-8add-fbd81c78cbed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56b920a5-9c41-44c6-8add-fbd81c78cbed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56b920a5-9c41-44c6-8add-fbd81c78cbed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...\n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...\n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...\n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.\n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "questions = pd.read_excel(os.path.join(root_dir, questions_dir))\n",
        "questions.drop(['index', 'index.1'], axis='columns', inplace=True)\n",
        "display(questions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ge3hSc_NMOSs",
        "outputId": "d8c7c313-4823-4f0a-b895-c7b8906963c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ff21cb6-c832-42e2-aa4e-cd36b332e5db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Gender</th>\n",
              "      <th>MBTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...</td>\n",
              "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
              "      <td>1</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...</td>\n",
              "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
              "      <td>1</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...</td>\n",
              "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.</td>\n",
              "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
              "      <td>1</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.</td>\n",
              "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
              "      <td>1</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ff21cb6-c832-42e2-aa4e-cd36b332e5db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ff21cb6-c832-42e2-aa4e-cd36b332e5db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ff21cb6-c832-42e2-aa4e-cd36b332e5db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁...   \n",
              "1  자유 시간 중 상당 부분을 다양한 관심사를 탐구하는 데 할애하나요? 요즘 어떤 관심...   \n",
              "2  다른 사람이 울고 있는 모습을 보면 자신도 울고 싶어질 때가 많나요? 이런 상황에서...   \n",
              "3         일이 잘못될 때를 대비해 여러 대비책을 세우는 편인가요? 이유는 무엇인가요.   \n",
              "4       압박감이 심한 환경에서도 평정심을 유지하는 편인가요? 최근 경험을 말씀해주세요.   \n",
              "\n",
              "                                              Answer  Gender  MBTI  \n",
              "0  <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...       1  INFP  \n",
              "1  <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...       1  INFP  \n",
              "2  <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...       1  INFP  \n",
              "3  <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...       1  INFP  \n",
              "4  <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...       1  INFP  "
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieve the original question in String, using the question number\n",
        "def retrival_q(q_num):\n",
        "  return questions.loc[q_num - 1]['Question']\n",
        "\n",
        "# Unit Test\n",
        "assert(retrival_q(1) == \"주기적으로 새로운 친구를 만드나요? 경험을 비추어봤을 때 어떤지와 그러한 이유가 궁금해요.\")\n",
        "\n",
        "\n",
        "training = pd.read_csv(os.path.join(root_dir, train_dir), encoding=\"CP949\")\n",
        "\n",
        "# We will only use the question-answer pair, at this time.\n",
        "training.drop(['Data_ID', 'User_ID', 'Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "training['Question'] = training['Q_number'].apply(retrival_q)\n",
        "training.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "training = training[['Question', 'Answer', 'Gender', 'MBTI']]\n",
        "\n",
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fx_Px3NLMOSu",
        "outputId": "07daeb06-074a-4d03-e2fe-d557458a7fbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f601402-d08d-444f-9f7f-12eed18d1f61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.</td>\n",
              "      <td>&lt;아니다&gt; 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...</td>\n",
              "      <td>&lt;중립&gt; 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...</td>\n",
              "      <td>&lt;그렇다&gt; 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.</td>\n",
              "      <td>&lt;그렇다&gt; 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.</td>\n",
              "      <td>&lt;중립&gt; 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f601402-d08d-444f-9f7f-12eed18d1f61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f601402-d08d-444f-9f7f-12eed18d1f61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f601402-d08d-444f-9f7f-12eed18d1f61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0                     마감 기한을 지키기가 힘든가요? 경험을 이야기해보아요.   \n",
              "1  조용하고 사적인 장소보다는 사람들로 붐비고 떠들썩한 장소를 좋아하나요? 답변에 대한...   \n",
              "2  단계를 건너뛰는 일 없이 절차대로 일을 완수하는 편인가요? 그러한 최근 경험은 어떤...   \n",
              "3    일이 원하는 대로 진행될 것이라는 자신감이 있나요? 그렇게 된 계기나 이유가 있나요.   \n",
              "4         대부분의 시간을 혼자서 일할 수 있는 직업을 원하나요? 이유도 말씀해주세요.   \n",
              "\n",
              "                                              Answer  Gender  \n",
              "0  <아니다> 저는 모든 일은 정해진 시간을 지켜서 해야 된다고 생각되어서 마감 기한을...       0  \n",
              "1  <중립> 저는 조용하고 사적인 장소도 좋아하고 사람들로 붐비고 떠들썩한 장소도 좋아...       1  \n",
              "2  <그렇다> 저는 규칙을 잘 지키고 매뉴얼 대로 일하는 사람입니다. 그래서 데이터 라...       1  \n",
              "3  <그렇다> 저는 항상 긍정적인 사고방식을 가지고 살려고 노력하고 있습니다. 이유는 ...       1  \n",
              "4  <중립> 혼자서 일하는 것도 좋고 함께 일하는 것도 모두 좋은데 같이 의논하는 일도...       1  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing = pd.read_csv(os.path.join(root_dir, test_dir), encoding=\"CP949\")\n",
        "\n",
        "# Again, we will only use the question-answer pair, at this moment.\n",
        "testing.drop(['Age'], axis='columns', inplace=True)\n",
        "\n",
        "# Retreieve the original question!\n",
        "testing['Question'] = testing['Q_number'].apply(retrival_q)\n",
        "testing.drop('Q_number', axis='columns', inplace=True)\n",
        "\n",
        "# Reordering\n",
        "testing = testing[['Question', 'Answer', 'Gender']]\n",
        "\n",
        "testing.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G7IOgaASMOSv"
      },
      "source": [
        "#### 5-1. Preprocessing\n",
        "For utilizing BERT, we have to satisify its own preprocessing requirements.  \n",
        "For example, it requires speical tokens such as SEP and CLS in the input.  \n",
        "But don't worry, since these requirements can be simply satisfied if we use the BERT Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbHoIPKgMOSx",
        "outputId": "ce42aa0e-1b15-4c86-bf8c-fab1ff3718ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for train_sentence in training['Question']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for train_sentence in training['Answer']:\n",
        "  tok = tokenizer_bert.encode(train_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 206 in tokens, so set max_length as 256, safely\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "genders = []\n",
        "labels_IE = []\n",
        "labels_SN = []\n",
        "labels_TF = []\n",
        "labels_JP = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in training.index:\n",
        "  question = training['Question'][idx]\n",
        "  answer = training['Answer'][idx]\n",
        "  gender = training['Gender'][idx]\n",
        "  mbti = training['MBTI'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  # Convert MBTI of string to list of integers.\n",
        "  mbti = MBTI_to_vec(mbti)\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  genders.append(torch.tensor([[gender]]))\n",
        "  labels_IE.append(torch.tensor([mbti[0]]))\n",
        "  labels_SN.append(torch.tensor([mbti[1]]))\n",
        "  labels_TF.append(torch.tensor([mbti[2]]))\n",
        "  labels_JP.append(torch.tensor([mbti[3]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "genders = torch.cat(genders, dim=0)\n",
        "labels_IE = torch.cat(labels_IE, dim=0)\n",
        "labels_SN = torch.cat(labels_SN, dim=0)\n",
        "labels_TF = torch.cat(labels_TF, dim=0)\n",
        "labels_JP = torch.cat(labels_JP, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7MMOPhjMOSz",
        "outputId": "8e3f6538-6394-4d8e-d0bd-ebc719b1d8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2, 25753, 14567, 28897, 18069, 14526,  2033, 19742, 22742,  8082,\n",
            "        31724,  3463, 32771,  8061, 19773, 16941, 24296,  8055,  2016,     3,\n",
            "         2030, 15345,  2032, 18430,  3463,  5724,  8423, 26850, 20699, 14204,\n",
            "        15916, 17729, 25878, 18895, 14045, 27024,  8107, 28669,  8120,  6266,\n",
            "        24832,  2016,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1])\n",
            "tensor([1, 0])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "11520 11520 11520 11520\n"
          ]
        }
      ],
      "source": [
        "print(input_ids[0])\n",
        "print(att_masks[0])\n",
        "print(genders[0])\n",
        "print(labels_IE[0])\n",
        "print(labels_SN[0])\n",
        "print(labels_TF[0])\n",
        "print(labels_JP[0])\n",
        "\n",
        "print(len(input_ids), len(att_masks), len(genders), len(labels_IE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6lOl5myMOS0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Fix the seeds\n",
        "seed_val = 50\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "guDzu8ISMOS0"
      },
      "source": [
        "#### 5-2. Data Split\n",
        "Currently, we do not have the answers for testing dataset, so we must split the training data to evaluate our model. (18:1:1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blddmarPMOS2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, genders, labels_IE)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, genders, labels_SN)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, genders, labels_TF)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, genders, labels_JP)\n",
        "\n",
        "batch_size = 16 # 16 or 32\n",
        "\n",
        "# Define dataloaders\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = RandomSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = RandomSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = RandomSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = RandomSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "# \"\"train_size = int(0.9 * len(dataset_IE))\n",
        "# val_size = int(0.05 * len(dataset_IE))\n",
        "# test_size = len(dataset_IE) - train_size - val_size\n",
        "\n",
        "# print(f\"lengths are {train_size}:{val_size}:{test_size}\")\n",
        "\n",
        "# # Split into train dataset, validation dataset and test dataset.\n",
        "# train_dataset_IE, val_dataset_IE, test_dataset_IE = random_split(dataset_IE, [train_size, val_size, test_size])\n",
        "# train_dataset_SN, val_dataset_SN, test_dataset_SN = random_split(dataset_SN, [train_size, val_size, test_size])\n",
        "# train_dataset_TF, val_dataset_TF, test_dataset_TF = random_split(dataset_TF, [train_size, val_size, test_size])\n",
        "# train_dataset_JP, val_dataset_JP, test_dataset_JP = random_split(dataset_JP, [train_size, val_size, test_size])\n",
        "\n",
        "# batch_size = 16 # 16 or 32\n",
        "\n",
        "# # Define dataloaders\n",
        "# train_dataloader_IE = DataLoader(\n",
        "#     train_dataset_IE,\n",
        "#     sampler = RandomSampler(train_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_IE = DataLoader (\n",
        "#     val_dataset_IE,\n",
        "#     sampler = SequentialSampler(val_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_IE = DataLoader (\n",
        "#     test_dataset_IE,\n",
        "#     sampler = SequentialSampler(test_dataset_IE),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_SN = DataLoader(\n",
        "#     train_dataset_SN,\n",
        "#     sampler = RandomSampler(train_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_SN = DataLoader (\n",
        "#     val_dataset_SN,\n",
        "#     sampler = SequentialSampler(val_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_SN = DataLoader (\n",
        "#     test_dataset_SN,\n",
        "#     sampler = SequentialSampler(test_dataset_SN),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_TF = DataLoader(\n",
        "#     train_dataset_TF,\n",
        "#     sampler = RandomSampler(train_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_TF = DataLoader (\n",
        "#     val_dataset_TF,\n",
        "#     sampler = SequentialSampler(val_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_TF = DataLoader (\n",
        "#     test_dataset_TF,\n",
        "#     sampler = SequentialSampler(test_dataset_TF),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# train_dataloader_JP = DataLoader(\n",
        "#     train_dataset_JP,\n",
        "#     sampler = RandomSampler(train_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# val_dataloader_JP = DataLoader (\n",
        "#     val_dataset_JP,\n",
        "#     sampler = SequentialSampler(val_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\n",
        "\n",
        "# test_dataloader_JP = DataLoader (\n",
        "#     test_dataset_JP,\n",
        "#     sampler = SequentialSampler(test_dataset_JP),\n",
        "#     batch_size = batch_size\n",
        "# )\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bFFExd4wMOS3"
      },
      "source": [
        "#### 5-3. Model Definition\n",
        "Now we require a model written in Torch package.  \n",
        "Because we decided to **fine-tune** the pretrained BERT model, I'm going to add just one layer on top of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZwNMp19MOS3",
        "outputId": "4e990605-6433-4439-e81b-a748e9b19a33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, get_cosine_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class MBTIClassifier(nn.Module):\n",
        "  def __init__ (self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=2,\n",
        "                dr_rate=None):\n",
        "    super(MBTIClassifier, self).__init__()\n",
        "    self.dr_rate = dr_rate\n",
        "    self.bert = bert\n",
        "    self.linstr = nn.Linear(hidden_size, (int)(hidden_size * (127 / 128)))\n",
        "    self.lingen = nn.Linear(1, hidden_size - (int)(hidden_size * (127 / 128)))\n",
        "    self.lin = nn.Linear(hidden_size, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(128, num_classes)\n",
        "    self.classifier = nn.Softmax(dim = 1)\n",
        "\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def forward(self, input_ids, att_masks, gens):\n",
        "    bert_output = self.bert(input_ids, token_type_ids=None, attention_mask=att_masks).pooler_output\n",
        "    \n",
        "    if self.dr_rate:\n",
        "      dr_output = self.dropout(bert_output)\n",
        "    else:\n",
        "      dr_output = bert_output\n",
        "\n",
        "    linstr_output = self.linstr(dr_output)\n",
        "    lingen_output = self.lingen(gens)\n",
        "\n",
        "    gen_added = torch.cat((linstr_output, lingen_output), dim=1)\n",
        "\n",
        "    lin_output = self.lin(gen_added)\n",
        "    relu_output = self.relu(lin_output)\n",
        "    lin2_output = self.lin2(relu_output)\n",
        "    \n",
        "    return self.classifier(lin2_output)\n",
        "\n",
        "model_bert_IE = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_SN = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_TF = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "model_bert_JP = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
        "  \n",
        "model_IE = MBTIClassifier(model_bert_IE, dr_rate = 0.3)\n",
        "model_SN = MBTIClassifier(model_bert_SN, dr_rate = 0.3)\n",
        "model_TF = MBTIClassifier(model_bert_TF, dr_rate = 0.3)\n",
        "model_JP = MBTIClassifier(model_bert_JP, dr_rate = 0.3)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters_IE = [\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_IE.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_SN = [\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_SN.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_TF = [\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_TF.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer_grouped_parameters_JP = [\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model_JP.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "learning_rate = 2e-5\n",
        "\n",
        "optimizer_IE = AdamW(optimizer_grouped_parameters_IE,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_SN = AdamW(optimizer_grouped_parameters_SN,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_TF = AdamW(optimizer_grouped_parameters_TF,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "optimizer_JP = AdamW(optimizer_grouped_parameters_JP,\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4 # 2 or 4\n",
        "\n",
        "total_steps = len(dataloader_IE) * epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "\n",
        "scheduler_IE = get_cosine_schedule_with_warmup(optimizer_IE, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_SN = get_cosine_schedule_with_warmup(optimizer_SN, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_TF = get_cosine_schedule_with_warmup(optimizer_TF, num_warmup_steps = warmup_steps, num_training_steps = total_steps)\n",
        "scheduler_JP = get_cosine_schedule_with_warmup(optimizer_JP, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fLVjzWPsMOS4"
      },
      "source": [
        "#### 5-4. Training\n",
        "Finally, we can do train our model!  \n",
        "Let's see how accurate our model is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL9BmATJMOS5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_IE.cuda()\n",
        "model_SN.cuda()\n",
        "model_TF.cuda()\n",
        "model_JP.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_accuracy(preds, labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sylUDbVKMOS6"
      },
      "source": [
        "##### 5-4-1. I vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vBxM9cHMOS6",
        "outputId": "b83c0db8-8d9d-477b-cf1c-c2938d4714fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= I/E : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.7001798748970032 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.7016459107398987 train acc 0.5116279069767442\n",
            "epoch 1 batch id 257 loss 0.6852167844772339 train acc 0.5055933852140078\n",
            "epoch 1 batch id 385 loss 0.7021611928939819 train acc 0.5209415584415584\n",
            "epoch 1 batch id 513 loss 0.7122368216514587 train acc 0.5285087719298246\n",
            "epoch 1 batch id 641 loss 0.6721355319023132 train acc 0.5349063962558502\n",
            "\n",
            "======= I/E : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6485157012939453 train acc 0.75\n",
            "epoch 2 batch id 129 loss 0.6639285087585449 train acc 0.6216085271317829\n",
            "epoch 2 batch id 257 loss 0.5877779722213745 train acc 0.6223249027237354\n",
            "epoch 2 batch id 385 loss 0.6351543068885803 train acc 0.6313311688311688\n",
            "epoch 2 batch id 513 loss 0.7415991425514221 train acc 0.6298732943469786\n",
            "epoch 2 batch id 641 loss 0.7780039310455322 train acc 0.6333853354134166\n",
            "\n",
            "======= I/E : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5490245223045349 train acc 0.8125\n",
            "epoch 3 batch id 129 loss 0.6687514781951904 train acc 0.7461240310077519\n",
            "epoch 3 batch id 257 loss 0.5545823574066162 train acc 0.7312743190661478\n",
            "epoch 3 batch id 385 loss 0.5382578372955322 train acc 0.7280844155844156\n",
            "epoch 3 batch id 513 loss 0.46660521626472473 train acc 0.729775828460039\n",
            "epoch 3 batch id 641 loss 0.46679598093032837 train acc 0.7308892355694228\n",
            "\n",
            "======= I/E : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.3763463497161865 train acc 0.9375\n",
            "epoch 4 batch id 129 loss 0.5151146054267883 train acc 0.8013565891472868\n",
            "epoch 4 batch id 257 loss 0.39506995677948 train acc 0.807636186770428\n",
            "epoch 4 batch id 385 loss 0.5986359715461731 train acc 0.8081168831168831\n",
            "epoch 4 batch id 513 loss 0.45705607533454895 train acc 0.8079922027290448\n",
            "epoch 4 batch id 641 loss 0.592829167842865 train acc 0.8105499219968799\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= I/E : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_IE.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_IE):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_gender = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_IE.zero_grad()\n",
        "\n",
        "    b_out = model_IE(b_input_id, b_input_mask, b_gender)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_IE.parameters(), 1.0)\n",
        "\n",
        "    optimizer_IE.step()\n",
        "    scheduler_IE.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_IE, model_IE_dir)\n",
        "del(model_IE)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8ganB3LMMOS7"
      },
      "source": [
        "##### 5-4-2. S vs. N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNJVDSD_MOS8",
        "outputId": "dffb796f-98fe-4fb1-d1ff-4c84003d0cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= S/N : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6960057020187378 train acc 0.4375\n",
            "epoch 1 batch id 129 loss 0.688785195350647 train acc 0.5247093023255814\n",
            "epoch 1 batch id 257 loss 0.6874986290931702 train acc 0.521887159533074\n",
            "epoch 1 batch id 385 loss 0.7806422710418701 train acc 0.5376623376623376\n",
            "epoch 1 batch id 513 loss 0.5792698264122009 train acc 0.5455653021442495\n",
            "epoch 1 batch id 641 loss 0.6319953799247742 train acc 0.5506045241809673\n",
            "\n",
            "======= S/N : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7074391841888428 train acc 0.4375\n",
            "epoch 2 batch id 129 loss 0.5853970050811768 train acc 0.6182170542635659\n",
            "epoch 2 batch id 257 loss 0.6319385170936584 train acc 0.6303501945525292\n",
            "epoch 2 batch id 385 loss 0.5918905138969421 train acc 0.6308441558441559\n",
            "epoch 2 batch id 513 loss 0.4849189817905426 train acc 0.6331627680311891\n",
            "epoch 2 batch id 641 loss 0.5771105289459229 train acc 0.6341653666146646\n",
            "\n",
            "======= S/N : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5119748115539551 train acc 0.875\n",
            "epoch 3 batch id 129 loss 0.4745030999183655 train acc 0.7286821705426356\n",
            "epoch 3 batch id 257 loss 0.6389216780662537 train acc 0.7244649805447471\n",
            "epoch 3 batch id 385 loss 0.604107141494751 train acc 0.7261363636363637\n",
            "epoch 3 batch id 513 loss 0.7219314575195312 train acc 0.7251461988304093\n",
            "epoch 3 batch id 641 loss 0.5001887083053589 train acc 0.7252340093603744\n",
            "\n",
            "======= S/N : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.6229147911071777 train acc 0.6875\n",
            "epoch 4 batch id 129 loss 0.5113075971603394 train acc 0.7761627906976745\n",
            "epoch 4 batch id 257 loss 0.5203523635864258 train acc 0.7818579766536965\n",
            "epoch 4 batch id 385 loss 0.4512735605239868 train acc 0.7816558441558441\n",
            "epoch 4 batch id 513 loss 0.5708966255187988 train acc 0.7824074074074074\n",
            "epoch 4 batch id 641 loss 0.5463740229606628 train acc 0.7834438377535101\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= S/N : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_SN.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_SN):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_SN.zero_grad()\n",
        "\n",
        "    b_out = model_SN(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_SN.parameters(), 1.0)\n",
        "\n",
        "    optimizer_SN.step()\n",
        "    scheduler_SN.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_SN, model_SN_dir)\n",
        "del(model_SN)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g79ojyhaMOS9"
      },
      "source": [
        "##### 5-4-3. T vs. F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtxsGmAOMOS9",
        "outputId": "2029547c-477d-4d12-fd1e-f4d206b3913c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= T/F : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.6729010343551636 train acc 0.625\n",
            "epoch 1 batch id 129 loss 0.6967265605926514 train acc 0.5072674418604651\n",
            "epoch 1 batch id 257 loss 0.6803112626075745 train acc 0.5068093385214008\n",
            "epoch 1 batch id 385 loss 0.6805212497711182 train acc 0.5076298701298702\n",
            "epoch 1 batch id 513 loss 0.7193647623062134 train acc 0.518396686159844\n",
            "epoch 1 batch id 641 loss 0.6367465257644653 train acc 0.5240834633385335\n",
            "\n",
            "======= T/F : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.6807119250297546 train acc 0.5625\n",
            "epoch 2 batch id 129 loss 0.7659392952919006 train acc 0.5944767441860465\n",
            "epoch 2 batch id 257 loss 0.6823577284812927 train acc 0.6070038910505836\n",
            "epoch 2 batch id 385 loss 0.6202472448348999 train acc 0.6116883116883117\n",
            "epoch 2 batch id 513 loss 0.5753186941146851 train acc 0.6126949317738791\n",
            "epoch 2 batch id 641 loss 0.6222316026687622 train acc 0.6143720748829953\n",
            "\n",
            "======= T/F : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.5949863195419312 train acc 0.75\n",
            "epoch 3 batch id 129 loss 0.5751014351844788 train acc 0.7078488372093024\n",
            "epoch 3 batch id 257 loss 0.584908664226532 train acc 0.7016050583657587\n",
            "epoch 3 batch id 385 loss 0.6516733169555664 train acc 0.7021103896103896\n",
            "epoch 3 batch id 513 loss 0.6686227321624756 train acc 0.7032163742690059\n",
            "epoch 3 batch id 641 loss 0.5425963997840881 train acc 0.7078783151326054\n",
            "\n",
            "======= T/F : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.3982124328613281 train acc 1.0\n",
            "epoch 4 batch id 129 loss 0.5368254780769348 train acc 0.8018410852713178\n",
            "epoch 4 batch id 257 loss 0.5269202589988708 train acc 0.7910992217898832\n",
            "epoch 4 batch id 385 loss 0.48677095770835876 train acc 0.7797077922077922\n",
            "epoch 4 batch id 513 loss 0.4672364890575409 train acc 0.776803118908382\n",
            "epoch 4 batch id 641 loss 0.5862283110618591 train acc 0.7783736349453978\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= T/F : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_TF.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_TF):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_age = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_TF.zero_grad()\n",
        "\n",
        "    b_out = model_TF(b_input_id, b_input_mask, b_age)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_TF.parameters(), 1.0)\n",
        "\n",
        "    optimizer_TF.step()\n",
        "    scheduler_TF.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "  \n",
        "torch.save(model_TF, model_TF_dir)\n",
        "del(model_TF)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1fzkPxjnMOS9"
      },
      "source": [
        "##### 5-4-4. J vs. P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoyWrrlIMOS9",
        "outputId": "4c1faa21-1a08-463f-828f-d789bc48adc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= J/P : 1 / 4 =======\n",
            "epoch 1 batch id 1 loss 0.7049600481987 train acc 0.1875\n",
            "epoch 1 batch id 129 loss 0.7053886651992798 train acc 0.49709302325581395\n",
            "epoch 1 batch id 257 loss 0.7000486850738525 train acc 0.48711089494163423\n",
            "epoch 1 batch id 385 loss 0.7155138254165649 train acc 0.4943181818181818\n",
            "epoch 1 batch id 513 loss 0.6768242716789246 train acc 0.496588693957115\n",
            "epoch 1 batch id 641 loss 0.6982666254043579 train acc 0.49726989079563183\n",
            "\n",
            "======= J/P : 2 / 4 =======\n",
            "epoch 2 batch id 1 loss 0.7004210948944092 train acc 0.375\n",
            "epoch 2 batch id 129 loss 0.6860992908477783 train acc 0.5203488372093024\n",
            "epoch 2 batch id 257 loss 0.6669090986251831 train acc 0.5233463035019456\n",
            "epoch 2 batch id 385 loss 0.6913437843322754 train acc 0.5287337662337662\n",
            "epoch 2 batch id 513 loss 0.6948210597038269 train acc 0.5282651072124757\n",
            "epoch 2 batch id 641 loss 0.7147037982940674 train acc 0.5328588143525741\n",
            "\n",
            "======= J/P : 3 / 4 =======\n",
            "epoch 3 batch id 1 loss 0.6591122150421143 train acc 0.625\n",
            "epoch 3 batch id 129 loss 0.7106804847717285 train acc 0.5983527131782945\n",
            "epoch 3 batch id 257 loss 0.6971054673194885 train acc 0.5911964980544747\n",
            "epoch 3 batch id 385 loss 0.7244173288345337 train acc 0.5978896103896104\n",
            "epoch 3 batch id 513 loss 0.7131266593933105 train acc 0.598196881091618\n",
            "epoch 3 batch id 641 loss 0.7270976305007935 train acc 0.5967238689547582\n",
            "\n",
            "======= J/P : 4 / 4 =======\n",
            "epoch 4 batch id 1 loss 0.7091090679168701 train acc 0.5\n",
            "epoch 4 batch id 129 loss 0.6114258766174316 train acc 0.6472868217054264\n",
            "epoch 4 batch id 257 loss 0.636346697807312 train acc 0.6507782101167315\n",
            "epoch 4 batch id 385 loss 0.6362364292144775 train acc 0.6548701298701298\n",
            "epoch 4 batch id 513 loss 0.6083358526229858 train acc 0.6537524366471735\n",
            "epoch 4 batch id 641 loss 0.5997598171234131 train acc 0.6530811232449298\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\n======= J/P : {epoch + 1} / {epochs} =======\")\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  model_JP.train()\n",
        "\n",
        "  for step, batch in enumerate(dataloader_JP):\n",
        "    b_input_id = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_gender = batch[2].float().to(device)\n",
        "    b_label = batch[3].float().to(device)\n",
        "\n",
        "    optimizer_JP.zero_grad()\n",
        "\n",
        "    b_out = model_JP(b_input_id, b_input_mask, b_gender)\n",
        "    loss = loss_fn(b_out, b_label)\n",
        "    loss.backward()\n",
        "        \n",
        "    torch.nn.utils.clip_grad_norm_(model_JP.parameters(), 1.0)\n",
        "\n",
        "    optimizer_JP.step()\n",
        "    scheduler_JP.step()\n",
        "\n",
        "    train_acc += calc_accuracy(b_out, b_label)\n",
        "\n",
        "    if step % 128 == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch + 1, step + 1, loss.data.cpu().numpy(), train_acc / (step + 1)))\n",
        "\n",
        "torch.save(model_JP, model_JP_dir)\n",
        "del(model_JP)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2xNlymYdMOS_"
      },
      "source": [
        "#### 5-5. Export Results\n",
        "Using our trained model, produce the output for real test inputs (variable`testing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEuYuPKNMOTA",
        "outputId": "dafc687d-e518-4adf-a2ba-0d619307ff4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading a tokenizer and a model.\n",
        "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# Experiment: measure the maximum number of tokens.\n",
        "max_len = 0\n",
        "for test_sentence in testing['Question']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "for test_sentence in testing['Answer']:\n",
        "  tok = tokenizer_bert.encode(test_sentence)\n",
        "  max_len = max(max_len, len(tok))\n",
        "\n",
        "print(max_len)\n",
        "# Here, the longest sentence's length is 105 in tokens, but set max_length as 256, as before\n",
        "max_len = 256\n",
        "\n",
        "input_ids = []\n",
        "att_masks = []\n",
        "genders = []\n",
        "\n",
        "# Preprocessing\n",
        "for idx in testing.index:\n",
        "  question = testing['Question'][idx]\n",
        "  answer = testing['Answer'][idx]\n",
        "  gender = training['Gender'][idx]\n",
        "\n",
        "  # Encode with the tokenizer.\n",
        "  encodings = tokenizer_bert(\n",
        "      question,\n",
        "      answer,\n",
        "      padding = 'max_length',\n",
        "      max_length = max_len,\n",
        "      return_tensors = 'pt',\n",
        "  )\n",
        "\n",
        "  input_ids.append(encodings['input_ids'])\n",
        "  att_masks.append(encodings['attention_mask'])\n",
        "  genders.append(torch.tensor([[gender]]))\n",
        "\n",
        "# Convert to tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "att_masks = torch.cat(att_masks, dim=0)\n",
        "genders = torch.cat(genders, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1qdFIjlMOTA"
      },
      "outputs": [],
      "source": [
        "# Construct datasets\n",
        "dataset_IE = TensorDataset(input_ids, att_masks, genders)\n",
        "dataset_SN = TensorDataset(input_ids, att_masks, genders)\n",
        "dataset_TF = TensorDataset(input_ids, att_masks, genders)\n",
        "dataset_JP = TensorDataset(input_ids, att_masks, genders)\n",
        "\n",
        "dataloader_IE = DataLoader (\n",
        "    dataset_IE,\n",
        "    sampler = SequentialSampler(dataset_IE),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_SN = DataLoader (\n",
        "    dataset_SN,\n",
        "    sampler = SequentialSampler(dataset_SN),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_TF = DataLoader (\n",
        "    dataset_TF,\n",
        "    sampler = SequentialSampler(dataset_TF),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "dataloader_JP = DataLoader (\n",
        "    dataset_JP,\n",
        "    sampler = SequentialSampler(dataset_JP),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFU3lfBYMOTB"
      },
      "outputs": [],
      "source": [
        "model_IE = torch.load(model_IE_dir)\n",
        "model_SN = torch.load(model_SN_dir)\n",
        "model_TF = torch.load(model_TF_dir)\n",
        "model_JP = torch.load(model_JP_dir)\n",
        "\n",
        "model_IE.eval()\n",
        "model_SN.eval()\n",
        "model_TF.eval()\n",
        "model_JP.eval()\n",
        "\n",
        "preds_IE = []\n",
        "preds_prob_IE = []\n",
        "preds_SN = []\n",
        "preds_prob_SN = []\n",
        "preds_TF = []\n",
        "preds_prob_TF = []\n",
        "preds_JP = []\n",
        "preds_prob_JP = []\n",
        "\n",
        "# Predict I vs. E\n",
        "for batch in dataloader_IE:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_gender = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_IE(b_input_id, b_input_mask, b_gender)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_IE = preds_prob_IE + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_IE = preds_IE + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict S vs. N\n",
        "for batch in dataloader_SN:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_gender = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_SN(b_input_id, b_input_mask, b_gender)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_SN = preds_prob_SN + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_SN = preds_SN + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict T vs. F\n",
        "for batch in dataloader_TF:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_gender = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_TF(b_input_id, b_input_mask, b_gender)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_TF = preds_prob_TF + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_TF = preds_TF + np.argmax(b_out_np, axis=1).flatten().tolist()\n",
        "\n",
        "# Predict J vs. P\n",
        "for batch in dataloader_JP:\n",
        "  b_input_id = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_gender = batch[2].float().to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      b_out = model_JP(b_input_id, b_input_mask, b_gender)\n",
        "\n",
        "  b_out_np = b_out.detach().cpu().numpy()\n",
        "  preds_prob_JP = preds_prob_JP + list(map(lambda x: x[1], b_out_np.tolist()))\n",
        "  preds_JP = preds_JP + np.argmax(b_out_np, axis=1).flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hixhsbnMOTB"
      },
      "outputs": [],
      "source": [
        "idx = range(1, len(preds_IE) + 1)\n",
        "\n",
        "preds = {'idx': idx,'I/E': preds_IE, 'S/N':preds_SN, 'T/F':preds_TF, 'J/P':preds_JP}\n",
        "preds = pd.DataFrame(data=preds)\n",
        "preds = preds.set_index('idx')\n",
        "preds.to_csv('result.csv')\n",
        "\n",
        "preds_prob = {'idx': idx,'I/E': preds_prob_IE, 'S/N':preds_prob_SN, 'T/F':preds_prob_TF, 'J/P':preds_prob_JP}\n",
        "preds_prob = pd.DataFrame(data=preds_prob)\n",
        "preds_prob = preds_prob.set_index('idx')\n",
        "preds_prob.to_csv('result_prob.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Y2chO2kJvNHy"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01c1a9fdf8b746cba3cedf5f8c0f3e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038fafb3656f40e990fa6ed1b50c769e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78826cc2909d4e3784970a2a33cd4da8",
            "placeholder": "​",
            "style": "IPY_MODEL_8e552f369d8143838c5cd2b3a2d1ade7",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "07882d527a69414d8a8189e85c60252d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "084f8a5ea1a64c87a84c940ff8a645d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c5bd9e0e734c8693e71b672471e8e8",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bec0902671e4871a41e8f85d61a7753",
            "value": 344259
          }
        },
        "09a29598952543a880c75a5f28792cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ca96c1f9f94424d882a69d7d712ed70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b61c33ba19343979cf9eeb47957ada5",
            "placeholder": "​",
            "style": "IPY_MODEL_fdb9b28a4f274813a56c57537c1d9a03",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "0e122a61a3954c41b02d5be7ed1c2802": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fa88787afac4f0897308b2f56f117da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27089c0ff2a1490b89e013199e0846ad",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cfbde0070de4cb8a024fbb0188696f9",
            "value": 344259
          }
        },
        "0fb60144db4943df851134e8088eeac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fe578bbbce841f6bf9bee3c730ccbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_728481dbd970436e9d1ba8a71fe501fa",
            "placeholder": "​",
            "style": "IPY_MODEL_bd73a5773fce42318f1cc70676df0f38",
            "value": " 80.0/80.0 [00:00&lt;00:00, 6.38kB/s]"
          }
        },
        "101f2e141c14415989868ac802311a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1047f42ba6f6496a96ca544efcef2d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ee3f6d38194482af3310e9d0920b0c",
            "placeholder": "​",
            "style": "IPY_MODEL_4f3944c736a948c4ac9c1f1bd5e91e69",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "104a7d4f0eb54dfda5f764df89edcf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "121ca9995142473f96356803b3434a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c7c626322d4836b5044ba2805d36f6",
            "placeholder": "​",
            "style": "IPY_MODEL_70071c741df14ebdb5321cfecba52137",
            "value": " 344k/344k [00:00&lt;00:00, 9.19MB/s]"
          }
        },
        "155527cc147e42acb67e96c3ecbe2061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "193909d95f0240b8b4454dea37205f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3493099bc74c5397ef4314bd0801d4",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd3c75325fe40068c3c0f5aad118169",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1967f89b4f6f47a39bfe6bac9b29a752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19b91febd5404c92a573074546dde610": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acd0562bcdb4e8f8ae5f7e1a0b06188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5627427a304f50acbba4404bf77edc",
            "placeholder": "​",
            "style": "IPY_MODEL_1967f89b4f6f47a39bfe6bac9b29a752",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1b61c33ba19343979cf9eeb47957ada5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb4f6412f48454fac0eba12352e22ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff536b7843442a2b1042259bc5ed51e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2036231715e7430a8b12009357268de2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214bec3ec5cc4540b042037ab439efc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4b7b4142ae441c86ad539af7f887c0",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71a6073cacf84c2aa7552b60c0befcac",
            "value": 725
          }
        },
        "27089c0ff2a1490b89e013199e0846ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfe16b12e65411f998e1bccff382486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee870da3041427d870266d640ccdb25",
              "IPY_MODEL_dd7566a5ed854fa8b23ab6d661cf6a49",
              "IPY_MODEL_5adbafcd77f54b81a91cc7b5254150a3"
            ],
            "layout": "IPY_MODEL_31d86153f4bf4c1197003a31064cd098"
          }
        },
        "2c112e18eb3141e6a8f5bd28f3ad7649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_193909d95f0240b8b4454dea37205f78",
              "IPY_MODEL_fe85e4863273498fa21968929db13755",
              "IPY_MODEL_dcafd6ba0d96450d8406e78ba6f7621b"
            ],
            "layout": "IPY_MODEL_d9b71b7cbd9e409bb3d7658fc548c347"
          }
        },
        "2c26640f1c874d80a9ea494479260e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c2a87b00f56464d8a525ef85730811f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8e0f1a40564fd3acc1504e435b363b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f85f0d8161e42b79dfa72b5588296a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bfc49f7a5d444cae6b924963f1584f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d86153f4bf4c1197003a31064cd098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337dcaafa91e41a7bcb61bdfef120ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d552e9a95945e3ae4fe63a360e6c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dd04ebbe30144ad81cdd63ff2fca145",
              "IPY_MODEL_9c93444eedb74a8daef088a9ca29226c",
              "IPY_MODEL_121ca9995142473f96356803b3434a12"
            ],
            "layout": "IPY_MODEL_2c8e0f1a40564fd3acc1504e435b363b"
          }
        },
        "3635ac7aab7640a080a0d24ef0360515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5619a62e7b4f67b43ffd1647d7963b",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b55d69dfea494a11a804f1f6c5b19f7b",
            "value": 725
          }
        },
        "366c8c5afc3d44f3967179dd05d7ba22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e0fe9f289a48778758124a2600fb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383a387effcb4435a67f2b1659685879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d19659167fc40518e98c3cdde65384a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e94eeebfed9493c88961914437532a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1047f42ba6f6496a96ca544efcef2d5e",
              "IPY_MODEL_0fa88787afac4f0897308b2f56f117da",
              "IPY_MODEL_6455ef8005ee405aaca37b069c0b8d2b"
            ],
            "layout": "IPY_MODEL_df227ea2cafc49189e72f224bc49fa7d"
          }
        },
        "406d37e6d35144b2814421bf9468da59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f597380ecab24113a275f8329ba94750",
              "IPY_MODEL_214bec3ec5cc4540b042037ab439efc2",
              "IPY_MODEL_f8cdac3d36df46eab5b9bd1861982ac8"
            ],
            "layout": "IPY_MODEL_1ff536b7843442a2b1042259bc5ed51e"
          }
        },
        "418a865feab74f37917a624e96da0bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b262d0bdc07b444c8d5e1a953ce11245",
            "placeholder": "​",
            "style": "IPY_MODEL_09a29598952543a880c75a5f28792cc9",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "469365e6ac7340cd85a03e59c9552216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b30e212f6fc4fb78e57a3fb93d7bd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1acd0562bcdb4e8f8ae5f7e1a0b06188",
              "IPY_MODEL_4ebe0d6b63f741c8a7b6ab034097bc57",
              "IPY_MODEL_4b4c9f5bd2044bd28c495bcb8cb095b1"
            ],
            "layout": "IPY_MODEL_6bce5b4d2f3c40c994b75e7c45c55d89"
          }
        },
        "4b4c9f5bd2044bd28c495bcb8cb095b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f85f0d8161e42b79dfa72b5588296a5",
            "placeholder": "​",
            "style": "IPY_MODEL_9c11841a8a6d44829b5ce29c852a74f1",
            "value": " 80.0/80.0 [00:00&lt;00:00, 6.90kB/s]"
          }
        },
        "4bec0902671e4871a41e8f85d61a7753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dd04ebbe30144ad81cdd63ff2fca145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c1a9fdf8b746cba3cedf5f8c0f3e6b",
            "placeholder": "​",
            "style": "IPY_MODEL_750c5777dff8415e97a87b7246ff0fce",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "4ebe0d6b63f741c8a7b6ab034097bc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adb63386d0d947c09ea0bc197fd66f8b",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07882d527a69414d8a8189e85c60252d",
            "value": 80
          }
        },
        "4f3944c736a948c4ac9c1f1bd5e91e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f9124e7cd94ff88b017d6d53987e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566d868ceab14a21abbabdf7408c1161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5adbafcd77f54b81a91cc7b5254150a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f1dd2b0c9843a6a22b914cf218312f",
            "placeholder": "​",
            "style": "IPY_MODEL_8d677659a9e0466aa535bd04f87ea4f1",
            "value": " 476M/476M [00:22&lt;00:00, 22.0MB/s]"
          }
        },
        "61c019a689574884bc05001cb9c1ccaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afcdfdd961154c438e311bf21ca9251b",
              "IPY_MODEL_c62cdcd8b89c4c29852c83bd7ed5039b",
              "IPY_MODEL_bee618c6b25f427cb89ecf50f2014f0a"
            ],
            "layout": "IPY_MODEL_e8d840714f184b91914d7a4eb7cc83cf"
          }
        },
        "6455ef8005ee405aaca37b069c0b8d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684356e428334eb48ac3cb596430e69b",
            "placeholder": "​",
            "style": "IPY_MODEL_b933947e1398495287f131ca08a1823b",
            "value": " 344k/344k [00:00&lt;00:00, 668kB/s]"
          }
        },
        "658ac41dbc584647a3166e4933c7c9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "684356e428334eb48ac3cb596430e69b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687619be7e0c478b8729b434e87d162d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337dcaafa91e41a7bcb61bdfef120ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_658ac41dbc584647a3166e4933c7c9e5",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "6a3ecd0fb03c49bfb391bfcf7b1ade5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bce5b4d2f3c40c994b75e7c45c55d89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70071c741df14ebdb5321cfecba52137": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a6073cacf84c2aa7552b60c0befcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7220c444ef8e4642ab154087b4ec1b08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72492b9ca9c3470db9dd3db4a0b11c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_687619be7e0c478b8729b434e87d162d",
              "IPY_MODEL_ffe882263cfe40cfb4d953a9e9188eaf",
              "IPY_MODEL_81ddfc4bf4d84132b908d03913baf918"
            ],
            "layout": "IPY_MODEL_e8a3921ca23a493fa3339a369de47d71"
          }
        },
        "728481dbd970436e9d1ba8a71fe501fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749d78bdfe8448af97f11e8aecffd5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750c5777dff8415e97a87b7246ff0fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7524089cb5ce4a4d9343c0decd53b2ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "787972945ca240dba19400497f40f8da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78826cc2909d4e3784970a2a33cd4da8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794b7f421a294afd9292ac5753d691af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b883e028819448b9f4c86ea4c4da45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9ef141849ca4015990d1d882679cf2d",
              "IPY_MODEL_e1915d29a39647598ef924d91a192c07",
              "IPY_MODEL_ed7435492f634be4b94e571d86abcc25"
            ],
            "layout": "IPY_MODEL_2c2a87b00f56464d8a525ef85730811f"
          }
        },
        "8154ac58d64949118eebb29cb9a8ae2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ca96c1f9f94424d882a69d7d712ed70",
              "IPY_MODEL_8a318f99b2174209bd3fcd3d77daea8b",
              "IPY_MODEL_0fe578bbbce841f6bf9bee3c730ccbfb"
            ],
            "layout": "IPY_MODEL_f670096f1af744ecb512e308e4ed423f"
          }
        },
        "81ddfc4bf4d84132b908d03913baf918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749d78bdfe8448af97f11e8aecffd5ea",
            "placeholder": "​",
            "style": "IPY_MODEL_50f9124e7cd94ff88b017d6d53987e14",
            "value": " 725/725 [00:00&lt;00:00, 62.0kB/s]"
          }
        },
        "82b81824fce74e7cbfff7fe71662e5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b357c82c444f57b7f590f1eabd5fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a318f99b2174209bd3fcd3d77daea8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf63db022724484eaf2d58e8a6eee104",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c26640f1c874d80a9ea494479260e8f",
            "value": 80
          }
        },
        "8d27daf13e44462e83875e14ad73d1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d5619a62e7b4f67b43ffd1647d7963b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d677659a9e0466aa535bd04f87ea4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e552f369d8143838c5cd2b3a2d1ade7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f1dd2b0c9843a6a22b914cf218312f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96426c8717ae46b5a774e1fc1137cb09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9782e16c6c4c90b2f0b6ec74d173f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366c8c5afc3d44f3967179dd05d7ba22",
            "placeholder": "​",
            "style": "IPY_MODEL_a11eb887e8da44a9a90c3b5bd29313f7",
            "value": " 344k/344k [00:00&lt;00:00, 794kB/s]"
          }
        },
        "9c11841a8a6d44829b5ce29c852a74f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c93444eedb74a8daef088a9ca29226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b91febd5404c92a573074546dde610",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_104a7d4f0eb54dfda5f764df89edcf4e",
            "value": 344259
          }
        },
        "9cb932d402504b5989e57d78fa1b3140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cfbde0070de4cb8a024fbb0188696f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f3493099bc74c5397ef4314bd0801d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4f679916db4aa1b5cd2215d38fd2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11eb887e8da44a9a90c3b5bd29313f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16f117786bc4521ae560b8c5901dc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3737d6efd0542ca8b26740ded255959",
            "placeholder": "​",
            "style": "IPY_MODEL_155527cc147e42acb67e96c3ecbe2061",
            "value": " 344k/344k [00:00&lt;00:00, 5.16MB/s]"
          }
        },
        "a2c5bd9e0e734c8693e71b672471e8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a561895a74604d7b9b2dc1e2fc8977bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9ef141849ca4015990d1d882679cf2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed22766ce8aa478689d14e2669ea8f4a",
            "placeholder": "​",
            "style": "IPY_MODEL_3d19659167fc40518e98c3cdde65384a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ac5627427a304f50acbba4404bf77edc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb63386d0d947c09ea0bc197fd66f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcdfdd961154c438e311bf21ca9251b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3e3d4162884d24bdcffc90dd0ec342",
            "placeholder": "​",
            "style": "IPY_MODEL_e3b1f39d3ef946a584e20ef866dad68f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b262d0bdc07b444c8d5e1a953ce11245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55d69dfea494a11a804f1f6c5b19f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5905ce2b26542bd950190eef243fe4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4f679916db4aa1b5cd2215d38fd2a0",
            "placeholder": "​",
            "style": "IPY_MODEL_83b357c82c444f57b7f590f1eabd5fe4",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b62be928a72444e0a62a710b97c0a448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cb8bb8132244c69baf132f242f749b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_418a865feab74f37917a624e96da0bb3",
              "IPY_MODEL_084f8a5ea1a64c87a84c940ff8a645d5",
              "IPY_MODEL_a16f117786bc4521ae560b8c5901dc42"
            ],
            "layout": "IPY_MODEL_7220c444ef8e4642ab154087b4ec1b08"
          }
        },
        "b7ee3f6d38194482af3310e9d0920b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b933947e1398495287f131ca08a1823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd73a5773fce42318f1cc70676df0f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bee618c6b25f427cb89ecf50f2014f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e73d5ee4a544fdbe5a19a91e1a6e66",
            "placeholder": "​",
            "style": "IPY_MODEL_d7d70836251a4cd3a00d8e204e3b5845",
            "value": " 80.0/80.0 [00:00&lt;00:00, 2.83kB/s]"
          }
        },
        "c62cdcd8b89c4c29852c83bd7ed5039b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62be928a72444e0a62a710b97c0a448",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a561895a74604d7b9b2dc1e2fc8977bc",
            "value": 80
          }
        },
        "c7cd50e46d31403986063c65fed50cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc3e3d4162884d24bdcffc90dd0ec342": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd3c75325fe40068c3c0f5aad118169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf63db022724484eaf2d58e8a6eee104": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e800112f90461ab51fda1a02ae3b96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c7c626322d4836b5044ba2805d36f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3737d6efd0542ca8b26740ded255959": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d70836251a4cd3a00d8e204e3b5845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b71b7cbd9e409bb3d7658fc548c347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcafd6ba0d96450d8406e78ba6f7621b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bfc49f7a5d444cae6b924963f1584f",
            "placeholder": "​",
            "style": "IPY_MODEL_0fb60144db4943df851134e8088eeac1",
            "value": " 80.0/80.0 [00:00&lt;00:00, 5.56kB/s]"
          }
        },
        "dd7566a5ed854fa8b23ab6d661cf6a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3ecd0fb03c49bfb391bfcf7b1ade5e",
            "max": 475782997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e122a61a3954c41b02d5be7ed1c2802",
            "value": 475782997
          }
        },
        "de4b7b4142ae441c86ad539af7f887c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df227ea2cafc49189e72f224bc49fa7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df965057c5da44ab9c21ffa4f12a1db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e08ea6bf1f7840d893d56b87f90c493d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_038fafb3656f40e990fa6ed1b50c769e",
              "IPY_MODEL_e7fafc08f0a44ba0b0c8787be0d8a994",
              "IPY_MODEL_9b9782e16c6c4c90b2f0b6ec74d173f8"
            ],
            "layout": "IPY_MODEL_787972945ca240dba19400497f40f8da"
          }
        },
        "e1915d29a39647598ef924d91a192c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566d868ceab14a21abbabdf7408c1161",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cb932d402504b5989e57d78fa1b3140",
            "value": 725
          }
        },
        "e3b1f39d3ef946a584e20ef866dad68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7fafc08f0a44ba0b0c8787be0d8a994": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea72dac4e45d4a11922a021623a9f61c",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_794b7f421a294afd9292ac5753d691af",
            "value": 344259
          }
        },
        "e8a3921ca23a493fa3339a369de47d71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d840714f184b91914d7a4eb7cc83cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea72dac4e45d4a11922a021623a9f61c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed22766ce8aa478689d14e2669ea8f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7435492f634be4b94e571d86abcc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b81824fce74e7cbfff7fe71662e5dd",
            "placeholder": "​",
            "style": "IPY_MODEL_383a387effcb4435a67f2b1659685879",
            "value": " 725/725 [00:00&lt;00:00, 48.9kB/s]"
          }
        },
        "eee870da3041427d870266d640ccdb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bb4f6412f48454fac0eba12352e22ed",
            "placeholder": "​",
            "style": "IPY_MODEL_36e0fe9f289a48778758124a2600fb56",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f2e73d5ee4a544fdbe5a19a91e1a6e66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ec537286854445893f792c1612247b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f597380ecab24113a275f8329ba94750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96426c8717ae46b5a774e1fc1137cb09",
            "placeholder": "​",
            "style": "IPY_MODEL_8d27daf13e44462e83875e14ad73d1a1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "f670096f1af744ecb512e308e4ed423f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cdac3d36df46eab5b9bd1861982ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ec537286854445893f792c1612247b",
            "placeholder": "​",
            "style": "IPY_MODEL_101f2e141c14415989868ac802311a00",
            "value": " 725/725 [00:00&lt;00:00, 62.8kB/s]"
          }
        },
        "faf70ebe806d4368a6e77bbc1376d7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc20f0dff5bf4ae98e38948f5f93a8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e800112f90461ab51fda1a02ae3b96",
            "placeholder": "​",
            "style": "IPY_MODEL_469365e6ac7340cd85a03e59c9552216",
            "value": " 725/725 [00:00&lt;00:00, 50.8kB/s]"
          }
        },
        "fc6fafcfb2a5455e80898f31da6d93c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5905ce2b26542bd950190eef243fe4b",
              "IPY_MODEL_3635ac7aab7640a080a0d24ef0360515",
              "IPY_MODEL_fc20f0dff5bf4ae98e38948f5f93a8e8"
            ],
            "layout": "IPY_MODEL_faf70ebe806d4368a6e77bbc1376d7c1"
          }
        },
        "fdb9b28a4f274813a56c57537c1d9a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe85e4863273498fa21968929db13755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7524089cb5ce4a4d9343c0decd53b2ba",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df965057c5da44ab9c21ffa4f12a1db8",
            "value": 80
          }
        },
        "ffe882263cfe40cfb4d953a9e9188eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2036231715e7430a8b12009357268de2",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7cd50e46d31403986063c65fed50cab",
            "value": 725
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
